{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# Select GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runTraining(epoch_num, weights_path='', augm = False):\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 16\n",
    "    batch_size_val = 16\n",
    "    lr = 0.001   # Learning Rate\n",
    "    epoch = epoch_num # Number of epochs\n",
    "    \n",
    "    root_dir = './Data/'\n",
    "\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                      root_dir,\n",
    "                                                      transform=transform,\n",
    "                                                      mask_transform=mask_transform,\n",
    "                                                      augment=augm,  # Set to True to enable data augmentation\n",
    "                                                      equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                              batch_size=batch_size,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'Test_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "    net = net.to(device)  # Move the model to the device\n",
    "\n",
    "    ## Load the weights from the previously trained model\n",
    "    if weights_path != '':\n",
    "        # previous_model_dir = './models/' + 'Test_Model' + '/' + str(epoch_num) +'_Epoch'\n",
    "        net.load_state_dict(torch.load(weights_path))\n",
    "        print(\" Model loaded: {}\".format(weights_path))\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    \n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(epoch):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data            \n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(softMax(net_predictions), segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            lossTotal = CE_loss_value\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(lossTotal))\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch) + '\\n' \n",
    "                             + \"[Validation] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch))\n",
    "\n",
    "        \n",
    "        ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH. \n",
    "        ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "\n",
    "        torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            \n",
    "        np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runTraining(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a training loop\n",
    "# Looping from 9998 to 9994\n",
    "for i in range(9998, 9994, -1):\n",
    "    print(\"Epoch: {}\".format(i))\n",
    "    runTraining(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model on an Image\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotOutput(model_path, image_path):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net_test = UNet(4)\n",
    "    net_test = net_test.to(device)\n",
    "    net_test.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "\n",
    "    # Preprocess the image\n",
    "    x = TF.to_tensor(image)\n",
    "    x = TF.normalize(x, [0.5], [0.5])\n",
    "    x = x.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move the tensor to the same device as the model\n",
    "    x = x.to(device)\n",
    "\n",
    "    output = net_test(x)\n",
    "\n",
    "    # The output is the predicted segmentation\n",
    "    predicted_segmentation = torch.argmax(output.squeeze(), dim=0)\n",
    "\n",
    "    # Convert the tensor to a numpy array\n",
    "    predicted_segmentation = predicted_segmentation.detach().cpu().numpy()\n",
    "\n",
    "    # Display the predicted segmentation\n",
    "    plt.imshow(predicted_segmentation, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the training and validation loss of given weights\n",
    "\n",
    "def getLoss(weights_path):\n",
    "    # Load the weights from the file\n",
    "    model = UNet(4)\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "    # Determine the device and move the model to the device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize the loss function\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize a variable to store the total loss\n",
    "    root_dir = './Data/'\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                        root_dir,\n",
    "                                                        transform=transform,\n",
    "                                                        mask_transform=mask_transform,\n",
    "                                                        augment=True,  # Set to True to enable data augmentation\n",
    "                                                        equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                                batch_size=16,\n",
    "                                worker_init_fn=np.random.seed(0),\n",
    "                                num_workers=0,\n",
    "                                shuffle=True)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,                 \n",
    "                            batch_size=16,       \n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "    lossEpoch_train = []\n",
    "    lossEpoch_val = []\n",
    "\n",
    "\n",
    "    for j, data in enumerate(train_loader_full):\n",
    "        ### Set to zero all the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = data            \n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = to_var(labels)\n",
    "        images = to_var(images)\n",
    "\n",
    "        ################### Train ###################\n",
    "        #-- The CNN makes its predictions (forward pass)\n",
    "        net_predictions = model(images)\n",
    "\n",
    "        #-- Compute the losses --#\n",
    "        # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "        segmentation_classes = getTargetSegmentation(labels)\n",
    "        \n",
    "        # COMPUTE THE LOSS\n",
    "        CE_loss_value = CE_loss(softMax(net_predictions), segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "        \n",
    "        lossTotal = CE_loss_value\n",
    "        lossEpoch_train.append(lossTotal.item())\n",
    "\n",
    "    lossEpoch_train = np.asarray(lossEpoch_train)\n",
    "    lossEpoch_train = lossEpoch_train.mean()\n",
    "\n",
    "\n",
    "    for j, data in enumerate(val_loader):\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = data            \n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = to_var(labels)\n",
    "        images = to_var(images)\n",
    "\n",
    "        ################### Validate ###################\n",
    "        #-- The CNN makes its predictions (forward pass)\n",
    "        net_predictions = model(images)\n",
    "\n",
    "        #-- Compute the losses --#\n",
    "        # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "        segmentation_classes = getTargetSegmentation(labels)\n",
    "        \n",
    "        # COMPUTE THE LOSS\n",
    "        CE_loss_value = CE_loss(softMax(net_predictions), segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "        \n",
    "        lossTotal = CE_loss_value\n",
    "        lossEpoch_val.append(lossTotal.item())\n",
    "\n",
    "    lossEpoch_val = np.asarray(lossEpoch_val)\n",
    "    lossEpoch_val = lossEpoch_val.mean()\n",
    "\n",
    "    print('Training loss:', lossEpoch_train)\n",
    "    print('Validation loss:', lossEpoch_val)\n",
    "    return lossEpoch_train, lossEpoch_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss for multiple models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models_paths = ['./models/' + 'Trained' + '/Adam_Labeled_1.3k_Epoch']\n",
    "# models_paths = ['./models/' + 'Trained\\Data_Augmented' + '/Adam_Labeled_' + str(i) + '5k_Epoch' for i in range(0, 8)]\n",
    "models_paths = ['./models/' + 'Test_Model' + '/' + str(i) + '0_Epoch' for i in range(10,1500,100)]\n",
    "# List to store the losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Iterate over the list of paths\n",
    "for path in models_paths:\n",
    "    # Get the losses for the current path\n",
    "    train_loss, val_loss = getLoss(path)\n",
    "    \n",
    "    # Add the losses to the lists\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "# Plot the losses\n",
    "epochs = range(len(train_losses))\n",
    "# epochs = [(5 + 10*i)*1000 for i in range(len(train_losses))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_losses, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the outputs for different models\n",
    "\n",
    "models_paths = ['./models/' + 'Test_Model' + '/' + str(i) + '999_Epoch' for i in range(1,15)]\n",
    "# models_paths = ['./models/' + 'Trained/Data_Augmented_15K_EpochPlus' + '/Adam_Labeled_' + str(i) + '5k_Epoch' for i in range(0, 8)]\n",
    "image_path = \"./Data/val/Img/patient061_01_1.png\"\n",
    "\n",
    "for model_path in models_paths:\n",
    "    plotOutput(model_path, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised\n",
    "\n",
    "The objective is to implement a program based on this article [FixMatch](https://arxiv.org/abs/2001.07685). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Importing different Libraries to be able to treat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which torch version is installed on the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# Select GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We'll have one classic supervised model with no transformed image dataset. The results will be use as a a reference for the final model. The final model is built by comparing an none transformed image result to the result of the previous model and by comparing an output of this image and all transformed images based on this one and minimizing the difference.\n",
    "\n",
    "This way the model will not base his comparaison on the position in the image but will be able to identify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher\n",
    "\n",
    "The teacher is a basic supervised model where only labled data are beeing used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def loadData(mode, batchSize, rootDir='./Data', _augment=False, _shuffle=False, _equalize=False,_numWorkers=0):\n",
    "    print(\"~~~~~~~~~~~ Loading Data ~~~~~~~~~~\")\n",
    "    \n",
    "    root_dir = './Data/'\n",
    "\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    _transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    _mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    _set = medicalDataLoader.MedicalImageDataset(mode,\n",
    "                                                      rootDir,\n",
    "                                                      transform=_transform,\n",
    "                                                      mask_transform=_mask_transform,\n",
    "                                                      augment=_augment,  # Set to True to enable data augmentation\n",
    "                                                      equalize=_equalize)\n",
    "\n",
    "    loader = DataLoader(_set,\n",
    "                              batch_size=batchSize,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=_numWorkers,\n",
    "                              shuffle=_shuffle)\n",
    "\n",
    "    return loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModel(numberOfClasses, weights_path, modelName):\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "    net = net.to(device)  # Move the model to the device\n",
    "\n",
    "        ## Load the weights from the previously trained model\n",
    "    if weights_path != '':\n",
    "        net.load_state_dict(torch.load(weights_path))\n",
    "        print(\" Model loaded: {}\".format(weights_path))\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuResources(net,softmax,CE_loss):\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining(epoch_num, weights_path='', augm = False):\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 16\n",
    "    batch_size_val = 16\n",
    "    lr = 0.001   # Learning Rate\n",
    "    epoch = epoch_num # Number of epochs\n",
    "    \n",
    "    train_loader_full = loadData('train', batch_size,_augment=augm, _shuffle=True)\n",
    "    val_loader = loadData('val', batch_size_val,_augment=augm)\n",
    "\n",
    "    modelName = 'Test_Model'\n",
    "    net = initModel(4, weights_path,modelName)\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    gpuResources(net,softmax,CE_loss)\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    \n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    # Create saving directory if not already existing\n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(epoch):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data            \n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(softmax(net_predictions), segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            lossTotal = CE_loss_value\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(lossTotal))\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch) + '\\n' \n",
    "                             + \"[Validation] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch))\n",
    "\n",
    "        \n",
    "        ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH. \n",
    "        ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "\n",
    "        torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            \n",
    "        np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n",
    "\n",
    "    return os.path.join(directory, 'Losses.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "~~~~~~~~~~~ Loading Data ~~~~~~~~~~\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Loading Data ~~~~~~~~~~\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 1.4694===================================================================] 100.0%\n",
      "[Validation] Epoch: 0, LossG: 1.4694                                      \n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 1.4414===================================================================] 100.0%\n",
      "[Validation] Epoch: 1, LossG: 1.4414                                      \n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 1.4143===================================================================] 100.0%\n",
      "[Validation] Epoch: 2, LossG: 1.4143                                      \n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 1.3850===================================================================] 100.0%\n",
      "[Validation] Epoch: 3, LossG: 1.3850                                      \n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 1.3579===================================================================] 100.0%\n",
      "[Validation] Epoch: 4, LossG: 1.3579                                      \n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 1.3321===================================================================] 100.0%\n",
      "[Validation] Epoch: 5, LossG: 1.3321                                      \n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 1.3052===================================================================] 100.0%\n",
      "[Validation] Epoch: 6, LossG: 1.3052                                      \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb Cellule 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m runTraining(\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb Cellule 24\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb#X36sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m lossTotal \u001b[39m=\u001b[39m CE_loss_value\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb#X36sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb#X36sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m lossTotal\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb#X36sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulsade/Development/UNet_Semi_Supervised_Medical_Image_Segmentation/mainSegmentationChallenge.ipynb#X36sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# THIS IS JUST TO VISUALIZE THE TRAINING \u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runTraining(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
