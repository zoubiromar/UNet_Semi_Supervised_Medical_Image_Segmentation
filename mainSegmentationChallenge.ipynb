{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# Select GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runTraining(epoch_num, weights_path='', augm = False):\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 16\n",
    "    batch_size_val = 16\n",
    "    lr = 0.001   # Learning Rate\n",
    "    epoch = epoch_num # Number of epochs\n",
    "    \n",
    "    root_dir = './Data/'\n",
    "\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                      root_dir,\n",
    "                                                      transform=transform,\n",
    "                                                      mask_transform=mask_transform,\n",
    "                                                      augment=augm,  # Set to True to enable data augmentation\n",
    "                                                      equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                              batch_size=batch_size,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'Test_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "    net = net.to(device)  # Move the model to the device\n",
    "\n",
    "    ## Load the weights from the previously trained model\n",
    "    if weights_path != '':\n",
    "        # previous_model_dir = './models/' + 'Test_Model' + '/' + str(epoch_num) +'_Epoch'\n",
    "        net.load_state_dict(torch.load(weights_path))\n",
    "        print(\" Model loaded: {}\".format(weights_path))\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    \n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(epoch):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data            \n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(softMax(net_predictions), segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            lossTotal = CE_loss_value\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(lossTotal))\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch) + '\\n' \n",
    "                             + \"[Validation] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch))\n",
    "\n",
    "        \n",
    "        ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH. \n",
    "        ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "\n",
    "        torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            \n",
    "        np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runTraining(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450\n",
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      " Model loaded: ./models/Test_Model/450_Epoch\n",
      "Total params: 1,769,492\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 0.7615===================================================================] 100.0%\n",
      "[Validation] Epoch: 0, LossG: 0.7615                                      \n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 0.7563===================================================================] 100.0%\n",
      "[Validation] Epoch: 1, LossG: 0.7563                                      \n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 0.7559===================================================================] 100.0%\n",
      "[Validation] Epoch: 2, LossG: 0.7559                                      \n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 0.7553===================================================================] 100.0%\n",
      "[Validation] Epoch: 3, LossG: 0.7553                                      \n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 0.7548===================================================================] 100.0%\n",
      "[Validation] Epoch: 4, LossG: 0.7548                                      \n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 0.7531===================================================================] 100.0%\n",
      "[Validation] Epoch: 5, LossG: 0.7531                                      \n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 0.7541===================================================================] 100.0%\n",
      "[Validation] Epoch: 6, LossG: 0.7541                                      \n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 0.7539===================================================================] 100.0%\n",
      "[Validation] Epoch: 7, LossG: 0.7539                                      \n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 0.7532===================================================================] 100.0%\n",
      "[Validation] Epoch: 8, LossG: 0.7532                                      \n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 0.7525===================================================================] 100.0%\n",
      "[Validation] Epoch: 9, LossG: 0.7525                                      \n",
      "[Training] Epoch: 10 [DONE]                                 \n",
      "[Training] Epoch: 10, LossG: 0.7526==================================================================] 100.0%\n",
      "[Validation] Epoch: 10, LossG: 0.7526                                    \n",
      "[Training] Epoch: 11 [DONE]                                 \n",
      "[Training] Epoch: 11, LossG: 0.7526==================================================================] 100.0%\n",
      "[Validation] Epoch: 11, LossG: 0.7526                                    \n",
      "[Training] Epoch: 12 [DONE]                                 \n",
      "[Training] Epoch: 12, LossG: 0.7514==================================================================] 100.0%\n",
      "[Validation] Epoch: 12, LossG: 0.7514                                    \n",
      "[Training] Epoch: 13 [DONE]                                 \n",
      "[Training] Epoch: 13, LossG: 0.7512==================================================================] 100.0%\n",
      "[Validation] Epoch: 13, LossG: 0.7512                                    \n",
      "[Training] Epoch: 14 [DONE]                                 \n",
      "[Training] Epoch: 14, LossG: 0.7510==================================================================] 100.0%\n",
      "[Validation] Epoch: 14, LossG: 0.7510                                    \n",
      "[Training] Epoch: 15 [DONE]                                 \n",
      "[Training] Epoch: 15, LossG: 0.7502==================================================================] 100.0%\n",
      "[Validation] Epoch: 15, LossG: 0.7502                                    \n",
      "[Training] Epoch: 16 [DONE]                                 \n",
      "[Training] Epoch: 16, LossG: 0.7501==================================================================] 100.0%\n",
      "[Validation] Epoch: 16, LossG: 0.7501                                    \n",
      "[Training] Epoch: 17 [DONE]                                 \n",
      "[Training] Epoch: 17, LossG: 0.7498==================================================================] 100.0%\n",
      "[Validation] Epoch: 17, LossG: 0.7498                                    \n",
      "[Training] Epoch: 18 [DONE]                                 \n",
      "[Training] Epoch: 18, LossG: 0.7497==================================================================] 100.0%\n",
      "[Validation] Epoch: 18, LossG: 0.7497                                    \n",
      "[Training] Epoch: 19 [DONE]                                 \n",
      "[Training] Epoch: 19, LossG: 0.7492==================================================================] 100.0%\n",
      "[Validation] Epoch: 19, LossG: 0.7492                                    \n",
      "[Training] Epoch: 20 [DONE]                                 \n",
      "[Training] Epoch: 20, LossG: 0.7496==================================================================] 100.0%\n",
      "[Validation] Epoch: 20, LossG: 0.7496                                    \n",
      "[Training] Epoch: 21 [DONE]                                 \n",
      "[Training] Epoch: 21, LossG: 0.7494==================================================================] 100.0%\n",
      "[Validation] Epoch: 21, LossG: 0.7494                                    \n",
      "[Training] Epoch: 22 [DONE]                                 \n",
      "[Training] Epoch: 22, LossG: 0.7495==================================================================] 100.0%\n",
      "[Validation] Epoch: 22, LossG: 0.7495                                    \n",
      "[Training] Epoch: 23 [DONE]                                 \n",
      "[Training] Epoch: 23, LossG: 0.7493==================================================================] 100.0%\n",
      "[Validation] Epoch: 23, LossG: 0.7493                                    \n",
      "[Training] Epoch: 24 [DONE]                                 \n",
      "[Training] Epoch: 24, LossG: 0.7490==================================================================] 100.0%\n",
      "[Validation] Epoch: 24, LossG: 0.7490                                    \n",
      "[Training] Epoch: 25 [DONE]                                 \n",
      "[Training] Epoch: 25, LossG: 0.7489==================================================================] 100.0%\n",
      "[Validation] Epoch: 25, LossG: 0.7489                                    \n",
      "[Training] Epoch: 26 [DONE]                                 \n",
      "[Training] Epoch: 26, LossG: 0.7487==================================================================] 100.0%\n",
      "[Validation] Epoch: 26, LossG: 0.7487                                    \n",
      "[Training] Epoch: 27 [DONE]                                 \n",
      "[Training] Epoch: 27, LossG: 0.7487==================================================================] 100.0%\n",
      "[Validation] Epoch: 27, LossG: 0.7487                                    \n",
      "[Training] Epoch: 28 [DONE]                                 \n",
      "[Training] Epoch: 28, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 28, LossG: 0.7485                                    \n",
      "[Training] Epoch: 29 [DONE]                                 \n",
      "[Training] Epoch: 29, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 29, LossG: 0.7485                                    \n",
      "[Training] Epoch: 30 [DONE]                                 \n",
      "[Training] Epoch: 30, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 30, LossG: 0.7485                                    \n",
      "[Training] Epoch: 31 [DONE]                                 \n",
      "[Training] Epoch: 31, LossG: 0.7484==================================================================] 100.0%\n",
      "[Validation] Epoch: 31, LossG: 0.7484                                    \n",
      "[Training] Epoch: 32 [DONE]                                 \n",
      "[Training] Epoch: 32, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 32, LossG: 0.7485                                    \n",
      "[Training] Epoch: 33 [DONE]                                 \n",
      "[Training] Epoch: 33, LossG: 0.7486==================================================================] 100.0%\n",
      "[Validation] Epoch: 33, LossG: 0.7486                                    \n",
      "[Training] Epoch: 34 [DONE]                                 \n",
      "[Training] Epoch: 34, LossG: 0.7481==================================================================] 100.0%\n",
      "[Validation] Epoch: 34, LossG: 0.7481                                    \n",
      "[Training] Epoch: 35 [DONE]                                 \n",
      "[Training] Epoch: 35, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 35, LossG: 0.7485                                    \n",
      "[Training] Epoch: 36 [DONE]                                 \n",
      "[Training] Epoch: 36, LossG: 0.7484==================================================================] 100.0%\n",
      "[Validation] Epoch: 36, LossG: 0.7484                                    \n",
      "[Training] Epoch: 37 [DONE]                                 \n",
      "[Training] Epoch: 37, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 37, LossG: 0.7485                                    \n",
      "[Training] Epoch: 38 [DONE]                                 \n",
      "[Training] Epoch: 38, LossG: 0.7483==================================================================] 100.0%\n",
      "[Validation] Epoch: 38, LossG: 0.7483                                    \n",
      "[Training] Epoch: 39 [DONE]                                 \n",
      "[Training] Epoch: 39, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 39, LossG: 0.7485                                    \n",
      "[Training] Epoch: 40 [DONE]                                 \n",
      "[Training] Epoch: 40, LossG: 0.7482==================================================================] 100.0%\n",
      "[Validation] Epoch: 40, LossG: 0.7482                                    \n",
      "[Training] Epoch: 41 [DONE]                                 \n",
      "[Training] Epoch: 41, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 41, LossG: 0.7485                                    \n",
      "[Training] Epoch: 42 [DONE]                                 \n",
      "[Training] Epoch: 42, LossG: 0.7485==================================================================] 100.0%\n",
      "[Validation] Epoch: 42, LossG: 0.7485                                    \n",
      "[Training] Epoch: 43 [DONE]                                 \n",
      "[Training] Epoch: 43, LossG: 0.7483==================================================================] 100.0%\n",
      "[Validation] Epoch: 43, LossG: 0.7483                                    \n",
      "[Training] Epoch: 44 [DONE]                                 \n",
      "[Training] Epoch: 44, LossG: 0.7484==================================================================] 100.0%\n",
      "[Validation] Epoch: 44, LossG: 0.7484                                    \n",
      "[Training] Epoch: 45 [DONE]                                 \n",
      "[Training] Epoch: 45, LossG: 0.7482==================================================================] 100.0%\n",
      "[Validation] Epoch: 45, LossG: 0.7482                                    \n",
      "[Training] Epoch: 46 [DONE]                                 \n",
      "[Training] Epoch: 46, LossG: 0.7479==================================================================] 100.0%\n",
      "[Validation] Epoch: 46, LossG: 0.7479                                    \n",
      "[Training] Epoch: 47 [DONE]                                 \n",
      "[Training] Epoch: 47, LossG: 0.7482==================================================================] 100.0%\n",
      "[Validation] Epoch: 47, LossG: 0.7482                                    \n",
      "[Training] Epoch: 48 [DONE]                                 \n",
      "[Training] Epoch: 48, LossG: 0.7477==================================================================] 100.0%\n",
      "[Validation] Epoch: 48, LossG: 0.7477                                    \n",
      "[Training] Epoch: 49 [DONE]                                 \n",
      "[Training] Epoch: 49, LossG: 0.7477==================================================================] 100.0%\n",
      "[Validation] Epoch: 49, LossG: 0.7477                                    \n",
      "[Training] Epoch: 50 [DONE]                                 \n",
      "[Training] Epoch: 50, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 50, LossG: 0.7478                                    \n",
      "[Training] Epoch: 51 [DONE]                                 \n",
      "[Training] Epoch: 51, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 51, LossG: 0.7478                                    \n",
      "[Training] Epoch: 52 [DONE]                                 \n",
      "[Training] Epoch: 52, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 52, LossG: 0.7478                                    \n",
      "[Training] Epoch: 53 [DONE]                                 \n",
      "[Training] Epoch: 53, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 53, LossG: 0.7478                                    \n",
      "[Training] Epoch: 54 [DONE]                                 \n",
      "[Training] Epoch: 54, LossG: 0.7475==================================================================] 100.0%\n",
      "[Validation] Epoch: 54, LossG: 0.7475                                    \n",
      "[Training] Epoch: 55 [DONE]                                 \n",
      "[Training] Epoch: 55, LossG: 0.7476==================================================================] 100.0%\n",
      "[Validation] Epoch: 55, LossG: 0.7476                                    \n",
      "[Training] Epoch: 56 [DONE]                                 \n",
      "[Training] Epoch: 56, LossG: 0.7474==================================================================] 100.0%\n",
      "[Validation] Epoch: 56, LossG: 0.7474                                    \n",
      "[Training] Epoch: 57 [DONE]                                 \n",
      "[Training] Epoch: 57, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 57, LossG: 0.7478                                    \n",
      "[Training] Epoch: 58 [DONE]                                 \n",
      "[Training] Epoch: 58, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 58, LossG: 0.7478                                    \n",
      "[Training] Epoch: 59 [DONE]                                 \n",
      "[Training] Epoch: 59, LossG: 0.7475==================================================================] 100.0%\n",
      "[Validation] Epoch: 59, LossG: 0.7475                                    \n",
      "[Training] Epoch: 60 [DONE]                                 \n",
      "[Training] Epoch: 60, LossG: 0.7481==================================================================] 100.0%\n",
      "[Validation] Epoch: 60, LossG: 0.7481                                    \n",
      "[Training] Epoch: 61 [DONE]                                 \n",
      "[Training] Epoch: 61, LossG: 0.7477==================================================================] 100.0%\n",
      "[Validation] Epoch: 61, LossG: 0.7477                                    \n",
      "[Training] Epoch: 62 [DONE]                                 \n",
      "[Training] Epoch: 62, LossG: 0.7477==================================================================] 100.0%\n",
      "[Validation] Epoch: 62, LossG: 0.7477                                    \n",
      "[Training] Epoch: 63 [DONE]                                 \n",
      "[Training] Epoch: 63, LossG: 0.7479==================================================================] 100.0%\n",
      "[Validation] Epoch: 63, LossG: 0.7479                                    \n",
      "[Training] Epoch: 64 [DONE]                                 \n",
      "[Training] Epoch: 64, LossG: 0.7477==================================================================] 100.0%\n",
      "[Validation] Epoch: 64, LossG: 0.7477                                    \n",
      "[Training] Epoch: 65 [DONE]                                 \n",
      "[Training] Epoch: 65, LossG: 0.7480==================================================================] 100.0%\n",
      "[Validation] Epoch: 65, LossG: 0.7480                                    \n",
      "[Training] Epoch: 66 [DONE]                                 \n",
      "[Training] Epoch: 66, LossG: 0.7476==================================================================] 100.0%\n",
      "[Validation] Epoch: 66, LossG: 0.7476                                    \n",
      "[Training] Epoch: 67 [DONE]                                 \n",
      "[Training] Epoch: 67, LossG: 0.7476==================================================================] 100.0%\n",
      "[Validation] Epoch: 67, LossG: 0.7476                                    \n",
      "[Training] Epoch: 68 [DONE]                                 \n",
      "[Training] Epoch: 68, LossG: 0.7476==================================================================] 100.0%\n",
      "[Validation] Epoch: 68, LossG: 0.7476                                    \n",
      "[Training] Epoch: 69 [DONE]                                 \n",
      "[Training] Epoch: 69, LossG: 0.7477==================================================================] 100.0%\n",
      "[Validation] Epoch: 69, LossG: 0.7477                                    \n",
      "[Training] Epoch: 70 [DONE]                                 \n",
      "[Training] Epoch: 70, LossG: 0.7482==================================================================] 100.0%\n",
      "[Validation] Epoch: 70, LossG: 0.7482                                    \n",
      "[Training] Epoch: 71 [DONE]                                 \n",
      "[Training] Epoch: 71, LossG: 0.7476==================================================================] 100.0%\n",
      "[Validation] Epoch: 71, LossG: 0.7476                                    \n",
      "[Training] Epoch: 72 [DONE]                                 \n",
      "[Training] Epoch: 72, LossG: 0.7474==================================================================] 100.0%\n",
      "[Validation] Epoch: 72, LossG: 0.7474                                    \n",
      "[Training] Epoch: 73 [DONE]                                 \n",
      "[Training] Epoch: 73, LossG: 0.7475==================================================================] 100.0%\n",
      "[Validation] Epoch: 73, LossG: 0.7475                                    \n",
      "[Training] Epoch: 74 [DONE]                                 \n",
      "[Training] Epoch: 74, LossG: 0.7475==================================================================] 100.0%\n",
      "[Validation] Epoch: 74, LossG: 0.7475                                    \n",
      "[Training] Epoch: 75 [DONE]                                 \n",
      "[Training] Epoch: 75, LossG: 0.7474==================================================================] 100.0%\n",
      "[Validation] Epoch: 75, LossG: 0.7474                                    \n",
      "[Training] Epoch: 76 [DONE]                                 \n",
      "[Training] Epoch: 76, LossG: 0.7473==================================================================] 100.0%\n",
      "[Validation] Epoch: 76, LossG: 0.7473                                    \n",
      "[Training] Epoch: 77 [DONE]                                 \n",
      "[Training] Epoch: 77, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 77, LossG: 0.7478                                    \n",
      "[Training] Epoch: 78 [DONE]                                 \n",
      "[Training] Epoch: 78, LossG: 0.7478==================================================================] 100.0%\n",
      "[Validation] Epoch: 78, LossG: 0.7478                                    \n",
      "[Training] Epoch: 79 [DONE]                                 \n",
      "[Training] Epoch: 79, LossG: 0.7476==================================================================] 100.0%\n",
      "[Validation] Epoch: 79, LossG: 0.7476                                    \n",
      "[Training] Epoch: 80 [DONE]                                 \n",
      "[Training] Epoch: 80, LossG: 0.7475==================================================================] 100.0%\n",
      "[Validation] Epoch: 80, LossG: 0.7475                                    \n",
      "[Training] Epoch: 81 [DONE]                                 \n",
      "[Training] Epoch: 81, LossG: 0.7474==================================================================] 100.0%\n",
      "[Validation] Epoch: 81, LossG: 0.7474                                    \n",
      "[Training] Epoch: 82 [DONE]                                 \n",
      "[Training] Epoch: 82, LossG: 0.7472==================================================================] 100.0%\n",
      "[Validation] Epoch: 82, LossG: 0.7472                                    \n",
      "[Training] Epoch: 83 [DONE]                                 \n",
      "[Training] Epoch: 83, LossG: 0.7471==================================================================] 100.0%\n",
      "[Validation] Epoch: 83, LossG: 0.7471                                    \n",
      "[Training] Epoch: 84 [DONE]                                 \n",
      "[Training] Epoch: 84, LossG: 0.7472==================================================================] 100.0%\n",
      "[Validation] Epoch: 84, LossG: 0.7472                                    \n",
      "[Training] Epoch: 85 [DONE]                                 \n",
      "[Training] Epoch: 85, LossG: 0.7474==================================================================] 100.0%\n",
      "[Validation] Epoch: 85, LossG: 0.7474                                    \n",
      "[Training] Epoch: 86 [DONE]                                 \n",
      "[Training] Epoch: 86, LossG: 0.7473==================================================================] 100.0%\n",
      "[Validation] Epoch: 86, LossG: 0.7473                                    \n",
      "[Training] Epoch: 87 [DONE]                                 \n",
      "[Training] Epoch: 87, LossG: 0.7473==================================================================] 100.0%\n",
      "[Validation] Epoch: 87, LossG: 0.7473                                    \n",
      "[Training] Epoch: 88 [DONE]                                 \n",
      "[Training] Epoch: 88, LossG: 0.7472==================================================================] 100.0%\n",
      "[Validation] Epoch: 88, LossG: 0.7472                                    \n",
      "[Training] Epoch: 89 [DONE]                                 \n",
      "[Training] Epoch: 89, LossG: 0.7472==================================================================] 100.0%\n",
      "[Validation] Epoch: 89, LossG: 0.7472                                    \n",
      "[Training] Epoch: 90 [DONE]                                 \n",
      "[Training] Epoch: 90, LossG: 0.7470==================================================================] 100.0%\n",
      "[Validation] Epoch: 90, LossG: 0.7470                                    \n",
      "[Training] Epoch: 91 [DONE]                                 \n",
      "[Training] Epoch: 91, LossG: 0.7471==================================================================] 100.0%\n",
      "[Validation] Epoch: 91, LossG: 0.7471                                    \n",
      "[Training] Epoch: 92 [DONE]                                 \n",
      "[Training] Epoch: 92, LossG: 0.7473==================================================================] 100.0%\n",
      "[Validation] Epoch: 92, LossG: 0.7473                                    \n",
      "[Training] Epoch: 93 [DONE]                                 \n",
      "[Training] Epoch: 93, LossG: 0.7472==================================================================] 100.0%\n",
      "[Validation] Epoch: 93, LossG: 0.7472                                    \n",
      "[Training] Epoch: 94 [DONE]                                 \n",
      "[Training] Epoch: 94, LossG: 0.7472==================================================================] 100.0%\n",
      "[Validation] Epoch: 94, LossG: 0.7472                                    \n",
      "[Training] Epoch: 95 [DONE]                                 \n",
      "[Training] Epoch: 95, LossG: 0.7477==================================================================] 100.0%\n",
      "[Validation] Epoch: 95, LossG: 0.7477                                    \n",
      "[Training] Epoch: 96 [DONE]                                 \n",
      "[Training] Epoch: 96, LossG: 0.7474==================================================================] 100.0%\n",
      "[Validation] Epoch: 96, LossG: 0.7474                                    \n",
      "[Training] Epoch: 97 [DONE]                                 \n",
      "[Training] Epoch: 97, LossG: 0.7473==================================================================] 100.0%\n",
      "[Validation] Epoch: 97, LossG: 0.7473                                    \n",
      "[Training] Epoch: 98 [DONE]                                 \n",
      "[Training] Epoch: 98, LossG: 0.7475==================================================================] 100.0%\n",
      "[Validation] Epoch: 98, LossG: 0.7475                                    \n",
      "[Training] Epoch: 99 [DONE]                                 \n",
      "[Training] Epoch: 99, LossG: 0.7473==================================================================] 100.0%\n",
      "[Validation] Epoch: 99, LossG: 0.7473                                    \n",
      "[Training] Epoch: 100 [DONE]                                 \n",
      "[Training] Epoch: 100, LossG: 0.7472=================================================================] 100.0%\n",
      "[Validation] Epoch: 100, LossG: 0.7472                                  \n",
      "[Training] Epoch: 101 [DONE]                                 \n",
      "[Training] Epoch: 101, LossG: 0.7472=================================================================] 100.0%\n",
      "[Validation] Epoch: 101, LossG: 0.7472                                  \n",
      "[Training] Epoch: 102 [DONE]                                 \n",
      "[Training] Epoch: 102, LossG: 0.7475=================================================================] 100.0%\n",
      "[Validation] Epoch: 102, LossG: 0.7475                                  \n",
      "[Training] Epoch: 103 [DONE]                                 \n",
      "[Training] Epoch: 103, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 103, LossG: 0.7471                                  \n",
      "[Training] Epoch: 104 [DONE]                                 \n",
      "[Training] Epoch: 104, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 104, LossG: 0.7468                                  \n",
      "[Training] Epoch: 105 [DONE]                                 \n",
      "[Training] Epoch: 105, LossG: 0.7472=================================================================] 100.0%\n",
      "[Validation] Epoch: 105, LossG: 0.7472                                  \n",
      "[Training] Epoch: 106 [DONE]                                 \n",
      "[Training] Epoch: 106, LossG: 0.7473=================================================================] 100.0%\n",
      "[Validation] Epoch: 106, LossG: 0.7473                                  \n",
      "[Training] Epoch: 107 [DONE]                                 \n",
      "[Training] Epoch: 107, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 107, LossG: 0.7470                                  \n",
      "[Training] Epoch: 108 [DONE]                                 \n",
      "[Training] Epoch: 108, LossG: 0.7474=================================================================] 100.0%\n",
      "[Validation] Epoch: 108, LossG: 0.7474                                  \n",
      "[Training] Epoch: 109 [DONE]                                 \n",
      "[Training] Epoch: 109, LossG: 0.7473=================================================================] 100.0%\n",
      "[Validation] Epoch: 109, LossG: 0.7473                                  \n",
      "[Training] Epoch: 110 [DONE]                                 \n",
      "[Training] Epoch: 110, LossG: 0.7472=================================================================] 100.0%\n",
      "[Validation] Epoch: 110, LossG: 0.7472                                  \n",
      "[Training] Epoch: 111 [DONE]                                 \n",
      "[Training] Epoch: 111, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 111, LossG: 0.7470                                  \n",
      "[Training] Epoch: 112 [DONE]                                 \n",
      "[Training] Epoch: 112, LossG: 0.7472=================================================================] 100.0%\n",
      "[Validation] Epoch: 112, LossG: 0.7472                                  \n",
      "[Training] Epoch: 113 [DONE]                                 \n",
      "[Training] Epoch: 113, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 113, LossG: 0.7470                                  \n",
      "[Training] Epoch: 114 [DONE]                                 \n",
      "[Training] Epoch: 114, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 114, LossG: 0.7469                                  \n",
      "[Training] Epoch: 115 [DONE]                                 \n",
      "[Training] Epoch: 115, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 115, LossG: 0.7471                                  \n",
      "[Training] Epoch: 116 [DONE]                                 \n",
      "[Training] Epoch: 116, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 116, LossG: 0.7470                                  \n",
      "[Training] Epoch: 117 [DONE]                                 \n",
      "[Training] Epoch: 117, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 117, LossG: 0.7471                                  \n",
      "[Training] Epoch: 118 [DONE]                                 \n",
      "[Training] Epoch: 118, LossG: 0.7472=================================================================] 100.0%\n",
      "[Validation] Epoch: 118, LossG: 0.7472                                  \n",
      "[Training] Epoch: 119 [DONE]                                 \n",
      "[Training] Epoch: 119, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 119, LossG: 0.7469                                  \n",
      "[Training] Epoch: 120 [DONE]                                 \n",
      "[Training] Epoch: 120, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 120, LossG: 0.7470                                  \n",
      "[Training] Epoch: 121 [DONE]                                 \n",
      "[Training] Epoch: 121, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 121, LossG: 0.7468                                  \n",
      "[Training] Epoch: 122 [DONE]                                 \n",
      "[Training] Epoch: 122, LossG: 0.7473=================================================================] 100.0%\n",
      "[Validation] Epoch: 122, LossG: 0.7473                                  \n",
      "[Training] Epoch: 123 [DONE]                                 \n",
      "[Training] Epoch: 123, LossG: 0.7474=================================================================] 100.0%\n",
      "[Validation] Epoch: 123, LossG: 0.7474                                  \n",
      "[Training] Epoch: 124 [DONE]                                 \n",
      "[Training] Epoch: 124, LossG: 0.7474=================================================================] 100.0%\n",
      "[Validation] Epoch: 124, LossG: 0.7474                                  \n",
      "[Training] Epoch: 125 [DONE]                                 \n",
      "[Training] Epoch: 125, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 125, LossG: 0.7469                                  \n",
      "[Training] Epoch: 126 [DONE]                                 \n",
      "[Training] Epoch: 126, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 126, LossG: 0.7468                                  \n",
      "[Training] Epoch: 127 [DONE]                                 \n",
      "[Training] Epoch: 127, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 127, LossG: 0.7470                                  \n",
      "[Training] Epoch: 128 [DONE]                                 \n",
      "[Training] Epoch: 128, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 128, LossG: 0.7470                                  \n",
      "[Training] Epoch: 129 [DONE]                                 \n",
      "[Training] Epoch: 129, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 129, LossG: 0.7468                                  \n",
      "[Training] Epoch: 130 [DONE]                                 \n",
      "[Training] Epoch: 130, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 130, LossG: 0.7468                                  \n",
      "[Training] Epoch: 131 [DONE]                                 \n",
      "[Training] Epoch: 131, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 131, LossG: 0.7471                                  \n",
      "[Training] Epoch: 132 [DONE]                                 \n",
      "[Training] Epoch: 132, LossG: 0.7473=================================================================] 100.0%\n",
      "[Validation] Epoch: 132, LossG: 0.7473                                  \n",
      "[Training] Epoch: 133 [DONE]                                 \n",
      "[Training] Epoch: 133, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 133, LossG: 0.7471                                  \n",
      "[Training] Epoch: 134 [DONE]                                 \n",
      "[Training] Epoch: 134, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 134, LossG: 0.7470                                  \n",
      "[Training] Epoch: 135 [DONE]                                 \n",
      "[Training] Epoch: 135, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 135, LossG: 0.7469                                  \n",
      "[Training] Epoch: 136 [DONE]                                 \n",
      "[Training] Epoch: 136, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 136, LossG: 0.7469                                  \n",
      "[Training] Epoch: 137 [DONE]                                 \n",
      "[Training] Epoch: 137, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 137, LossG: 0.7471                                  \n",
      "[Training] Epoch: 138 [DONE]                                 \n",
      "[Training] Epoch: 138, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 138, LossG: 0.7471                                  \n",
      "[Training] Epoch: 139 [DONE]                                 \n",
      "[Training] Epoch: 139, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 139, LossG: 0.7468                                  \n",
      "[Training] Epoch: 140 [DONE]                                 \n",
      "[Training] Epoch: 140, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 140, LossG: 0.7469                                  \n",
      "[Training] Epoch: 141 [DONE]                                 \n",
      "[Training] Epoch: 141, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 141, LossG: 0.7469                                  \n",
      "[Training] Epoch: 142 [DONE]                                 \n",
      "[Training] Epoch: 142, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 142, LossG: 0.7468                                  \n",
      "[Training] Epoch: 143 [DONE]                                 \n",
      "[Training] Epoch: 143, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 143, LossG: 0.7468                                  \n",
      "[Training] Epoch: 144 [DONE]                                 \n",
      "[Training] Epoch: 144, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 144, LossG: 0.7467                                  \n",
      "[Training] Epoch: 145 [DONE]                                 \n",
      "[Training] Epoch: 145, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 145, LossG: 0.7467                                  \n",
      "[Training] Epoch: 146 [DONE]                                 \n",
      "[Training] Epoch: 146, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 146, LossG: 0.7466                                  \n",
      "[Training] Epoch: 147 [DONE]                                 \n",
      "[Training] Epoch: 147, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 147, LossG: 0.7467                                  \n",
      "[Training] Epoch: 148 [DONE]                                 \n",
      "[Training] Epoch: 148, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 148, LossG: 0.7467                                  \n",
      "[Training] Epoch: 149 [DONE]                                 \n",
      "[Training] Epoch: 149, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 149, LossG: 0.7467                                  \n",
      "[Training] Epoch: 150 [DONE]                                 \n",
      "[Training] Epoch: 150, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 150, LossG: 0.7469                                  \n",
      "[Training] Epoch: 151 [DONE]                                 \n",
      "[Training] Epoch: 151, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 151, LossG: 0.7467                                  \n",
      "[Training] Epoch: 152 [DONE]                                 \n",
      "[Training] Epoch: 152, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 152, LossG: 0.7471                                  \n",
      "[Training] Epoch: 153 [DONE]                                 \n",
      "[Training] Epoch: 153, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 153, LossG: 0.7469                                  \n",
      "[Training] Epoch: 154 [DONE]                                 \n",
      "[Training] Epoch: 154, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 154, LossG: 0.7468                                  \n",
      "[Training] Epoch: 155 [DONE]                                 \n",
      "[Training] Epoch: 155, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 155, LossG: 0.7469                                  \n",
      "[Training] Epoch: 156 [DONE]                                 \n",
      "[Training] Epoch: 156, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 156, LossG: 0.7467                                  \n",
      "[Training] Epoch: 157 [DONE]                                 \n",
      "[Training] Epoch: 157, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 157, LossG: 0.7468                                  \n",
      "[Training] Epoch: 158 [DONE]                                 \n",
      "[Training] Epoch: 158, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 158, LossG: 0.7468                                  \n",
      "[Training] Epoch: 159 [DONE]                                 \n",
      "[Training] Epoch: 159, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 159, LossG: 0.7468                                  \n",
      "[Training] Epoch: 160 [DONE]                                 \n",
      "[Training] Epoch: 160, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 160, LossG: 0.7468                                  \n",
      "[Training] Epoch: 161 [DONE]                                 \n",
      "[Training] Epoch: 161, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 161, LossG: 0.7470                                  \n",
      "[Training] Epoch: 162 [DONE]                                 \n",
      "[Training] Epoch: 162, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 162, LossG: 0.7471                                  \n",
      "[Training] Epoch: 163 [DONE]                                 \n",
      "[Training] Epoch: 163, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 163, LossG: 0.7470                                  \n",
      "[Training] Epoch: 164 [DONE]                                 \n",
      "[Training] Epoch: 164, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 164, LossG: 0.7469                                  \n",
      "[Training] Epoch: 165 [DONE]                                 \n",
      "[Training] Epoch: 165, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 165, LossG: 0.7470                                  \n",
      "[Training] Epoch: 166 [DONE]                                 \n",
      "[Training] Epoch: 166, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 166, LossG: 0.7469                                  \n",
      "[Training] Epoch: 167 [DONE]                                 \n",
      "[Training] Epoch: 167, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 167, LossG: 0.7466                                  \n",
      "[Training] Epoch: 168 [DONE]                                 \n",
      "[Training] Epoch: 168, LossG: 0.7474=================================================================] 100.0%\n",
      "[Validation] Epoch: 168, LossG: 0.7474                                  \n",
      "[Training] Epoch: 169 [DONE]                                 \n",
      "[Training] Epoch: 169, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 169, LossG: 0.7469                                  \n",
      "[Training] Epoch: 170 [DONE]                                 \n",
      "[Training] Epoch: 170, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 170, LossG: 0.7467                                  \n",
      "[Training] Epoch: 171 [DONE]                                 \n",
      "[Training] Epoch: 171, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 171, LossG: 0.7467                                  \n",
      "[Training] Epoch: 172 [DONE]                                 \n",
      "[Training] Epoch: 172, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 172, LossG: 0.7467                                  \n",
      "[Training] Epoch: 173 [DONE]                                 \n",
      "[Training] Epoch: 173, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 173, LossG: 0.7467                                  \n",
      "[Training] Epoch: 174 [DONE]                                 \n",
      "[Training] Epoch: 174, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 174, LossG: 0.7467                                  \n",
      "[Training] Epoch: 175 [DONE]                                 \n",
      "[Training] Epoch: 175, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 175, LossG: 0.7467                                  \n",
      "[Training] Epoch: 176 [DONE]                                 \n",
      "[Training] Epoch: 176, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 176, LossG: 0.7466                                  \n",
      "[Training] Epoch: 177 [DONE]                                 \n",
      "[Training] Epoch: 177, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 177, LossG: 0.7466                                  \n",
      "[Training] Epoch: 178 [DONE]                                 \n",
      "[Training] Epoch: 178, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 178, LossG: 0.7467                                  \n",
      "[Training] Epoch: 179 [DONE]                                 \n",
      "[Training] Epoch: 179, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 179, LossG: 0.7466                                  \n",
      "[Training] Epoch: 180 [DONE]                                 \n",
      "[Training] Epoch: 180, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 180, LossG: 0.7467                                  \n",
      "[Training] Epoch: 181 [DONE]                                 \n",
      "[Training] Epoch: 181, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 181, LossG: 0.7466                                  \n",
      "[Training] Epoch: 182 [DONE]                                 \n",
      "[Training] Epoch: 182, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 182, LossG: 0.7466                                  \n",
      "[Training] Epoch: 183 [DONE]                                 \n",
      "[Training] Epoch: 183, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 183, LossG: 0.7469                                  \n",
      "[Training] Epoch: 184 [DONE]                                 \n",
      "[Training] Epoch: 184, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 184, LossG: 0.7466                                  \n",
      "[Training] Epoch: 185 [DONE]                                 \n",
      "[Training] Epoch: 185, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 185, LossG: 0.7468                                  \n",
      "[Training] Epoch: 186 [DONE]                                 \n",
      "[Training] Epoch: 186, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 186, LossG: 0.7466                                  \n",
      "[Training] Epoch: 187 [DONE]                                 \n",
      "[Training] Epoch: 187, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 187, LossG: 0.7466                                  \n",
      "[Training] Epoch: 188 [DONE]                                 \n",
      "[Training] Epoch: 188, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 188, LossG: 0.7467                                  \n",
      "[Training] Epoch: 189 [DONE]                                 \n",
      "[Training] Epoch: 189, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 189, LossG: 0.7466                                  \n",
      "[Training] Epoch: 190 [DONE]                                 \n",
      "[Training] Epoch: 190, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 190, LossG: 0.7466                                  \n",
      "[Training] Epoch: 191 [DONE]                                 \n",
      "[Training] Epoch: 191, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 191, LossG: 0.7464                                  \n",
      "[Training] Epoch: 192 [DONE]                                 \n",
      "[Training] Epoch: 192, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 192, LossG: 0.7466                                  \n",
      "[Training] Epoch: 193 [DONE]                                 \n",
      "[Training] Epoch: 193, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 193, LossG: 0.7465                                  \n",
      "[Training] Epoch: 194 [DONE]                                 \n",
      "[Training] Epoch: 194, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 194, LossG: 0.7467                                  \n",
      "[Training] Epoch: 195 [DONE]                                 \n",
      "[Training] Epoch: 195, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 195, LossG: 0.7467                                  \n",
      "[Training] Epoch: 196 [DONE]                                 \n",
      "[Training] Epoch: 196, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 196, LossG: 0.7463                                  \n",
      "[Training] Epoch: 197 [DONE]                                 \n",
      "[Training] Epoch: 197, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 197, LossG: 0.7464                                  \n",
      "[Training] Epoch: 198 [DONE]                                 \n",
      "[Training] Epoch: 198, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 198, LossG: 0.7465                                  \n",
      "[Training] Epoch: 199 [DONE]                                 \n",
      "[Training] Epoch: 199, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 199, LossG: 0.7464                                  \n",
      "[Training] Epoch: 200 [DONE]                                 \n",
      "[Training] Epoch: 200, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 200, LossG: 0.7465                                  \n",
      "[Training] Epoch: 201 [DONE]                                 \n",
      "[Training] Epoch: 201, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 201, LossG: 0.7468                                  \n",
      "[Training] Epoch: 202 [DONE]                                 \n",
      "[Training] Epoch: 202, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 202, LossG: 0.7466                                  \n",
      "[Training] Epoch: 203 [DONE]                                 \n",
      "[Training] Epoch: 203, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 203, LossG: 0.7470                                  \n",
      "[Training] Epoch: 204 [DONE]                                 \n",
      "[Training] Epoch: 204, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 204, LossG: 0.7467                                  \n",
      "[Training] Epoch: 205 [DONE]                                 \n",
      "[Training] Epoch: 205, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 205, LossG: 0.7469                                  \n",
      "[Training] Epoch: 206 [DONE]                                 \n",
      "[Training] Epoch: 206, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 206, LossG: 0.7471                                  \n",
      "[Training] Epoch: 207 [DONE]                                 \n",
      "[Training] Epoch: 207, LossG: 0.7471=================================================================] 100.0%\n",
      "[Validation] Epoch: 207, LossG: 0.7471                                  \n",
      "[Training] Epoch: 208 [DONE]                                 \n",
      "[Training] Epoch: 208, LossG: 0.7473=================================================================] 100.0%\n",
      "[Validation] Epoch: 208, LossG: 0.7473                                  \n",
      "[Training] Epoch: 209 [DONE]                                 \n",
      "[Training] Epoch: 209, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 209, LossG: 0.7470                                  \n",
      "[Training] Epoch: 210 [DONE]                                 \n",
      "[Training] Epoch: 210, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 210, LossG: 0.7467                                  \n",
      "[Training] Epoch: 211 [DONE]                                 \n",
      "[Training] Epoch: 211, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 211, LossG: 0.7465                                  \n",
      "[Training] Epoch: 212 [DONE]                                 \n",
      "[Training] Epoch: 212, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 212, LossG: 0.7463                                  \n",
      "[Training] Epoch: 213 [DONE]                                 \n",
      "[Training] Epoch: 213, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 213, LossG: 0.7465                                  \n",
      "[Training] Epoch: 214 [DONE]                                 \n",
      "[Training] Epoch: 214, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 214, LossG: 0.7465                                  \n",
      "[Training] Epoch: 215 [DONE]                                 \n",
      "[Training] Epoch: 215, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 215, LossG: 0.7465                                  \n",
      "[Training] Epoch: 216 [DONE]                                 \n",
      "[Training] Epoch: 216, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 216, LossG: 0.7464                                  \n",
      "[Training] Epoch: 217 [DONE]                                 \n",
      "[Training] Epoch: 217, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 217, LossG: 0.7464                                  \n",
      "[Training] Epoch: 218 [DONE]                                 \n",
      "[Training] Epoch: 218, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 218, LossG: 0.7464                                  \n",
      "[Training] Epoch: 219 [DONE]                                 \n",
      "[Training] Epoch: 219, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 219, LossG: 0.7464                                  \n",
      "[Training] Epoch: 220 [DONE]                                 \n",
      "[Training] Epoch: 220, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 220, LossG: 0.7463                                  \n",
      "[Training] Epoch: 221 [DONE]                                 \n",
      "[Training] Epoch: 221, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 221, LossG: 0.7465                                  \n",
      "[Training] Epoch: 222 [DONE]                                 \n",
      "[Training] Epoch: 222, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 222, LossG: 0.7463                                  \n",
      "[Training] Epoch: 223 [DONE]                                 \n",
      "[Training] Epoch: 223, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 223, LossG: 0.7463                                  \n",
      "[Training] Epoch: 224 [DONE]                                 \n",
      "[Training] Epoch: 224, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 224, LossG: 0.7463                                  \n",
      "[Training] Epoch: 225 [DONE]                                 \n",
      "[Training] Epoch: 225, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 225, LossG: 0.7463                                  \n",
      "[Training] Epoch: 226 [DONE]                                 \n",
      "[Training] Epoch: 226, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 226, LossG: 0.7462                                  \n",
      "[Training] Epoch: 227 [DONE]                                 \n",
      "[Training] Epoch: 227, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 227, LossG: 0.7462                                  \n",
      "[Training] Epoch: 228 [DONE]                                 \n",
      "[Training] Epoch: 228, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 228, LossG: 0.7464                                  \n",
      "[Training] Epoch: 229 [DONE]                                 \n",
      "[Training] Epoch: 229, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 229, LossG: 0.7462                                  \n",
      "[Training] Epoch: 230 [DONE]                                 \n",
      "[Training] Epoch: 230, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 230, LossG: 0.7462                                  \n",
      "[Training] Epoch: 231 [DONE]                                 \n",
      "[Training] Epoch: 231, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 231, LossG: 0.7462                                  \n",
      "[Training] Epoch: 232 [DONE]                                 \n",
      "[Training] Epoch: 232, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 232, LossG: 0.7461                                  \n",
      "[Training] Epoch: 233 [DONE]                                 \n",
      "[Training] Epoch: 233, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 233, LossG: 0.7464                                  \n",
      "[Training] Epoch: 234 [DONE]                                 \n",
      "[Training] Epoch: 234, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 234, LossG: 0.7463                                  \n",
      "[Training] Epoch: 235 [DONE]                                 \n",
      "[Training] Epoch: 235, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 235, LossG: 0.7463                                  \n",
      "[Training] Epoch: 236 [DONE]                                 \n",
      "[Training] Epoch: 236, LossG: 0.7474=================================================================] 100.0%\n",
      "[Validation] Epoch: 236, LossG: 0.7474                                  \n",
      "[Training] Epoch: 237 [DONE]                                 \n",
      "[Training] Epoch: 237, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 237, LossG: 0.7470                                  \n",
      "[Training] Epoch: 238 [DONE]                                 \n",
      "[Training] Epoch: 238, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 238, LossG: 0.7469                                  \n",
      "[Training] Epoch: 239 [DONE]                                 \n",
      "[Training] Epoch: 239, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 239, LossG: 0.7465                                  \n",
      "[Training] Epoch: 240 [DONE]                                 \n",
      "[Training] Epoch: 240, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 240, LossG: 0.7464                                  \n",
      "[Training] Epoch: 241 [DONE]                                 \n",
      "[Training] Epoch: 241, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 241, LossG: 0.7464                                  \n",
      "[Training] Epoch: 242 [DONE]                                 \n",
      "[Training] Epoch: 242, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 242, LossG: 0.7465                                  \n",
      "[Training] Epoch: 243 [DONE]                                 \n",
      "[Training] Epoch: 243, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 243, LossG: 0.7465                                  \n",
      "[Training] Epoch: 244 [DONE]                                 \n",
      "[Training] Epoch: 244, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 244, LossG: 0.7462                                  \n",
      "[Training] Epoch: 245 [DONE]                                 \n",
      "[Training] Epoch: 245, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 245, LossG: 0.7464                                  \n",
      "[Training] Epoch: 246 [DONE]                                 \n",
      "[Training] Epoch: 246, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 246, LossG: 0.7463                                  \n",
      "[Training] Epoch: 247 [DONE]                                 \n",
      "[Training] Epoch: 247, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 247, LossG: 0.7465                                  \n",
      "[Training] Epoch: 248 [DONE]                                 \n",
      "[Training] Epoch: 248, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 248, LossG: 0.7466                                  \n",
      "[Training] Epoch: 249 [DONE]                                 \n",
      "[Training] Epoch: 249, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 249, LossG: 0.7466                                  \n",
      "[Training] Epoch: 250 [DONE]                                 \n",
      "[Training] Epoch: 250, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 250, LossG: 0.7467                                  \n",
      "[Training] Epoch: 251 [DONE]                                 \n",
      "[Training] Epoch: 251, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 251, LossG: 0.7466                                  \n",
      "[Training] Epoch: 252 [DONE]                                 \n",
      "[Training] Epoch: 252, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 252, LossG: 0.7467                                  \n",
      "[Training] Epoch: 253 [DONE]                                 \n",
      "[Training] Epoch: 253, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 253, LossG: 0.7466                                  \n",
      "[Training] Epoch: 254 [DONE]                                 \n",
      "[Training] Epoch: 254, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 254, LossG: 0.7464                                  \n",
      "[Training] Epoch: 255 [DONE]                                 \n",
      "[Training] Epoch: 255, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 255, LossG: 0.7467                                  \n",
      "[Training] Epoch: 256 [DONE]                                 \n",
      "[Training] Epoch: 256, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 256, LossG: 0.7464                                  \n",
      "[Training] Epoch: 257 [DONE]                                 \n",
      "[Training] Epoch: 257, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 257, LossG: 0.7465                                  \n",
      "[Training] Epoch: 258 [DONE]                                 \n",
      "[Training] Epoch: 258, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 258, LossG: 0.7466                                  \n",
      "[Training] Epoch: 259 [DONE]                                 \n",
      "[Training] Epoch: 259, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 259, LossG: 0.7465                                  \n",
      "[Training] Epoch: 260 [DONE]                                 \n",
      "[Training] Epoch: 260, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 260, LossG: 0.7463                                  \n",
      "[Training] Epoch: 261 [DONE]                                 \n",
      "[Training] Epoch: 261, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 261, LossG: 0.7464                                  \n",
      "[Training] Epoch: 262 [DONE]                                 \n",
      "[Training] Epoch: 262, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 262, LossG: 0.7463                                  \n",
      "[Training] Epoch: 263 [DONE]                                 \n",
      "[Training] Epoch: 263, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 263, LossG: 0.7463                                  \n",
      "[Training] Epoch: 264 [DONE]                                 \n",
      "[Training] Epoch: 264, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 264, LossG: 0.7463                                  \n",
      "[Training] Epoch: 265 [DONE]                                 \n",
      "[Training] Epoch: 265, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 265, LossG: 0.7463                                  \n",
      "[Training] Epoch: 266 [DONE]                                 \n",
      "[Training] Epoch: 266, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 266, LossG: 0.7462                                  \n",
      "[Training] Epoch: 267 [DONE]                                 \n",
      "[Training] Epoch: 267, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 267, LossG: 0.7463                                  \n",
      "[Training] Epoch: 268 [DONE]                                 \n",
      "[Training] Epoch: 268, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 268, LossG: 0.7462                                  \n",
      "[Training] Epoch: 269 [DONE]                                 \n",
      "[Training] Epoch: 269, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 269, LossG: 0.7463                                  \n",
      "[Training] Epoch: 270 [DONE]                                 \n",
      "[Training] Epoch: 270, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 270, LossG: 0.7461                                  \n",
      "[Training] Epoch: 271 [DONE]                                 \n",
      "[Training] Epoch: 271, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 271, LossG: 0.7462                                  \n",
      "[Training] Epoch: 272 [DONE]                                 \n",
      "[Training] Epoch: 272, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 272, LossG: 0.7462                                  \n",
      "[Training] Epoch: 273 [DONE]                                 \n",
      "[Training] Epoch: 273, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 273, LossG: 0.7462                                  \n",
      "[Training] Epoch: 274 [DONE]                                 \n",
      "[Training] Epoch: 274, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 274, LossG: 0.7461                                  \n",
      "[Training] Epoch: 275 [DONE]                                 \n",
      "[Training] Epoch: 275, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 275, LossG: 0.7461                                  \n",
      "[Training] Epoch: 276 [DONE]                                 \n",
      "[Training] Epoch: 276, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 276, LossG: 0.7462                                  \n",
      "[Training] Epoch: 277 [DONE]                                 \n",
      "[Training] Epoch: 277, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 277, LossG: 0.7462                                  \n",
      "[Training] Epoch: 278 [DONE]                                 \n",
      "[Training] Epoch: 278, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 278, LossG: 0.7463                                  \n",
      "[Training] Epoch: 279 [DONE]                                 \n",
      "[Training] Epoch: 279, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 279, LossG: 0.7463                                  \n",
      "[Training] Epoch: 280 [DONE]                                 \n",
      "[Training] Epoch: 280, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 280, LossG: 0.7462                                  \n",
      "[Training] Epoch: 281 [DONE]                                 \n",
      "[Training] Epoch: 281, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 281, LossG: 0.7464                                  \n",
      "[Training] Epoch: 282 [DONE]                                 \n",
      "[Training] Epoch: 282, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 282, LossG: 0.7463                                  \n",
      "[Training] Epoch: 283 [DONE]                                 \n",
      "[Training] Epoch: 283, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 283, LossG: 0.7463                                  \n",
      "[Training] Epoch: 284 [DONE]                                 \n",
      "[Training] Epoch: 284, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 284, LossG: 0.7462                                  \n",
      "[Training] Epoch: 285 [DONE]                                 \n",
      "[Training] Epoch: 285, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 285, LossG: 0.7462                                  \n",
      "[Training] Epoch: 286 [DONE]                                 \n",
      "[Training] Epoch: 286, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 286, LossG: 0.7462                                  \n",
      "[Training] Epoch: 287 [DONE]                                 \n",
      "[Training] Epoch: 287, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 287, LossG: 0.7464                                  \n",
      "[Training] Epoch: 288 [DONE]                                 \n",
      "[Training] Epoch: 288, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 288, LossG: 0.7462                                  \n",
      "[Training] Epoch: 289 [DONE]                                 \n",
      "[Training] Epoch: 289, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 289, LossG: 0.7460                                  \n",
      "[Training] Epoch: 290 [DONE]                                 \n",
      "[Training] Epoch: 290, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 290, LossG: 0.7461                                  \n",
      "[Training] Epoch: 291 [DONE]                                 \n",
      "[Training] Epoch: 291, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 291, LossG: 0.7461                                  \n",
      "[Training] Epoch: 292 [DONE]                                 \n",
      "[Training] Epoch: 292, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 292, LossG: 0.7462                                  \n",
      "[Training] Epoch: 293 [DONE]                                 \n",
      "[Training] Epoch: 293, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 293, LossG: 0.7462                                  \n",
      "[Training] Epoch: 294 [DONE]                                 \n",
      "[Training] Epoch: 294, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 294, LossG: 0.7463                                  \n",
      "[Training] Epoch: 295 [DONE]                                 \n",
      "[Training] Epoch: 295, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 295, LossG: 0.7463                                  \n",
      "[Training] Epoch: 296 [DONE]                                 \n",
      "[Training] Epoch: 296, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 296, LossG: 0.7462                                  \n",
      "[Training] Epoch: 297 [DONE]                                 \n",
      "[Training] Epoch: 297, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 297, LossG: 0.7462                                  \n",
      "[Training] Epoch: 298 [DONE]                                 \n",
      "[Training] Epoch: 298, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 298, LossG: 0.7464                                  \n",
      "[Training] Epoch: 299 [DONE]                                 \n",
      "[Training] Epoch: 299, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 299, LossG: 0.7462                                  \n",
      "[Training] Epoch: 300 [DONE]                                 \n",
      "[Training] Epoch: 300, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 300, LossG: 0.7465                                  \n",
      "[Training] Epoch: 301 [DONE]                                 \n",
      "[Training] Epoch: 301, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 301, LossG: 0.7464                                  \n",
      "[Training] Epoch: 302 [DONE]                                 \n",
      "[Training] Epoch: 302, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 302, LossG: 0.7464                                  \n",
      "[Training] Epoch: 303 [DONE]                                 \n",
      "[Training] Epoch: 303, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 303, LossG: 0.7463                                  \n",
      "[Training] Epoch: 304 [DONE]                                 \n",
      "[Training] Epoch: 304, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 304, LossG: 0.7461                                  \n",
      "[Training] Epoch: 305 [DONE]                                 \n",
      "[Training] Epoch: 305, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 305, LossG: 0.7462                                  \n",
      "[Training] Epoch: 306 [DONE]                                 \n",
      "[Training] Epoch: 306, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 306, LossG: 0.7462                                  \n",
      "[Training] Epoch: 307 [DONE]                                 \n",
      "[Training] Epoch: 307, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 307, LossG: 0.7461                                  \n",
      "[Training] Epoch: 308 [DONE]                                 \n",
      "[Training] Epoch: 308, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 308, LossG: 0.7462                                  \n",
      "[Training] Epoch: 309 [DONE]                                 \n",
      "[Training] Epoch: 309, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 309, LossG: 0.7462                                  \n",
      "[Training] Epoch: 310 [DONE]                                 \n",
      "[Training] Epoch: 310, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 310, LossG: 0.7461                                  \n",
      "[Training] Epoch: 311 [DONE]                                 \n",
      "[Training] Epoch: 311, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 311, LossG: 0.7460                                  \n",
      "[Training] Epoch: 312 [DONE]                                 \n",
      "[Training] Epoch: 312, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 312, LossG: 0.7461                                  \n",
      "[Training] Epoch: 313 [DONE]                                 \n",
      "[Training] Epoch: 313, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 313, LossG: 0.7461                                  \n",
      "[Training] Epoch: 314 [DONE]                                 \n",
      "[Training] Epoch: 314, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 314, LossG: 0.7461                                  \n",
      "[Training] Epoch: 315 [DONE]                                 \n",
      "[Training] Epoch: 315, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 315, LossG: 0.7461                                  \n",
      "[Training] Epoch: 316 [DONE]                                 \n",
      "[Training] Epoch: 316, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 316, LossG: 0.7460                                  \n",
      "[Training] Epoch: 317 [DONE]                                 \n",
      "[Training] Epoch: 317, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 317, LossG: 0.7460                                  \n",
      "[Training] Epoch: 318 [DONE]                                 \n",
      "[Training] Epoch: 318, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 318, LossG: 0.7461                                  \n",
      "[Training] Epoch: 319 [DONE]                                 \n",
      "[Training] Epoch: 319, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 319, LossG: 0.7460                                  \n",
      "[Training] Epoch: 320 [DONE]                                 \n",
      "[Training] Epoch: 320, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 320, LossG: 0.7460                                  \n",
      "[Training] Epoch: 321 [DONE]                                 \n",
      "[Training] Epoch: 321, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 321, LossG: 0.7461                                  \n",
      "[Training] Epoch: 322 [DONE]                                 \n",
      "[Training] Epoch: 322, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 322, LossG: 0.7460                                  \n",
      "[Training] Epoch: 323 [DONE]                                 \n",
      "[Training] Epoch: 323, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 323, LossG: 0.7462                                  \n",
      "[Training] Epoch: 324 [DONE]                                 \n",
      "[Training] Epoch: 324, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 324, LossG: 0.7461                                  \n",
      "[Training] Epoch: 325 [DONE]                                 \n",
      "[Training] Epoch: 325, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 325, LossG: 0.7462                                  \n",
      "[Training] Epoch: 326 [DONE]                                 \n",
      "[Training] Epoch: 326, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 326, LossG: 0.7461                                  \n",
      "[Training] Epoch: 327 [DONE]                                 \n",
      "[Training] Epoch: 327, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 327, LossG: 0.7461                                  \n",
      "[Training] Epoch: 328 [DONE]                                 \n",
      "[Training] Epoch: 328, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 328, LossG: 0.7461                                  \n",
      "[Training] Epoch: 329 [DONE]                                 \n",
      "[Training] Epoch: 329, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 329, LossG: 0.7460                                  \n",
      "[Training] Epoch: 330 [DONE]                                 \n",
      "[Training] Epoch: 330, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 330, LossG: 0.7460                                  \n",
      "[Training] Epoch: 331 [DONE]                                 \n",
      "[Training] Epoch: 331, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 331, LossG: 0.7461                                  \n",
      "[Training] Epoch: 332 [DONE]                                 \n",
      "[Training] Epoch: 332, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 332, LossG: 0.7460                                  \n",
      "[Training] Epoch: 333 [DONE]                                 \n",
      "[Training] Epoch: 333, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 333, LossG: 0.7460                                  \n",
      "[Training] Epoch: 334 [DONE]                                 \n",
      "[Training] Epoch: 334, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 334, LossG: 0.7461                                  \n",
      "[Training] Epoch: 335 [DONE]                                 \n",
      "[Training] Epoch: 335, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 335, LossG: 0.7460                                  \n",
      "[Training] Epoch: 336 [DONE]                                 \n",
      "[Training] Epoch: 336, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 336, LossG: 0.7461                                  \n",
      "[Training] Epoch: 337 [DONE]                                 \n",
      "[Training] Epoch: 337, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 337, LossG: 0.7463                                  \n",
      "[Training] Epoch: 338 [DONE]                                 \n",
      "[Training] Epoch: 338, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 338, LossG: 0.7461                                  \n",
      "[Training] Epoch: 339 [DONE]                                 \n",
      "[Training] Epoch: 339, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 339, LossG: 0.7462                                  \n",
      "[Training] Epoch: 340 [DONE]                                 \n",
      "[Training] Epoch: 340, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 340, LossG: 0.7462                                  \n",
      "[Training] Epoch: 341 [DONE]                                 \n",
      "[Training] Epoch: 341, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 341, LossG: 0.7461                                  \n",
      "[Training] Epoch: 342 [DONE]                                 \n",
      "[Training] Epoch: 342, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 342, LossG: 0.7462                                  \n",
      "[Training] Epoch: 343 [DONE]                                 \n",
      "[Training] Epoch: 343, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 343, LossG: 0.7463                                  \n",
      "[Training] Epoch: 344 [DONE]                                 \n",
      "[Training] Epoch: 344, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 344, LossG: 0.7463                                  \n",
      "[Training] Epoch: 345 [DONE]                                 \n",
      "[Training] Epoch: 345, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 345, LossG: 0.7462                                  \n",
      "[Training] Epoch: 346 [DONE]                                 \n",
      "[Training] Epoch: 346, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 346, LossG: 0.7461                                  \n",
      "[Training] Epoch: 347 [DONE]                                 \n",
      "[Training] Epoch: 347, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 347, LossG: 0.7461                                  \n",
      "[Training] Epoch: 348 [DONE]                                 \n",
      "[Training] Epoch: 348, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 348, LossG: 0.7461                                  \n",
      "[Training] Epoch: 349 [DONE]                                 \n",
      "[Training] Epoch: 349, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 349, LossG: 0.7461                                  \n",
      "[Training] Epoch: 350 [DONE]                                 \n",
      "[Training] Epoch: 350, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 350, LossG: 0.7462                                  \n",
      "[Training] Epoch: 351 [DONE]                                 \n",
      "[Training] Epoch: 351, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 351, LossG: 0.7463                                  \n",
      "[Training] Epoch: 352 [DONE]                                 \n",
      "[Training] Epoch: 352, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 352, LossG: 0.7461                                  \n",
      "[Training] Epoch: 353 [DONE]                                 \n",
      "[Training] Epoch: 353, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 353, LossG: 0.7461                                  \n",
      "[Training] Epoch: 354 [DONE]                                 \n",
      "[Training] Epoch: 354, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 354, LossG: 0.7460                                  \n",
      "[Training] Epoch: 355 [DONE]                                 \n",
      "[Training] Epoch: 355, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 355, LossG: 0.7461                                  \n",
      "[Training] Epoch: 356 [DONE]                                 \n",
      "[Training] Epoch: 356, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 356, LossG: 0.7461                                  \n",
      "[Training] Epoch: 357 [DONE]                                 \n",
      "[Training] Epoch: 357, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 357, LossG: 0.7459                                  \n",
      "[Training] Epoch: 358 [DONE]                                 \n",
      "[Training] Epoch: 358, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 358, LossG: 0.7460                                  \n",
      "[Training] Epoch: 359 [DONE]                                 \n",
      "[Training] Epoch: 359, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 359, LossG: 0.7459                                  \n",
      "[Training] Epoch: 360 [DONE]                                 \n",
      "[Training] Epoch: 360, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 360, LossG: 0.7461                                  \n",
      "[Training] Epoch: 361 [DONE]                                 \n",
      "[Training] Epoch: 361, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 361, LossG: 0.7461                                  \n",
      "[Training] Epoch: 362 [DONE]                                 \n",
      "[Training] Epoch: 362, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 362, LossG: 0.7461                                  \n",
      "[Training] Epoch: 363 [DONE]                                 \n",
      "[Training] Epoch: 363, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 363, LossG: 0.7460                                  \n",
      "[Training] Epoch: 364 [DONE]                                 \n",
      "[Training] Epoch: 364, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 364, LossG: 0.7461                                  \n",
      "[Training] Epoch: 365 [DONE]                                 \n",
      "[Training] Epoch: 365, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 365, LossG: 0.7461                                  \n",
      "[Training] Epoch: 366 [DONE]                                 \n",
      "[Training] Epoch: 366, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 366, LossG: 0.7461                                  \n",
      "[Training] Epoch: 367 [DONE]                                 \n",
      "[Training] Epoch: 367, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 367, LossG: 0.7460                                  \n",
      "[Training] Epoch: 368 [DONE]                                 \n",
      "[Training] Epoch: 368, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 368, LossG: 0.7461                                  \n",
      "[Training] Epoch: 369 [DONE]                                 \n",
      "[Training] Epoch: 369, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 369, LossG: 0.7460                                  \n",
      "[Training] Epoch: 370 [DONE]                                 \n",
      "[Training] Epoch: 370, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 370, LossG: 0.7462                                  \n",
      "[Training] Epoch: 371 [DONE]                                 \n",
      "[Training] Epoch: 371, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 371, LossG: 0.7461                                  \n",
      "[Training] Epoch: 372 [DONE]                                 \n",
      "[Training] Epoch: 372, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 372, LossG: 0.7461                                  \n",
      "[Training] Epoch: 373 [DONE]                                 \n",
      "[Training] Epoch: 373, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 373, LossG: 0.7461                                  \n",
      "[Training] Epoch: 374 [DONE]                                 \n",
      "[Training] Epoch: 374, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 374, LossG: 0.7461                                  \n",
      "[Training] Epoch: 375 [DONE]                                 \n",
      "[Training] Epoch: 375, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 375, LossG: 0.7462                                  \n",
      "[Training] Epoch: 376 [DONE]                                 \n",
      "[Training] Epoch: 376, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 376, LossG: 0.7461                                  \n",
      "[Training] Epoch: 377 [DONE]                                 \n",
      "[Training] Epoch: 377, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 377, LossG: 0.7461                                  \n",
      "[Training] Epoch: 378 [DONE]                                 \n",
      "[Training] Epoch: 378, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 378, LossG: 0.7460                                  \n",
      "[Training] Epoch: 379 [DONE]                                 \n",
      "[Training] Epoch: 379, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 379, LossG: 0.7460                                  \n",
      "[Training] Epoch: 380 [DONE]                                 \n",
      "[Training] Epoch: 380, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 380, LossG: 0.7461                                  \n",
      "[Training] Epoch: 381 [DONE]                                 \n",
      "[Training] Epoch: 381, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 381, LossG: 0.7463                                  \n",
      "[Training] Epoch: 382 [DONE]                                 \n",
      "[Training] Epoch: 382, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 382, LossG: 0.7464                                  \n",
      "[Training] Epoch: 383 [DONE]                                 \n",
      "[Training] Epoch: 383, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 383, LossG: 0.7462                                  \n",
      "[Training] Epoch: 384 [DONE]                                 \n",
      "[Training] Epoch: 384, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 384, LossG: 0.7464                                  \n",
      "[Training] Epoch: 385 [DONE]                                 \n",
      "[Training] Epoch: 385, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 385, LossG: 0.7466                                  \n",
      "[Training] Epoch: 386 [DONE]                                 \n",
      "[Training] Epoch: 386, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 386, LossG: 0.7468                                  \n",
      "[Training] Epoch: 387 [DONE]                                 \n",
      "[Training] Epoch: 387, LossG: 0.7470=================================================================] 100.0%\n",
      "[Validation] Epoch: 387, LossG: 0.7470                                  \n",
      "[Training] Epoch: 388 [DONE]                                 \n",
      "[Training] Epoch: 388, LossG: 0.7466=================================================================] 100.0%\n",
      "[Validation] Epoch: 388, LossG: 0.7466                                  \n",
      "[Training] Epoch: 389 [DONE]                                 \n",
      "[Training] Epoch: 389, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 389, LossG: 0.7465                                  \n",
      "[Training] Epoch: 390 [DONE]                                 \n",
      "[Training] Epoch: 390, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 390, LossG: 0.7464                                  \n",
      "[Training] Epoch: 391 [DONE]                                 \n",
      "[Training] Epoch: 391, LossG: 0.7467=================================================================] 100.0%\n",
      "[Validation] Epoch: 391, LossG: 0.7467                                  \n",
      "[Training] Epoch: 392 [DONE]                                 \n",
      "[Training] Epoch: 392, LossG: 0.7469=================================================================] 100.0%\n",
      "[Validation] Epoch: 392, LossG: 0.7469                                  \n",
      "[Training] Epoch: 393 [DONE]                                 \n",
      "[Training] Epoch: 393, LossG: 0.7468=================================================================] 100.0%\n",
      "[Validation] Epoch: 393, LossG: 0.7468                                  \n",
      "[Training] Epoch: 394 [DONE]                                 \n",
      "[Training] Epoch: 394, LossG: 0.7465=================================================================] 100.0%\n",
      "[Validation] Epoch: 394, LossG: 0.7465                                  \n",
      "[Training] Epoch: 395 [DONE]                                 \n",
      "[Training] Epoch: 395, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 395, LossG: 0.7463                                  \n",
      "[Training] Epoch: 396 [DONE]                                 \n",
      "[Training] Epoch: 396, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 396, LossG: 0.7464                                  \n",
      "[Training] Epoch: 397 [DONE]                                 \n",
      "[Training] Epoch: 397, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 397, LossG: 0.7462                                  \n",
      "[Training] Epoch: 398 [DONE]                                 \n",
      "[Training] Epoch: 398, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 398, LossG: 0.7462                                  \n",
      "[Training] Epoch: 399 [DONE]                                 \n",
      "[Training] Epoch: 399, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 399, LossG: 0.7463                                  \n",
      "[Training] Epoch: 400 [DONE]                                 \n",
      "[Training] Epoch: 400, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 400, LossG: 0.7463                                  \n",
      "[Training] Epoch: 401 [DONE]                                 \n",
      "[Training] Epoch: 401, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 401, LossG: 0.7462                                  \n",
      "[Training] Epoch: 402 [DONE]                                 \n",
      "[Training] Epoch: 402, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 402, LossG: 0.7461                                  \n",
      "[Training] Epoch: 403 [DONE]                                 \n",
      "[Training] Epoch: 403, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 403, LossG: 0.7461                                  \n",
      "[Training] Epoch: 404 [DONE]                                 \n",
      "[Training] Epoch: 404, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 404, LossG: 0.7460                                  \n",
      "[Training] Epoch: 405 [DONE]                                 \n",
      "[Training] Epoch: 405, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 405, LossG: 0.7459                                  \n",
      "[Training] Epoch: 406 [DONE]                                 \n",
      "[Training] Epoch: 406, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 406, LossG: 0.7460                                  \n",
      "[Training] Epoch: 407 [DONE]                                 \n",
      "[Training] Epoch: 407, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 407, LossG: 0.7459                                  \n",
      "[Training] Epoch: 408 [DONE]                                 \n",
      "[Training] Epoch: 408, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 408, LossG: 0.7459                                  \n",
      "[Training] Epoch: 409 [DONE]                                 \n",
      "[Training] Epoch: 409, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 409, LossG: 0.7460                                  \n",
      "[Training] Epoch: 410 [DONE]                                 \n",
      "[Training] Epoch: 410, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 410, LossG: 0.7460                                  \n",
      "[Training] Epoch: 411 [DONE]                                 \n",
      "[Training] Epoch: 411, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 411, LossG: 0.7459                                  \n",
      "[Training] Epoch: 412 [DONE]                                 \n",
      "[Training] Epoch: 412, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 412, LossG: 0.7459                                  \n",
      "[Training] Epoch: 413 [DONE]                                 \n",
      "[Training] Epoch: 413, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 413, LossG: 0.7460                                  \n",
      "[Training] Epoch: 414 [DONE]                                 \n",
      "[Training] Epoch: 414, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 414, LossG: 0.7460                                  \n",
      "[Training] Epoch: 415 [DONE]                                 \n",
      "[Training] Epoch: 415, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 415, LossG: 0.7460                                  \n",
      "[Training] Epoch: 416 [DONE]                                 \n",
      "[Training] Epoch: 416, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 416, LossG: 0.7459                                  \n",
      "[Training] Epoch: 417 [DONE]                                 \n",
      "[Training] Epoch: 417, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 417, LossG: 0.7460                                  \n",
      "[Training] Epoch: 418 [DONE]                                 \n",
      "[Training] Epoch: 418, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 418, LossG: 0.7460                                  \n",
      "[Training] Epoch: 419 [DONE]                                 \n",
      "[Training] Epoch: 419, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 419, LossG: 0.7460                                  \n",
      "[Training] Epoch: 420 [DONE]                                 \n",
      "[Training] Epoch: 420, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 420, LossG: 0.7459                                  \n",
      "[Training] Epoch: 421 [DONE]                                 \n",
      "[Training] Epoch: 421, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 421, LossG: 0.7460                                  \n",
      "[Training] Epoch: 422 [DONE]                                 \n",
      "[Training] Epoch: 422, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 422, LossG: 0.7459                                  \n",
      "[Training] Epoch: 423 [DONE]                                 \n",
      "[Training] Epoch: 423, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 423, LossG: 0.7459                                  \n",
      "[Training] Epoch: 424 [DONE]                                 \n",
      "[Training] Epoch: 424, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 424, LossG: 0.7459                                  \n",
      "[Training] Epoch: 425 [DONE]                                 \n",
      "[Training] Epoch: 425, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 425, LossG: 0.7458                                  \n",
      "[Training] Epoch: 426 [DONE]                                 \n",
      "[Training] Epoch: 426, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 426, LossG: 0.7459                                  \n",
      "[Training] Epoch: 427 [DONE]                                 \n",
      "[Training] Epoch: 427, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 427, LossG: 0.7458                                  \n",
      "[Training] Epoch: 428 [DONE]                                 \n",
      "[Training] Epoch: 428, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 428, LossG: 0.7459                                  \n",
      "[Training] Epoch: 429 [DONE]                                 \n",
      "[Training] Epoch: 429, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 429, LossG: 0.7459                                  \n",
      "[Training] Epoch: 430 [DONE]                                 \n",
      "[Training] Epoch: 430, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 430, LossG: 0.7460                                  \n",
      "[Training] Epoch: 431 [DONE]                                 \n",
      "[Training] Epoch: 431, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 431, LossG: 0.7459                                  \n",
      "[Training] Epoch: 432 [DONE]                                 \n",
      "[Training] Epoch: 432, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 432, LossG: 0.7458                                  \n",
      "[Training] Epoch: 433 [DONE]                                 \n",
      "[Training] Epoch: 433, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 433, LossG: 0.7458                                  \n",
      "[Training] Epoch: 434 [DONE]                                 \n",
      "[Training] Epoch: 434, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 434, LossG: 0.7460                                  \n",
      "[Training] Epoch: 435 [DONE]                                 \n",
      "[Training] Epoch: 435, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 435, LossG: 0.7459                                  \n",
      "[Training] Epoch: 436 [DONE]                                 \n",
      "[Training] Epoch: 436, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 436, LossG: 0.7458                                  \n",
      "[Training] Epoch: 437 [DONE]                                 \n",
      "[Training] Epoch: 437, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 437, LossG: 0.7458                                  \n",
      "[Training] Epoch: 438 [DONE]                                 \n",
      "[Training] Epoch: 438, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 438, LossG: 0.7459                                  \n",
      "[Training] Epoch: 439 [DONE]                                 \n",
      "[Training] Epoch: 439, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 439, LossG: 0.7460                                  \n",
      "[Training] Epoch: 440 [DONE]                                 \n",
      "[Training] Epoch: 440, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 440, LossG: 0.7461                                  \n",
      "[Training] Epoch: 441 [DONE]                                 \n",
      "[Training] Epoch: 441, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 441, LossG: 0.7459                                  \n",
      "[Training] Epoch: 442 [DONE]                                 \n",
      "[Training] Epoch: 442, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 442, LossG: 0.7460                                  \n",
      "[Training] Epoch: 443 [DONE]                                 \n",
      "[Training] Epoch: 443, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 443, LossG: 0.7460                                  \n",
      "[Training] Epoch: 444 [DONE]                                 \n",
      "[Training] Epoch: 444, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 444, LossG: 0.7459                                  \n",
      "[Training] Epoch: 445 [DONE]                                 \n",
      "[Training] Epoch: 445, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 445, LossG: 0.7460                                  \n",
      "[Training] Epoch: 446 [DONE]                                 \n",
      "[Training] Epoch: 446, LossG: 0.7463=================================================================] 100.0%\n",
      "[Validation] Epoch: 446, LossG: 0.7463                                  \n",
      "[Training] Epoch: 447 [DONE]                                 \n",
      "[Training] Epoch: 447, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 447, LossG: 0.7462                                  \n",
      "[Training] Epoch: 448 [DONE]                                 \n",
      "[Training] Epoch: 448, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 448, LossG: 0.7461                                  \n",
      "[Training] Epoch: 449 [DONE]                                 \n",
      "[Training] Epoch: 449, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 449, LossG: 0.7460                                  \n",
      "Epoch: 449\n",
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      " Model loaded: ./models/Test_Model/449_Epoch\n",
      "Total params: 1,769,492\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 0.7462===================================================================] 100.0%\n",
      "[Validation] Epoch: 0, LossG: 0.7462                                      \n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 0.7463===================================================================] 100.0%\n",
      "[Validation] Epoch: 1, LossG: 0.7463                                      \n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 0.7461===================================================================] 100.0%\n",
      "[Validation] Epoch: 2, LossG: 0.7461                                      \n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 0.7461===================================================================] 100.0%\n",
      "[Validation] Epoch: 3, LossG: 0.7461                                      \n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 0.7462===================================================================] 100.0%\n",
      "[Validation] Epoch: 4, LossG: 0.7462                                      \n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 0.7461===================================================================] 100.0%\n",
      "[Validation] Epoch: 5, LossG: 0.7461                                      \n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 0.7460===================================================================] 100.0%\n",
      "[Validation] Epoch: 6, LossG: 0.7460                                      \n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 0.7461===================================================================] 100.0%\n",
      "[Validation] Epoch: 7, LossG: 0.7461                                      \n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 0.7461===================================================================] 100.0%\n",
      "[Validation] Epoch: 8, LossG: 0.7461                                      \n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 0.7460===================================================================] 100.0%\n",
      "[Validation] Epoch: 9, LossG: 0.7460                                      \n",
      "[Training] Epoch: 10 [DONE]                                 \n",
      "[Training] Epoch: 10, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 10, LossG: 0.7459                                    \n",
      "[Training] Epoch: 11 [DONE]                                 \n",
      "[Training] Epoch: 11, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 11, LossG: 0.7461                                    \n",
      "[Training] Epoch: 12 [DONE]                                 \n",
      "[Training] Epoch: 12, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 12, LossG: 0.7460                                    \n",
      "[Training] Epoch: 13 [DONE]                                 \n",
      "[Training] Epoch: 13, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 13, LossG: 0.7461                                    \n",
      "[Training] Epoch: 14 [DONE]                                 \n",
      "[Training] Epoch: 14, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 14, LossG: 0.7460                                    \n",
      "[Training] Epoch: 15 [DONE]                                 \n",
      "[Training] Epoch: 15, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 15, LossG: 0.7459                                    \n",
      "[Training] Epoch: 16 [DONE]                                 \n",
      "[Training] Epoch: 16, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 16, LossG: 0.7460                                    \n",
      "[Training] Epoch: 17 [DONE]                                 \n",
      "[Training] Epoch: 17, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 17, LossG: 0.7459                                    \n",
      "[Training] Epoch: 18 [DONE]                                 \n",
      "[Training] Epoch: 18, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 18, LossG: 0.7459                                    \n",
      "[Training] Epoch: 19 [DONE]                                 \n",
      "[Training] Epoch: 19, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 19, LossG: 0.7461                                    \n",
      "[Training] Epoch: 20 [DONE]                                 \n",
      "[Training] Epoch: 20, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 20, LossG: 0.7461                                    \n",
      "[Training] Epoch: 21 [DONE]                                 \n",
      "[Training] Epoch: 21, LossG: 0.7462==================================================================] 100.0%\n",
      "[Validation] Epoch: 21, LossG: 0.7462                                    \n",
      "[Training] Epoch: 22 [DONE]                                 \n",
      "[Training] Epoch: 22, LossG: 0.7462==================================================================] 100.0%\n",
      "[Validation] Epoch: 22, LossG: 0.7462                                    \n",
      "[Training] Epoch: 23 [DONE]                                 \n",
      "[Training] Epoch: 23, LossG: 0.7462==================================================================] 100.0%\n",
      "[Validation] Epoch: 23, LossG: 0.7462                                    \n",
      "[Training] Epoch: 24 [DONE]                                 \n",
      "[Training] Epoch: 24, LossG: 0.7462==================================================================] 100.0%\n",
      "[Validation] Epoch: 24, LossG: 0.7462                                    \n",
      "[Training] Epoch: 25 [DONE]                                 \n",
      "[Training] Epoch: 25, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 25, LossG: 0.7460                                    \n",
      "[Training] Epoch: 26 [DONE]                                 \n",
      "[Training] Epoch: 26, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 26, LossG: 0.7460                                    \n",
      "[Training] Epoch: 27 [DONE]                                 \n",
      "[Training] Epoch: 27, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 27, LossG: 0.7461                                    \n",
      "[Training] Epoch: 28 [DONE]                                 \n",
      "[Training] Epoch: 28, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 28, LossG: 0.7459                                    \n",
      "[Training] Epoch: 29 [DONE]                                 \n",
      "[Training] Epoch: 29, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 29, LossG: 0.7460                                    \n",
      "[Training] Epoch: 30 [DONE]                                 \n",
      "[Training] Epoch: 30, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 30, LossG: 0.7459                                    \n",
      "[Training] Epoch: 31 [DONE]                                 \n",
      "[Training] Epoch: 31, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 31, LossG: 0.7460                                    \n",
      "[Training] Epoch: 32 [DONE]                                 \n",
      "[Training] Epoch: 32, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 32, LossG: 0.7461                                    \n",
      "[Training] Epoch: 33 [DONE]                                 \n",
      "[Training] Epoch: 33, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 33, LossG: 0.7460                                    \n",
      "[Training] Epoch: 34 [DONE]                                 \n",
      "[Training] Epoch: 34, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 34, LossG: 0.7460                                    \n",
      "[Training] Epoch: 35 [DONE]                                 \n",
      "[Training] Epoch: 35, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 35, LossG: 0.7461                                    \n",
      "[Training] Epoch: 36 [DONE]                                 \n",
      "[Training] Epoch: 36, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 36, LossG: 0.7460                                    \n",
      "[Training] Epoch: 37 [DONE]                                 \n",
      "[Training] Epoch: 37, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 37, LossG: 0.7459                                    \n",
      "[Training] Epoch: 38 [DONE]                                 \n",
      "[Training] Epoch: 38, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 38, LossG: 0.7459                                    \n",
      "[Training] Epoch: 39 [DONE]                                 \n",
      "[Training] Epoch: 39, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 39, LossG: 0.7459                                    \n",
      "[Training] Epoch: 40 [DONE]                                 \n",
      "[Training] Epoch: 40, LossG: 0.7464==================================================================] 100.0%\n",
      "[Validation] Epoch: 40, LossG: 0.7464                                    \n",
      "[Training] Epoch: 41 [DONE]                                 \n",
      "[Training] Epoch: 41, LossG: 0.7464==================================================================] 100.0%\n",
      "[Validation] Epoch: 41, LossG: 0.7464                                    \n",
      "[Training] Epoch: 42 [DONE]                                 \n",
      "[Training] Epoch: 42, LossG: 0.7469==================================================================] 100.0%\n",
      "[Validation] Epoch: 42, LossG: 0.7469                                    \n",
      "[Training] Epoch: 43 [DONE]                                 \n",
      "[Training] Epoch: 43, LossG: 0.7471==================================================================] 100.0%\n",
      "[Validation] Epoch: 43, LossG: 0.7471                                    \n",
      "[Training] Epoch: 44 [DONE]                                 \n",
      "[Training] Epoch: 44, LossG: 0.7468==================================================================] 100.0%\n",
      "[Validation] Epoch: 44, LossG: 0.7468                                    \n",
      "[Training] Epoch: 45 [DONE]                                 \n",
      "[Training] Epoch: 45, LossG: 0.7466==================================================================] 100.0%\n",
      "[Validation] Epoch: 45, LossG: 0.7466                                    \n",
      "[Training] Epoch: 46 [DONE]                                 \n",
      "[Training] Epoch: 46, LossG: 0.7463==================================================================] 100.0%\n",
      "[Validation] Epoch: 46, LossG: 0.7463                                    \n",
      "[Training] Epoch: 47 [DONE]                                 \n",
      "[Training] Epoch: 47, LossG: 0.7462==================================================================] 100.0%\n",
      "[Validation] Epoch: 47, LossG: 0.7462                                    \n",
      "[Training] Epoch: 48 [DONE]                                 \n",
      "[Training] Epoch: 48, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 48, LossG: 0.7461                                    \n",
      "[Training] Epoch: 49 [DONE]                                 \n",
      "[Training] Epoch: 49, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 49, LossG: 0.7460                                    \n",
      "[Training] Epoch: 50 [DONE]                                 \n",
      "[Training] Epoch: 50, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 50, LossG: 0.7460                                    \n",
      "[Training] Epoch: 51 [DONE]                                 \n",
      "[Training] Epoch: 51, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 51, LossG: 0.7460                                    \n",
      "[Training] Epoch: 52 [DONE]                                 \n",
      "[Training] Epoch: 52, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 52, LossG: 0.7459                                    \n",
      "[Training] Epoch: 53 [DONE]                                 \n",
      "[Training] Epoch: 53, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 53, LossG: 0.7459                                    \n",
      "[Training] Epoch: 54 [DONE]                                 \n",
      "[Training] Epoch: 54, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 54, LossG: 0.7459                                    \n",
      "[Training] Epoch: 55 [DONE]                                 \n",
      "[Training] Epoch: 55, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 55, LossG: 0.7459                                    \n",
      "[Training] Epoch: 56 [DONE]                                 \n",
      "[Training] Epoch: 56, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 56, LossG: 0.7459                                    \n",
      "[Training] Epoch: 57 [DONE]                                 \n",
      "[Training] Epoch: 57, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 57, LossG: 0.7458                                    \n",
      "[Training] Epoch: 58 [DONE]                                 \n",
      "[Training] Epoch: 58, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 58, LossG: 0.7459                                    \n",
      "[Training] Epoch: 59 [DONE]                                 \n",
      "[Training] Epoch: 59, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 59, LossG: 0.7460                                    \n",
      "[Training] Epoch: 60 [DONE]                                 \n",
      "[Training] Epoch: 60, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 60, LossG: 0.7460                                    \n",
      "[Training] Epoch: 61 [DONE]                                 \n",
      "[Training] Epoch: 61, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 61, LossG: 0.7460                                    \n",
      "[Training] Epoch: 62 [DONE]                                 \n",
      "[Training] Epoch: 62, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 62, LossG: 0.7460                                    \n",
      "[Training] Epoch: 63 [DONE]                                 \n",
      "[Training] Epoch: 63, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 63, LossG: 0.7459                                    \n",
      "[Training] Epoch: 64 [DONE]                                 \n",
      "[Training] Epoch: 64, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 64, LossG: 0.7458                                    \n",
      "[Training] Epoch: 65 [DONE]                                 \n",
      "[Training] Epoch: 65, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 65, LossG: 0.7457                                    \n",
      "[Training] Epoch: 66 [DONE]                                 \n",
      "[Training] Epoch: 66, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 66, LossG: 0.7459                                    \n",
      "[Training] Epoch: 67 [DONE]                                 \n",
      "[Training] Epoch: 67, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 67, LossG: 0.7459                                    \n",
      "[Training] Epoch: 68 [DONE]                                 \n",
      "[Training] Epoch: 68, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 68, LossG: 0.7459                                    \n",
      "[Training] Epoch: 69 [DONE]                                 \n",
      "[Training] Epoch: 69, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 69, LossG: 0.7459                                    \n",
      "[Training] Epoch: 70 [DONE]                                 \n",
      "[Training] Epoch: 70, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 70, LossG: 0.7459                                    \n",
      "[Training] Epoch: 71 [DONE]                                 \n",
      "[Training] Epoch: 71, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 71, LossG: 0.7458                                    \n",
      "[Training] Epoch: 72 [DONE]                                 \n",
      "[Training] Epoch: 72, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 72, LossG: 0.7458                                    \n",
      "[Training] Epoch: 73 [DONE]                                 \n",
      "[Training] Epoch: 73, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 73, LossG: 0.7458                                    \n",
      "[Training] Epoch: 74 [DONE]                                 \n",
      "[Training] Epoch: 74, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 74, LossG: 0.7458                                    \n",
      "[Training] Epoch: 75 [DONE]                                 \n",
      "[Training] Epoch: 75, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 75, LossG: 0.7459                                    \n",
      "[Training] Epoch: 76 [DONE]                                 \n",
      "[Training] Epoch: 76, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 76, LossG: 0.7459                                    \n",
      "[Training] Epoch: 77 [DONE]                                 \n",
      "[Training] Epoch: 77, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 77, LossG: 0.7458                                    \n",
      "[Training] Epoch: 78 [DONE]                                 \n",
      "[Training] Epoch: 78, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 78, LossG: 0.7459                                    \n",
      "[Training] Epoch: 79 [DONE]                                 \n",
      "[Training] Epoch: 79, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 79, LossG: 0.7459                                    \n",
      "[Training] Epoch: 80 [DONE]                                 \n",
      "[Training] Epoch: 80, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 80, LossG: 0.7458                                    \n",
      "[Training] Epoch: 81 [DONE]                                 \n",
      "[Training] Epoch: 81, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 81, LossG: 0.7457                                    \n",
      "[Training] Epoch: 82 [DONE]                                 \n",
      "[Training] Epoch: 82, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 82, LossG: 0.7459                                    \n",
      "[Training] Epoch: 83 [DONE]                                 \n",
      "[Training] Epoch: 83, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 83, LossG: 0.7458                                    \n",
      "[Training] Epoch: 84 [DONE]                                 \n",
      "[Training] Epoch: 84, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 84, LossG: 0.7459                                    \n",
      "[Training] Epoch: 85 [DONE]                                 \n",
      "[Training] Epoch: 85, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 85, LossG: 0.7459                                    \n",
      "[Training] Epoch: 86 [DONE]                                 \n",
      "[Training] Epoch: 86, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 86, LossG: 0.7457                                    \n",
      "[Training] Epoch: 87 [DONE]                                 \n",
      "[Training] Epoch: 87, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 87, LossG: 0.7459                                    \n",
      "[Training] Epoch: 88 [DONE]                                 \n",
      "[Training] Epoch: 88, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 88, LossG: 0.7458                                    \n",
      "[Training] Epoch: 89 [DONE]                                 \n",
      "[Training] Epoch: 89, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 89, LossG: 0.7459                                    \n",
      "[Training] Epoch: 90 [DONE]                                 \n",
      "[Training] Epoch: 90, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 90, LossG: 0.7458                                    \n",
      "[Training] Epoch: 91 [DONE]                                 \n",
      "[Training] Epoch: 91, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 91, LossG: 0.7458                                    \n",
      "[Training] Epoch: 92 [DONE]                                 \n",
      "[Training] Epoch: 92, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 92, LossG: 0.7458                                    \n",
      "[Training] Epoch: 93 [DONE]                                 \n",
      "[Training] Epoch: 93, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 93, LossG: 0.7459                                    \n",
      "[Training] Epoch: 94 [DONE]                                 \n",
      "[Training] Epoch: 94, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 94, LossG: 0.7458                                    \n",
      "[Training] Epoch: 95 [DONE]                                 \n",
      "[Training] Epoch: 95, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 95, LossG: 0.7459                                    \n",
      "[Training] Epoch: 96 [DONE]                                 \n",
      "[Training] Epoch: 96, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 96, LossG: 0.7458                                    \n",
      "[Training] Epoch: 97 [DONE]                                 \n",
      "[Training] Epoch: 97, LossG: 0.7460==================================================================] 100.0%\n",
      "[Validation] Epoch: 97, LossG: 0.7460                                    \n",
      "[Training] Epoch: 98 [DONE]                                 \n",
      "[Training] Epoch: 98, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 98, LossG: 0.7458                                    \n",
      "[Training] Epoch: 99 [DONE]                                 \n",
      "[Training] Epoch: 99, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 99, LossG: 0.7458                                    \n",
      "[Training] Epoch: 100 [DONE]                                 \n",
      "[Training] Epoch: 100, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 100, LossG: 0.7459                                  \n",
      "[Training] Epoch: 101 [DONE]                                 \n",
      "[Training] Epoch: 101, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 101, LossG: 0.7459                                  \n",
      "[Training] Epoch: 102 [DONE]                                 \n",
      "[Training] Epoch: 102, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 102, LossG: 0.7459                                  \n",
      "[Training] Epoch: 103 [DONE]                                 \n",
      "[Training] Epoch: 103, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 103, LossG: 0.7459                                  \n",
      "[Training] Epoch: 104 [DONE]                                 \n",
      "[Training] Epoch: 104, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 104, LossG: 0.7458                                  \n",
      "[Training] Epoch: 105 [DONE]                                 \n",
      "[Training] Epoch: 105, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 105, LossG: 0.7458                                  \n",
      "[Training] Epoch: 106 [DONE]                                 \n",
      "[Training] Epoch: 106, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 106, LossG: 0.7458                                  \n",
      "[Training] Epoch: 107 [DONE]                                 \n",
      "[Training] Epoch: 107, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 107, LossG: 0.7458                                  \n",
      "[Training] Epoch: 108 [DONE]                                 \n",
      "[Training] Epoch: 108, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 108, LossG: 0.7458                                  \n",
      "[Training] Epoch: 109 [DONE]                                 \n",
      "[Training] Epoch: 109, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 109, LossG: 0.7458                                  \n",
      "[Training] Epoch: 110 [DONE]                                 \n",
      "[Training] Epoch: 110, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 110, LossG: 0.7458                                  \n",
      "[Training] Epoch: 111 [DONE]                                 \n",
      "[Training] Epoch: 111, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 111, LossG: 0.7458                                  \n",
      "[Training] Epoch: 112 [DONE]                                 \n",
      "[Training] Epoch: 112, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 112, LossG: 0.7457                                  \n",
      "[Training] Epoch: 113 [DONE]                                 \n",
      "[Training] Epoch: 113, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 113, LossG: 0.7458                                  \n",
      "[Training] Epoch: 114 [DONE]                                 \n",
      "[Training] Epoch: 114, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 114, LossG: 0.7461                                  \n",
      "[Training] Epoch: 115 [DONE]                                 \n",
      "[Training] Epoch: 115, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 115, LossG: 0.7460                                  \n",
      "[Training] Epoch: 116 [DONE]                                 \n",
      "[Training] Epoch: 116, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 116, LossG: 0.7459                                  \n",
      "[Training] Epoch: 117 [DONE]                                 \n",
      "[Training] Epoch: 117, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 117, LossG: 0.7459                                  \n",
      "[Training] Epoch: 118 [DONE]                                 \n",
      "[Training] Epoch: 118, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 118, LossG: 0.7458                                  \n",
      "[Training] Epoch: 119 [DONE]                                 \n",
      "[Training] Epoch: 119, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 119, LossG: 0.7457                                  \n",
      "[Training] Epoch: 120 [DONE]                                 \n",
      "[Training] Epoch: 120, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 120, LossG: 0.7459                                  \n",
      "[Training] Epoch: 121 [DONE]                                 \n",
      "[Training] Epoch: 121, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 121, LossG: 0.7458                                  \n",
      "[Training] Epoch: 122 [DONE]                                 \n",
      "[Training] Epoch: 122, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 122, LossG: 0.7460                                  \n",
      "[Training] Epoch: 123 [DONE]                                 \n",
      "[Training] Epoch: 123, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 123, LossG: 0.7461                                  \n",
      "[Training] Epoch: 124 [DONE]                                 \n",
      "[Training] Epoch: 124, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 124, LossG: 0.7460                                  \n",
      "[Training] Epoch: 125 [DONE]                                 \n",
      "[Training] Epoch: 125, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 125, LossG: 0.7459                                  \n",
      "[Training] Epoch: 126 [DONE]                                 \n",
      "[Training] Epoch: 126, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 126, LossG: 0.7458                                  \n",
      "[Training] Epoch: 127 [DONE]                                 \n",
      "[Training] Epoch: 127, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 127, LossG: 0.7459                                  \n",
      "[Training] Epoch: 128 [DONE]                                 \n",
      "[Training] Epoch: 128, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 128, LossG: 0.7458                                  \n",
      "[Training] Epoch: 129 [DONE]                                 \n",
      "[Training] Epoch: 129, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 129, LossG: 0.7457                                  \n",
      "[Training] Epoch: 130 [DONE]                                 \n",
      "[Training] Epoch: 130, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 130, LossG: 0.7458                                  \n",
      "[Training] Epoch: 131 [DONE]                                 \n",
      "[Training] Epoch: 131, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 131, LossG: 0.7457                                  \n",
      "[Training] Epoch: 132 [DONE]                                 \n",
      "[Training] Epoch: 132, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 132, LossG: 0.7457                                  \n",
      "[Training] Epoch: 133 [DONE]                                 \n",
      "[Training] Epoch: 133, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 133, LossG: 0.7458                                  \n",
      "[Training] Epoch: 134 [DONE]                                 \n",
      "[Training] Epoch: 134, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 134, LossG: 0.7458                                  \n",
      "[Training] Epoch: 135 [DONE]                                 \n",
      "[Training] Epoch: 135, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 135, LossG: 0.7458                                  \n",
      "[Training] Epoch: 136 [DONE]                                 \n",
      "[Training] Epoch: 136, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 136, LossG: 0.7458                                  \n",
      "[Training] Epoch: 137 [DONE]                                 \n",
      "[Training] Epoch: 137, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 137, LossG: 0.7458                                  \n",
      "[Training] Epoch: 138 [DONE]                                 \n",
      "[Training] Epoch: 138, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 138, LossG: 0.7458                                  \n",
      "[Training] Epoch: 139 [DONE]                                 \n",
      "[Training] Epoch: 139, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 139, LossG: 0.7459                                  \n",
      "[Training] Epoch: 140 [DONE]                                 \n",
      "[Training] Epoch: 140, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 140, LossG: 0.7459                                  \n",
      "[Training] Epoch: 141 [DONE]                                 \n",
      "[Training] Epoch: 141, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 141, LossG: 0.7459                                  \n",
      "[Training] Epoch: 142 [DONE]                                 \n",
      "[Training] Epoch: 142, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 142, LossG: 0.7458                                  \n",
      "[Training] Epoch: 143 [DONE]                                 \n",
      "[Training] Epoch: 143, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 143, LossG: 0.7459                                  \n",
      "[Training] Epoch: 144 [DONE]                                 \n",
      "[Training] Epoch: 144, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 144, LossG: 0.7458                                  \n",
      "[Training] Epoch: 145 [DONE]                                 \n",
      "[Training] Epoch: 145, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 145, LossG: 0.7461                                  \n",
      "[Training] Epoch: 146 [DONE]                                 \n",
      "[Training] Epoch: 146, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 146, LossG: 0.7459                                  \n",
      "[Training] Epoch: 147 [DONE]                                 \n",
      "[Training] Epoch: 147, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 147, LossG: 0.7459                                  \n",
      "[Training] Epoch: 148 [DONE]                                 \n",
      "[Training] Epoch: 148, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 148, LossG: 0.7461                                  \n",
      "[Training] Epoch: 149 [DONE]                                 \n",
      "[Training] Epoch: 149, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 149, LossG: 0.7461                                  \n",
      "[Training] Epoch: 150 [DONE]                                 \n",
      "[Training] Epoch: 150, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 150, LossG: 0.7459                                  \n",
      "[Training] Epoch: 151 [DONE]                                 \n",
      "[Training] Epoch: 151, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 151, LossG: 0.7459                                  \n",
      "[Training] Epoch: 152 [DONE]                                 \n",
      "[Training] Epoch: 152, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 152, LossG: 0.7458                                  \n",
      "[Training] Epoch: 153 [DONE]                                 \n",
      "[Training] Epoch: 153, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 153, LossG: 0.7458                                  \n",
      "[Training] Epoch: 154 [DONE]                                 \n",
      "[Training] Epoch: 154, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 154, LossG: 0.7458                                  \n",
      "[Training] Epoch: 155 [DONE]                                 \n",
      "[Training] Epoch: 155, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 155, LossG: 0.7458                                  \n",
      "[Training] Epoch: 156 [DONE]                                 \n",
      "[Training] Epoch: 156, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 156, LossG: 0.7459                                  \n",
      "[Training] Epoch: 157 [DONE]                                 \n",
      "[Training] Epoch: 157, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 157, LossG: 0.7459                                  \n",
      "[Training] Epoch: 158 [DONE]                                 \n",
      "[Training] Epoch: 158, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 158, LossG: 0.7458                                  \n",
      "[Training] Epoch: 159 [DONE]                                 \n",
      "[Training] Epoch: 159, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 159, LossG: 0.7459                                  \n",
      "[Training] Epoch: 160 [DONE]                                 \n",
      "[Training] Epoch: 160, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 160, LossG: 0.7459                                  \n",
      "[Training] Epoch: 161 [DONE]                                 \n",
      "[Training] Epoch: 161, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 161, LossG: 0.7459                                  \n",
      "[Training] Epoch: 162 [DONE]                                 \n",
      "[Training] Epoch: 162, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 162, LossG: 0.7458                                  \n",
      "[Training] Epoch: 163 [DONE]                                 \n",
      "[Training] Epoch: 163, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 163, LossG: 0.7458                                  \n",
      "[Training] Epoch: 164 [DONE]                                 \n",
      "[Training] Epoch: 164, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 164, LossG: 0.7458                                  \n",
      "[Training] Epoch: 165 [DONE]                                 \n",
      "[Training] Epoch: 165, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 165, LossG: 0.7457                                  \n",
      "[Training] Epoch: 166 [DONE]                                 \n",
      "[Training] Epoch: 166, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 166, LossG: 0.7458                                  \n",
      "[Training] Epoch: 167 [DONE]                                 \n",
      "[Training] Epoch: 167, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 167, LossG: 0.7458                                  \n",
      "[Training] Epoch: 168 [DONE]                                 \n",
      "[Training] Epoch: 168, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 168, LossG: 0.7457                                  \n",
      "[Training] Epoch: 169 [DONE]                                 \n",
      "[Training] Epoch: 169, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 169, LossG: 0.7457                                  \n",
      "[Training] Epoch: 170 [DONE]                                 \n",
      "[Training] Epoch: 170, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 170, LossG: 0.7457                                  \n",
      "[Training] Epoch: 171 [DONE]                                 \n",
      "[Training] Epoch: 171, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 171, LossG: 0.7457                                  \n",
      "[Training] Epoch: 172 [DONE]                                 \n",
      "[Training] Epoch: 172, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 172, LossG: 0.7459                                  \n",
      "[Training] Epoch: 173 [DONE]                                 \n",
      "[Training] Epoch: 173, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 173, LossG: 0.7458                                  \n",
      "[Training] Epoch: 174 [DONE]                                 \n",
      "[Training] Epoch: 174, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 174, LossG: 0.7459                                  \n",
      "[Training] Epoch: 175 [DONE]                                 \n",
      "[Training] Epoch: 175, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 175, LossG: 0.7458                                  \n",
      "[Training] Epoch: 176 [DONE]                                 \n",
      "[Training] Epoch: 176, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 176, LossG: 0.7457                                  \n",
      "[Training] Epoch: 177 [DONE]                                 \n",
      "[Training] Epoch: 177, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 177, LossG: 0.7457                                  \n",
      "[Training] Epoch: 178 [DONE]                                 \n",
      "[Training] Epoch: 178, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 178, LossG: 0.7457                                  \n",
      "[Training] Epoch: 179 [DONE]                                 \n",
      "[Training] Epoch: 179, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 179, LossG: 0.7458                                  \n",
      "[Training] Epoch: 180 [DONE]                                 \n",
      "[Training] Epoch: 180, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 180, LossG: 0.7459                                  \n",
      "[Training] Epoch: 181 [DONE]                                 \n",
      "[Training] Epoch: 181, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 181, LossG: 0.7457                                  \n",
      "[Training] Epoch: 182 [DONE]                                 \n",
      "[Training] Epoch: 182, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 182, LossG: 0.7458                                  \n",
      "[Training] Epoch: 183 [DONE]                                 \n",
      "[Training] Epoch: 183, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 183, LossG: 0.7457                                  \n",
      "[Training] Epoch: 184 [DONE]                                 \n",
      "[Training] Epoch: 184, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 184, LossG: 0.7457                                  \n",
      "[Training] Epoch: 185 [DONE]                                 \n",
      "[Training] Epoch: 185, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 185, LossG: 0.7457                                  \n",
      "[Training] Epoch: 186 [DONE]                                 \n",
      "[Training] Epoch: 186, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 186, LossG: 0.7457                                  \n",
      "[Training] Epoch: 187 [DONE]                                 \n",
      "[Training] Epoch: 187, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 187, LossG: 0.7457                                  \n",
      "[Training] Epoch: 188 [DONE]                                 \n",
      "[Training] Epoch: 188, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 188, LossG: 0.7458                                  \n",
      "[Training] Epoch: 189 [DONE]                                 \n",
      "[Training] Epoch: 189, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 189, LossG: 0.7457                                  \n",
      "[Training] Epoch: 190 [DONE]                                 \n",
      "[Training] Epoch: 190, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 190, LossG: 0.7457                                  \n",
      "[Training] Epoch: 191 [DONE]                                 \n",
      "[Training] Epoch: 191, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 191, LossG: 0.7456                                  \n",
      "[Training] Epoch: 192 [DONE]                                 \n",
      "[Training] Epoch: 192, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 192, LossG: 0.7457                                  \n",
      "[Training] Epoch: 193 [DONE]                                 \n",
      "[Training] Epoch: 193, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 193, LossG: 0.7457                                  \n",
      "[Training] Epoch: 194 [DONE]                                 \n",
      "[Training] Epoch: 194, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 194, LossG: 0.7457                                  \n",
      "[Training] Epoch: 195 [DONE]                                 \n",
      "[Training] Epoch: 195, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 195, LossG: 0.7457                                  \n",
      "[Training] Epoch: 196 [DONE]                                 \n",
      "[Training] Epoch: 196, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 196, LossG: 0.7457                                  \n",
      "[Training] Epoch: 197 [DONE]                                 \n",
      "[Training] Epoch: 197, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 197, LossG: 0.7457                                  \n",
      "[Training] Epoch: 198 [DONE]                                 \n",
      "[Training] Epoch: 198, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 198, LossG: 0.7457                                  \n",
      "[Training] Epoch: 199 [DONE]                                 \n",
      "[Training] Epoch: 199, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 199, LossG: 0.7457                                  \n",
      "[Training] Epoch: 200 [DONE]                                 \n",
      "[Training] Epoch: 200, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 200, LossG: 0.7457                                  \n",
      "[Training] Epoch: 201 [DONE]                                 \n",
      "[Training] Epoch: 201, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 201, LossG: 0.7457                                  \n",
      "[Training] Epoch: 202 [DONE]                                 \n",
      "[Training] Epoch: 202, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 202, LossG: 0.7456                                  \n",
      "[Training] Epoch: 203 [DONE]                                 \n",
      "[Training] Epoch: 203, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 203, LossG: 0.7457                                  \n",
      "[Training] Epoch: 204 [DONE]                                 \n",
      "[Training] Epoch: 204, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 204, LossG: 0.7456                                  \n",
      "[Training] Epoch: 205 [DONE]                                 \n",
      "[Training] Epoch: 205, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 205, LossG: 0.7457                                  \n",
      "[Training] Epoch: 206 [DONE]                                 \n",
      "[Training] Epoch: 206, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 206, LossG: 0.7457                                  \n",
      "[Training] Epoch: 207 [DONE]                                 \n",
      "[Training] Epoch: 207, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 207, LossG: 0.7457                                  \n",
      "[Training] Epoch: 208 [DONE]                                 \n",
      "[Training] Epoch: 208, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 208, LossG: 0.7456                                  \n",
      "[Training] Epoch: 209 [DONE]                                 \n",
      "[Training] Epoch: 209, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 209, LossG: 0.7457                                  \n",
      "[Training] Epoch: 210 [DONE]                                 \n",
      "[Training] Epoch: 210, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 210, LossG: 0.7456                                  \n",
      "[Training] Epoch: 211 [DONE]                                 \n",
      "[Training] Epoch: 211, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 211, LossG: 0.7458                                  \n",
      "[Training] Epoch: 212 [DONE]                                 \n",
      "[Training] Epoch: 212, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 212, LossG: 0.7456                                  \n",
      "[Training] Epoch: 213 [DONE]                                 \n",
      "[Training] Epoch: 213, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 213, LossG: 0.7456                                  \n",
      "[Training] Epoch: 214 [DONE]                                 \n",
      "[Training] Epoch: 214, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 214, LossG: 0.7456                                  \n",
      "[Training] Epoch: 215 [DONE]                                 \n",
      "[Training] Epoch: 215, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 215, LossG: 0.7456                                  \n",
      "[Training] Epoch: 216 [DONE]                                 \n",
      "[Training] Epoch: 216, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 216, LossG: 0.7456                                  \n",
      "[Training] Epoch: 217 [DONE]                                 \n",
      "[Training] Epoch: 217, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 217, LossG: 0.7456                                  \n",
      "[Training] Epoch: 218 [DONE]                                 \n",
      "[Training] Epoch: 218, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 218, LossG: 0.7457                                  \n",
      "[Training] Epoch: 219 [DONE]                                 \n",
      "[Training] Epoch: 219, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 219, LossG: 0.7457                                  \n",
      "[Training] Epoch: 220 [DONE]                                 \n",
      "[Training] Epoch: 220, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 220, LossG: 0.7458                                  \n",
      "[Training] Epoch: 221 [DONE]                                 \n",
      "[Training] Epoch: 221, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 221, LossG: 0.7458                                  \n",
      "[Training] Epoch: 222 [DONE]                                 \n",
      "[Training] Epoch: 222, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 222, LossG: 0.7457                                  \n",
      "[Training] Epoch: 223 [DONE]                                 \n",
      "[Training] Epoch: 223, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 223, LossG: 0.7458                                  \n",
      "[Training] Epoch: 224 [DONE]                                 \n",
      "[Training] Epoch: 224, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 224, LossG: 0.7458                                  \n",
      "[Training] Epoch: 225 [DONE]                                 \n",
      "[Training] Epoch: 225, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 225, LossG: 0.7457                                  \n",
      "[Training] Epoch: 226 [DONE]                                 \n",
      "[Training] Epoch: 226, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 226, LossG: 0.7457                                  \n",
      "[Training] Epoch: 227 [DONE]                                 \n",
      "[Training] Epoch: 227, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 227, LossG: 0.7457                                  \n",
      "[Training] Epoch: 228 [DONE]                                 \n",
      "[Training] Epoch: 228, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 228, LossG: 0.7457                                  \n",
      "[Training] Epoch: 229 [DONE]                                 \n",
      "[Training] Epoch: 229, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 229, LossG: 0.7457                                  \n",
      "[Training] Epoch: 230 [DONE]                                 \n",
      "[Training] Epoch: 230, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 230, LossG: 0.7457                                  \n",
      "[Training] Epoch: 231 [DONE]                                 \n",
      "[Training] Epoch: 231, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 231, LossG: 0.7456                                  \n",
      "[Training] Epoch: 232 [DONE]                                 \n",
      "[Training] Epoch: 232, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 232, LossG: 0.7457                                  \n",
      "[Training] Epoch: 233 [DONE]                                 \n",
      "[Training] Epoch: 233, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 233, LossG: 0.7456                                  \n",
      "[Training] Epoch: 234 [DONE]                                 \n",
      "[Training] Epoch: 234, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 234, LossG: 0.7457                                  \n",
      "[Training] Epoch: 235 [DONE]                                 \n",
      "[Training] Epoch: 235, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 235, LossG: 0.7457                                  \n",
      "[Training] Epoch: 236 [DONE]                                 \n",
      "[Training] Epoch: 236, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 236, LossG: 0.7457                                  \n",
      "[Training] Epoch: 237 [DONE]                                 \n",
      "[Training] Epoch: 237, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 237, LossG: 0.7457                                  \n",
      "[Training] Epoch: 238 [DONE]                                 \n",
      "[Training] Epoch: 238, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 238, LossG: 0.7457                                  \n",
      "[Training] Epoch: 239 [DONE]                                 \n",
      "[Training] Epoch: 239, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 239, LossG: 0.7457                                  \n",
      "[Training] Epoch: 240 [DONE]                                 \n",
      "[Training] Epoch: 240, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 240, LossG: 0.7456                                  \n",
      "[Training] Epoch: 241 [DONE]                                 \n",
      "[Training] Epoch: 241, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 241, LossG: 0.7457                                  \n",
      "[Training] Epoch: 242 [DONE]                                 \n",
      "[Training] Epoch: 242, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 242, LossG: 0.7456                                  \n",
      "[Training] Epoch: 243 [DONE]                                 \n",
      "[Training] Epoch: 243, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 243, LossG: 0.7459                                  \n",
      "[Training] Epoch: 244 [DONE]                                 \n",
      "[Training] Epoch: 244, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 244, LossG: 0.7462                                  \n",
      "[Training] Epoch: 245 [DONE]                                 \n",
      "[Training] Epoch: 245, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 245, LossG: 0.7460                                  \n",
      "[Training] Epoch: 246 [DONE]                                 \n",
      "[Training] Epoch: 246, LossG: 0.7461=================================================================] 100.0%\n",
      "[Validation] Epoch: 246, LossG: 0.7461                                  \n",
      "[Training] Epoch: 247 [DONE]                                 \n",
      "[Training] Epoch: 247, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 247, LossG: 0.7462                                  \n",
      "[Training] Epoch: 248 [DONE]                                 \n",
      "[Training] Epoch: 248, LossG: 0.7464=================================================================] 100.0%\n",
      "[Validation] Epoch: 248, LossG: 0.7464                                  \n",
      "[Training] Epoch: 249 [DONE]                                 \n",
      "[Training] Epoch: 249, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 249, LossG: 0.7462                                  \n",
      "[Training] Epoch: 250 [DONE]                                 \n",
      "[Training] Epoch: 250, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 250, LossG: 0.7460                                  \n",
      "[Training] Epoch: 251 [DONE]                                 \n",
      "[Training] Epoch: 251, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 251, LossG: 0.7459                                  \n",
      "[Training] Epoch: 252 [DONE]                                 \n",
      "[Training] Epoch: 252, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 252, LossG: 0.7458                                  \n",
      "[Training] Epoch: 253 [DONE]                                 \n",
      "[Training] Epoch: 253, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 253, LossG: 0.7460                                  \n",
      "[Training] Epoch: 254 [DONE]                                 \n",
      "[Training] Epoch: 254, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 254, LossG: 0.7458                                  \n",
      "[Training] Epoch: 255 [DONE]                                 \n",
      "[Training] Epoch: 255, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 255, LossG: 0.7458                                  \n",
      "[Training] Epoch: 256 [DONE]                                 \n",
      "[Training] Epoch: 256, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 256, LossG: 0.7457                                  \n",
      "[Training] Epoch: 257 [DONE]                                 \n",
      "[Training] Epoch: 257, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 257, LossG: 0.7458                                  \n",
      "[Training] Epoch: 258 [DONE]                                 \n",
      "[Training] Epoch: 258, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 258, LossG: 0.7458                                  \n",
      "[Training] Epoch: 259 [DONE]                                 \n",
      "[Training] Epoch: 259, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 259, LossG: 0.7459                                  \n",
      "[Training] Epoch: 260 [DONE]                                 \n",
      "[Training] Epoch: 260, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 260, LossG: 0.7458                                  \n",
      "[Training] Epoch: 261 [DONE]                                 \n",
      "[Training] Epoch: 261, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 261, LossG: 0.7457                                  \n",
      "[Training] Epoch: 262 [DONE]                                 \n",
      "[Training] Epoch: 262, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 262, LossG: 0.7457                                  \n",
      "[Training] Epoch: 263 [DONE]                                 \n",
      "[Training] Epoch: 263, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 263, LossG: 0.7457                                  \n",
      "[Training] Epoch: 264 [DONE]                                 \n",
      "[Training] Epoch: 264, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 264, LossG: 0.7457                                  \n",
      "[Training] Epoch: 265 [DONE]                                 \n",
      "[Training] Epoch: 265, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 265, LossG: 0.7458                                  \n",
      "[Training] Epoch: 266 [DONE]                                 \n",
      "[Training] Epoch: 266, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 266, LossG: 0.7457                                  \n",
      "[Training] Epoch: 267 [DONE]                                 \n",
      "[Training] Epoch: 267, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 267, LossG: 0.7456                                  \n",
      "[Training] Epoch: 268 [DONE]                                 \n",
      "[Training] Epoch: 268, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 268, LossG: 0.7456                                  \n",
      "[Training] Epoch: 269 [DONE]                                 \n",
      "[Training] Epoch: 269, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 269, LossG: 0.7458                                  \n",
      "[Training] Epoch: 270 [DONE]                                 \n",
      "[Training] Epoch: 270, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 270, LossG: 0.7458                                  \n",
      "[Training] Epoch: 271 [DONE]                                 \n",
      "[Training] Epoch: 271, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 271, LossG: 0.7457                                  \n",
      "[Training] Epoch: 272 [DONE]                                 \n",
      "[Training] Epoch: 272, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 272, LossG: 0.7456                                  \n",
      "[Training] Epoch: 273 [DONE]                                 \n",
      "[Training] Epoch: 273, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 273, LossG: 0.7456                                  \n",
      "[Training] Epoch: 274 [DONE]                                 \n",
      "[Training] Epoch: 274, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 274, LossG: 0.7456                                  \n",
      "[Training] Epoch: 275 [DONE]                                 \n",
      "[Training] Epoch: 275, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 275, LossG: 0.7457                                  \n",
      "[Training] Epoch: 276 [DONE]                                 \n",
      "[Training] Epoch: 276, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 276, LossG: 0.7456                                  \n",
      "[Training] Epoch: 277 [DONE]                                 \n",
      "[Training] Epoch: 277, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 277, LossG: 0.7456                                  \n",
      "[Training] Epoch: 278 [DONE]                                 \n",
      "[Training] Epoch: 278, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 278, LossG: 0.7457                                  \n",
      "[Training] Epoch: 279 [DONE]                                 \n",
      "[Training] Epoch: 279, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 279, LossG: 0.7457                                  \n",
      "[Training] Epoch: 280 [DONE]                                 \n",
      "[Training] Epoch: 280, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 280, LossG: 0.7456                                  \n",
      "[Training] Epoch: 281 [DONE]                                 \n",
      "[Training] Epoch: 281, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 281, LossG: 0.7456                                  \n",
      "[Training] Epoch: 282 [DONE]                                 \n",
      "[Training] Epoch: 282, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 282, LossG: 0.7457                                  \n",
      "[Training] Epoch: 283 [DONE]                                 \n",
      "[Training] Epoch: 283, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 283, LossG: 0.7456                                  \n",
      "[Training] Epoch: 284 [DONE]                                 \n",
      "[Training] Epoch: 284, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 284, LossG: 0.7456                                  \n",
      "[Training] Epoch: 285 [DONE]                                 \n",
      "[Training] Epoch: 285, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 285, LossG: 0.7456                                  \n",
      "[Training] Epoch: 286 [DONE]                                 \n",
      "[Training] Epoch: 286, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 286, LossG: 0.7456                                  \n",
      "[Training] Epoch: 287 [DONE]                                 \n",
      "[Training] Epoch: 287, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 287, LossG: 0.7456                                  \n",
      "[Training] Epoch: 288 [DONE]                                 \n",
      "[Training] Epoch: 288, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 288, LossG: 0.7456                                  \n",
      "[Training] Epoch: 289 [DONE]                                 \n",
      "[Training] Epoch: 289, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 289, LossG: 0.7456                                  \n",
      "[Training] Epoch: 290 [DONE]                                 \n",
      "[Training] Epoch: 290, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 290, LossG: 0.7457                                  \n",
      "[Training] Epoch: 291 [DONE]                                 \n",
      "[Training] Epoch: 291, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 291, LossG: 0.7459                                  \n",
      "[Training] Epoch: 292 [DONE]                                 \n",
      "[Training] Epoch: 292, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 292, LossG: 0.7458                                  \n",
      "[Training] Epoch: 293 [DONE]                                 \n",
      "[Training] Epoch: 293, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 293, LossG: 0.7458                                  \n",
      "[Training] Epoch: 294 [DONE]                                 \n",
      "[Training] Epoch: 294, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 294, LossG: 0.7458                                  \n",
      "[Training] Epoch: 295 [DONE]                                 \n",
      "[Training] Epoch: 295, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 295, LossG: 0.7457                                  \n",
      "[Training] Epoch: 296 [DONE]                                 \n",
      "[Training] Epoch: 296, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 296, LossG: 0.7457                                  \n",
      "[Training] Epoch: 297 [DONE]                                 \n",
      "[Training] Epoch: 297, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 297, LossG: 0.7456                                  \n",
      "[Training] Epoch: 298 [DONE]                                 \n",
      "[Training] Epoch: 298, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 298, LossG: 0.7456                                  \n",
      "[Training] Epoch: 299 [DONE]                                 \n",
      "[Training] Epoch: 299, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 299, LossG: 0.7457                                  \n",
      "[Training] Epoch: 300 [DONE]                                 \n",
      "[Training] Epoch: 300, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 300, LossG: 0.7457                                  \n",
      "[Training] Epoch: 301 [DONE]                                 \n",
      "[Training] Epoch: 301, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 301, LossG: 0.7456                                  \n",
      "[Training] Epoch: 302 [DONE]                                 \n",
      "[Training] Epoch: 302, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 302, LossG: 0.7456                                  \n",
      "[Training] Epoch: 303 [DONE]                                 \n",
      "[Training] Epoch: 303, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 303, LossG: 0.7456                                  \n",
      "[Training] Epoch: 304 [DONE]                                 \n",
      "[Training] Epoch: 304, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 304, LossG: 0.7456                                  \n",
      "[Training] Epoch: 305 [DONE]                                 \n",
      "[Training] Epoch: 305, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 305, LossG: 0.7456                                  \n",
      "[Training] Epoch: 306 [DONE]                                 \n",
      "[Training] Epoch: 306, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 306, LossG: 0.7457                                  \n",
      "[Training] Epoch: 307 [DONE]                                 \n",
      "[Training] Epoch: 307, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 307, LossG: 0.7456                                  \n",
      "[Training] Epoch: 308 [DONE]                                 \n",
      "[Training] Epoch: 308, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 308, LossG: 0.7457                                  \n",
      "[Training] Epoch: 309 [DONE]                                 \n",
      "[Training] Epoch: 309, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 309, LossG: 0.7457                                  \n",
      "[Training] Epoch: 310 [DONE]                                 \n",
      "[Training] Epoch: 310, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 310, LossG: 0.7459                                  \n",
      "[Training] Epoch: 311 [DONE]                                 \n",
      "[Training] Epoch: 311, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 311, LossG: 0.7459                                  \n",
      "[Training] Epoch: 312 [DONE]                                 \n",
      "[Training] Epoch: 312, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 312, LossG: 0.7459                                  \n",
      "[Training] Epoch: 313 [DONE]                                 \n",
      "[Training] Epoch: 313, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 313, LossG: 0.7457                                  \n",
      "[Training] Epoch: 314 [DONE]                                 \n",
      "[Training] Epoch: 314, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 314, LossG: 0.7459                                  \n",
      "[Training] Epoch: 315 [DONE]                                 \n",
      "[Training] Epoch: 315, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 315, LossG: 0.7457                                  \n",
      "[Training] Epoch: 316 [DONE]                                 \n",
      "[Training] Epoch: 316, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 316, LossG: 0.7457                                  \n",
      "[Training] Epoch: 317 [DONE]                                 \n",
      "[Training] Epoch: 317, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 317, LossG: 0.7457                                  \n",
      "[Training] Epoch: 318 [DONE]                                 \n",
      "[Training] Epoch: 318, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 318, LossG: 0.7456                                  \n",
      "[Training] Epoch: 319 [DONE]                                 \n",
      "[Training] Epoch: 319, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 319, LossG: 0.7456                                  \n",
      "[Training] Epoch: 320 [DONE]                                 \n",
      "[Training] Epoch: 320, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 320, LossG: 0.7456                                  \n",
      "[Training] Epoch: 321 [DONE]                                 \n",
      "[Training] Epoch: 321, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 321, LossG: 0.7457                                  \n",
      "[Training] Epoch: 322 [DONE]                                 \n",
      "[Training] Epoch: 322, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 322, LossG: 0.7457                                  \n",
      "[Training] Epoch: 323 [DONE]                                 \n",
      "[Training] Epoch: 323, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 323, LossG: 0.7458                                  \n",
      "[Training] Epoch: 324 [DONE]                                 \n",
      "[Training] Epoch: 324, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 324, LossG: 0.7457                                  \n",
      "[Training] Epoch: 325 [DONE]                                 \n",
      "[Training] Epoch: 325, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 325, LossG: 0.7457                                  \n",
      "[Training] Epoch: 326 [DONE]                                 \n",
      "[Training] Epoch: 326, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 326, LossG: 0.7457                                  \n",
      "[Training] Epoch: 327 [DONE]                                 \n",
      "[Training] Epoch: 327, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 327, LossG: 0.7458                                  \n",
      "[Training] Epoch: 328 [DONE]                                 \n",
      "[Training] Epoch: 328, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 328, LossG: 0.7457                                  \n",
      "[Training] Epoch: 329 [DONE]                                 \n",
      "[Training] Epoch: 329, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 329, LossG: 0.7457                                  \n",
      "[Training] Epoch: 330 [DONE]                                 \n",
      "[Training] Epoch: 330, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 330, LossG: 0.7457                                  \n",
      "[Training] Epoch: 331 [DONE]                                 \n",
      "[Training] Epoch: 331, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 331, LossG: 0.7458                                  \n",
      "[Training] Epoch: 332 [DONE]                                 \n",
      "[Training] Epoch: 332, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 332, LossG: 0.7458                                  \n",
      "[Training] Epoch: 333 [DONE]                                 \n",
      "[Training] Epoch: 333, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 333, LossG: 0.7458                                  \n",
      "[Training] Epoch: 334 [DONE]                                 \n",
      "[Training] Epoch: 334, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 334, LossG: 0.7458                                  \n",
      "[Training] Epoch: 335 [DONE]                                 \n",
      "[Training] Epoch: 335, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 335, LossG: 0.7456                                  \n",
      "[Training] Epoch: 336 [DONE]                                 \n",
      "[Training] Epoch: 336, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 336, LossG: 0.7456                                  \n",
      "[Training] Epoch: 337 [DONE]                                 \n",
      "[Training] Epoch: 337, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 337, LossG: 0.7457                                  \n",
      "[Training] Epoch: 338 [DONE]                                 \n",
      "[Training] Epoch: 338, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 338, LossG: 0.7456                                  \n",
      "[Training] Epoch: 339 [DONE]                                 \n",
      "[Training] Epoch: 339, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 339, LossG: 0.7456                                  \n",
      "[Training] Epoch: 340 [DONE]                                 \n",
      "[Training] Epoch: 340, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 340, LossG: 0.7457                                  \n",
      "[Training] Epoch: 341 [DONE]                                 \n",
      "[Training] Epoch: 341, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 341, LossG: 0.7456                                  \n",
      "[Training] Epoch: 342 [DONE]                                 \n",
      "[Training] Epoch: 342, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 342, LossG: 0.7456                                  \n",
      "[Training] Epoch: 343 [DONE]                                 \n",
      "[Training] Epoch: 343, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 343, LossG: 0.7456                                  \n",
      "[Training] Epoch: 344 [DONE]                                 \n",
      "[Training] Epoch: 344, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 344, LossG: 0.7456                                  \n",
      "[Training] Epoch: 345 [DONE]                                 \n",
      "[Training] Epoch: 345, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 345, LossG: 0.7455                                  \n",
      "[Training] Epoch: 346 [DONE]                                 \n",
      "[Training] Epoch: 346, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 346, LossG: 0.7456                                  \n",
      "[Training] Epoch: 347 [DONE]                                 \n",
      "[Training] Epoch: 347, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 347, LossG: 0.7456                                  \n",
      "[Training] Epoch: 348 [DONE]                                 \n",
      "[Training] Epoch: 348, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 348, LossG: 0.7457                                  \n",
      "[Training] Epoch: 349 [DONE]                                 \n",
      "[Training] Epoch: 349, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 349, LossG: 0.7457                                  \n",
      "[Training] Epoch: 350 [DONE]                                 \n",
      "[Training] Epoch: 350, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 350, LossG: 0.7456                                  \n",
      "[Training] Epoch: 351 [DONE]                                 \n",
      "[Training] Epoch: 351, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 351, LossG: 0.7456                                  \n",
      "[Training] Epoch: 352 [DONE]                                 \n",
      "[Training] Epoch: 352, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 352, LossG: 0.7456                                  \n",
      "[Training] Epoch: 353 [DONE]                                 \n",
      "[Training] Epoch: 353, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 353, LossG: 0.7456                                  \n",
      "[Training] Epoch: 354 [DONE]                                 \n",
      "[Training] Epoch: 354, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 354, LossG: 0.7456                                  \n",
      "[Training] Epoch: 355 [DONE]                                 \n",
      "[Training] Epoch: 355, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 355, LossG: 0.7456                                  \n",
      "[Training] Epoch: 356 [DONE]                                 \n",
      "[Training] Epoch: 356, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 356, LossG: 0.7455                                  \n",
      "[Training] Epoch: 357 [DONE]                                 \n",
      "[Training] Epoch: 357, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 357, LossG: 0.7455                                  \n",
      "[Training] Epoch: 358 [DONE]                                 \n",
      "[Training] Epoch: 358, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 358, LossG: 0.7456                                  \n",
      "[Training] Epoch: 359 [DONE]                                 \n",
      "[Training] Epoch: 359, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 359, LossG: 0.7456                                  \n",
      "[Training] Epoch: 360 [DONE]                                 \n",
      "[Training] Epoch: 360, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 360, LossG: 0.7457                                  \n",
      "[Training] Epoch: 361 [DONE]                                 \n",
      "[Training] Epoch: 361, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 361, LossG: 0.7455                                  \n",
      "[Training] Epoch: 362 [DONE]                                 \n",
      "[Training] Epoch: 362, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 362, LossG: 0.7456                                  \n",
      "[Training] Epoch: 363 [DONE]                                 \n",
      "[Training] Epoch: 363, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 363, LossG: 0.7456                                  \n",
      "[Training] Epoch: 364 [DONE]                                 \n",
      "[Training] Epoch: 364, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 364, LossG: 0.7455                                  \n",
      "[Training] Epoch: 365 [DONE]                                 \n",
      "[Training] Epoch: 365, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 365, LossG: 0.7455                                  \n",
      "[Training] Epoch: 366 [DONE]                                 \n",
      "[Training] Epoch: 366, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 366, LossG: 0.7455                                  \n",
      "[Training] Epoch: 367 [DONE]                                 \n",
      "[Training] Epoch: 367, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 367, LossG: 0.7455                                  \n",
      "[Training] Epoch: 368 [DONE]                                 \n",
      "[Training] Epoch: 368, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 368, LossG: 0.7455                                  \n",
      "[Training] Epoch: 369 [DONE]                                 \n",
      "[Training] Epoch: 369, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 369, LossG: 0.7456                                  \n",
      "[Training] Epoch: 370 [DONE]                                 \n",
      "[Training] Epoch: 370, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 370, LossG: 0.7456                                  \n",
      "[Training] Epoch: 371 [DONE]                                 \n",
      "[Training] Epoch: 371, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 371, LossG: 0.7456                                  \n",
      "[Training] Epoch: 372 [DONE]                                 \n",
      "[Training] Epoch: 372, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 372, LossG: 0.7456                                  \n",
      "[Training] Epoch: 373 [DONE]                                 \n",
      "[Training] Epoch: 373, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 373, LossG: 0.7455                                  \n",
      "[Training] Epoch: 374 [DONE]                                 \n",
      "[Training] Epoch: 374, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 374, LossG: 0.7455                                  \n",
      "[Training] Epoch: 375 [DONE]                                 \n",
      "[Training] Epoch: 375, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 375, LossG: 0.7456                                  \n",
      "[Training] Epoch: 376 [DONE]                                 \n",
      "[Training] Epoch: 376, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 376, LossG: 0.7456                                  \n",
      "[Training] Epoch: 377 [DONE]                                 \n",
      "[Training] Epoch: 377, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 377, LossG: 0.7456                                  \n",
      "[Training] Epoch: 378 [DONE]                                 \n",
      "[Training] Epoch: 378, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 378, LossG: 0.7456                                  \n",
      "[Training] Epoch: 379 [DONE]                                 \n",
      "[Training] Epoch: 379, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 379, LossG: 0.7456                                  \n",
      "[Training] Epoch: 380 [DONE]                                 \n",
      "[Training] Epoch: 380, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 380, LossG: 0.7456                                  \n",
      "[Training] Epoch: 381 [DONE]                                 \n",
      "[Training] Epoch: 381, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 381, LossG: 0.7456                                  \n",
      "[Training] Epoch: 382 [DONE]                                 \n",
      "[Training] Epoch: 382, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 382, LossG: 0.7456                                  \n",
      "[Training] Epoch: 383 [DONE]                                 \n",
      "[Training] Epoch: 383, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 383, LossG: 0.7455                                  \n",
      "[Training] Epoch: 384 [DONE]                                 \n",
      "[Training] Epoch: 384, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 384, LossG: 0.7456                                  \n",
      "[Training] Epoch: 385 [DONE]                                 \n",
      "[Training] Epoch: 385, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 385, LossG: 0.7455                                  \n",
      "[Training] Epoch: 386 [DONE]                                 \n",
      "[Training] Epoch: 386, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 386, LossG: 0.7456                                  \n",
      "[Training] Epoch: 387 [DONE]                                 \n",
      "[Training] Epoch: 387, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 387, LossG: 0.7456                                  \n",
      "[Training] Epoch: 388 [DONE]                                 \n",
      "[Training] Epoch: 388, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 388, LossG: 0.7455                                  \n",
      "[Training] Epoch: 389 [DONE]                                 \n",
      "[Training] Epoch: 389, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 389, LossG: 0.7455                                  \n",
      "[Training] Epoch: 390 [DONE]                                 \n",
      "[Training] Epoch: 390, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 390, LossG: 0.7456                                  \n",
      "[Training] Epoch: 391 [DONE]                                 \n",
      "[Training] Epoch: 391, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 391, LossG: 0.7455                                  \n",
      "[Training] Epoch: 392 [DONE]                                 \n",
      "[Training] Epoch: 392, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 392, LossG: 0.7456                                  \n",
      "[Training] Epoch: 393 [DONE]                                 \n",
      "[Training] Epoch: 393, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 393, LossG: 0.7455                                  \n",
      "[Training] Epoch: 394 [DONE]                                 \n",
      "[Training] Epoch: 394, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 394, LossG: 0.7455                                  \n",
      "[Training] Epoch: 395 [DONE]                                 \n",
      "[Training] Epoch: 395, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 395, LossG: 0.7455                                  \n",
      "[Training] Epoch: 396 [DONE]                                 \n",
      "[Training] Epoch: 396, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 396, LossG: 0.7456                                  \n",
      "[Training] Epoch: 397 [DONE]                                 \n",
      "[Training] Epoch: 397, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 397, LossG: 0.7455                                  \n",
      "[Training] Epoch: 398 [DONE]                                 \n",
      "[Training] Epoch: 398, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 398, LossG: 0.7457                                  \n",
      "[Training] Epoch: 399 [DONE]                                 \n",
      "[Training] Epoch: 399, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 399, LossG: 0.7457                                  \n",
      "[Training] Epoch: 400 [DONE]                                 \n",
      "[Training] Epoch: 400, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 400, LossG: 0.7457                                  \n",
      "[Training] Epoch: 401 [DONE]                                 \n",
      "[Training] Epoch: 401, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 401, LossG: 0.7456                                  \n",
      "[Training] Epoch: 402 [DONE]                                 \n",
      "[Training] Epoch: 402, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 402, LossG: 0.7457                                  \n",
      "[Training] Epoch: 403 [DONE]                                 \n",
      "[Training] Epoch: 403, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 403, LossG: 0.7455                                  \n",
      "[Training] Epoch: 404 [DONE]                                 \n",
      "[Training] Epoch: 404, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 404, LossG: 0.7456                                  \n",
      "[Training] Epoch: 405 [DONE]                                 \n",
      "[Training] Epoch: 405, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 405, LossG: 0.7456                                  \n",
      "[Training] Epoch: 406 [DONE]                                 \n",
      "[Training] Epoch: 406, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 406, LossG: 0.7456                                  \n",
      "[Training] Epoch: 407 [DONE]                                 \n",
      "[Training] Epoch: 407, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 407, LossG: 0.7456                                  \n",
      "[Training] Epoch: 408 [DONE]                                 \n",
      "[Training] Epoch: 408, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 408, LossG: 0.7456                                  \n",
      "[Training] Epoch: 409 [DONE]                                 \n",
      "[Training] Epoch: 409, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 409, LossG: 0.7455                                  \n",
      "[Training] Epoch: 410 [DONE]                                 \n",
      "[Training] Epoch: 410, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 410, LossG: 0.7455                                  \n",
      "[Training] Epoch: 411 [DONE]                                 \n",
      "[Training] Epoch: 411, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 411, LossG: 0.7456                                  \n",
      "[Training] Epoch: 412 [DONE]                                 \n",
      "[Training] Epoch: 412, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 412, LossG: 0.7455                                  \n",
      "[Training] Epoch: 413 [DONE]                                 \n",
      "[Training] Epoch: 413, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 413, LossG: 0.7456                                  \n",
      "[Training] Epoch: 414 [DONE]                                 \n",
      "[Training] Epoch: 414, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 414, LossG: 0.7457                                  \n",
      "[Training] Epoch: 415 [DONE]                                 \n",
      "[Training] Epoch: 415, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 415, LossG: 0.7457                                  \n",
      "[Training] Epoch: 416 [DONE]                                 \n",
      "[Training] Epoch: 416, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 416, LossG: 0.7456                                  \n",
      "[Training] Epoch: 417 [DONE]                                 \n",
      "[Training] Epoch: 417, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 417, LossG: 0.7456                                  \n",
      "[Training] Epoch: 418 [DONE]                                 \n",
      "[Training] Epoch: 418, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 418, LossG: 0.7456                                  \n",
      "[Training] Epoch: 419 [DONE]                                 \n",
      "[Training] Epoch: 419, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 419, LossG: 0.7455                                  \n",
      "[Training] Epoch: 420 [DONE]                                 \n",
      "[Training] Epoch: 420, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 420, LossG: 0.7456                                  \n",
      "[Training] Epoch: 421 [DONE]                                 \n",
      "[Training] Epoch: 421, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 421, LossG: 0.7455                                  \n",
      "[Training] Epoch: 422 [DONE]                                 \n",
      "[Training] Epoch: 422, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 422, LossG: 0.7456                                  \n",
      "[Training] Epoch: 423 [DONE]                                 \n",
      "[Training] Epoch: 423, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 423, LossG: 0.7456                                  \n",
      "[Training] Epoch: 424 [DONE]                                 \n",
      "[Training] Epoch: 424, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 424, LossG: 0.7456                                  \n",
      "[Training] Epoch: 425 [DONE]                                 \n",
      "[Training] Epoch: 425, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 425, LossG: 0.7456                                  \n",
      "[Training] Epoch: 426 [DONE]                                 \n",
      "[Training] Epoch: 426, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 426, LossG: 0.7456                                  \n",
      "[Training] Epoch: 427 [DONE]                                 \n",
      "[Training] Epoch: 427, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 427, LossG: 0.7456                                  \n",
      "[Training] Epoch: 428 [DONE]                                 \n",
      "[Training] Epoch: 428, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 428, LossG: 0.7455                                  \n",
      "[Training] Epoch: 429 [DONE]                                 \n",
      "[Training] Epoch: 429, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 429, LossG: 0.7455                                  \n",
      "[Training] Epoch: 430 [DONE]                                 \n",
      "[Training] Epoch: 430, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 430, LossG: 0.7456                                  \n",
      "[Training] Epoch: 431 [DONE]                                 \n",
      "[Training] Epoch: 431, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 431, LossG: 0.7455                                  \n",
      "[Training] Epoch: 432 [DONE]                                 \n",
      "[Training] Epoch: 432, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 432, LossG: 0.7455                                  \n",
      "[Training] Epoch: 433 [DONE]                                 \n",
      "[Training] Epoch: 433, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 433, LossG: 0.7455                                  \n",
      "[Training] Epoch: 434 [DONE]                                 \n",
      "[Training] Epoch: 434, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 434, LossG: 0.7456                                  \n",
      "[Training] Epoch: 435 [DONE]                                 \n",
      "[Training] Epoch: 435, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 435, LossG: 0.7457                                  \n",
      "[Training] Epoch: 436 [DONE]                                 \n",
      "[Training] Epoch: 436, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 436, LossG: 0.7455                                  \n",
      "[Training] Epoch: 437 [DONE]                                 \n",
      "[Training] Epoch: 437, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 437, LossG: 0.7456                                  \n",
      "[Training] Epoch: 438 [DONE]                                 \n",
      "[Training] Epoch: 438, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 438, LossG: 0.7455                                  \n",
      "[Training] Epoch: 439 [DONE]                                 \n",
      "[Training] Epoch: 439, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 439, LossG: 0.7455                                  \n",
      "[Training] Epoch: 440 [DONE]                                 \n",
      "[Training] Epoch: 440, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 440, LossG: 0.7456                                  \n",
      "[Training] Epoch: 441 [DONE]                                 \n",
      "[Training] Epoch: 441, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 441, LossG: 0.7456                                  \n",
      "[Training] Epoch: 442 [DONE]                                 \n",
      "[Training] Epoch: 442, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 442, LossG: 0.7455                                  \n",
      "[Training] Epoch: 443 [DONE]                                 \n",
      "[Training] Epoch: 443, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 443, LossG: 0.7455                                  \n",
      "[Training] Epoch: 444 [DONE]                                 \n",
      "[Training] Epoch: 444, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 444, LossG: 0.7456                                  \n",
      "[Training] Epoch: 445 [DONE]                                 \n",
      "[Training] Epoch: 445, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 445, LossG: 0.7456                                  \n",
      "[Training] Epoch: 446 [DONE]                                 \n",
      "[Training] Epoch: 446, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 446, LossG: 0.7456                                  \n",
      "[Training] Epoch: 447 [DONE]                                 \n",
      "[Training] Epoch: 447, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 447, LossG: 0.7456                                  \n",
      "[Training] Epoch: 448 [DONE]                                 \n",
      "[Training] Epoch: 448, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 448, LossG: 0.7456                                  \n",
      "Epoch: 448\n",
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      " Model loaded: ./models/Test_Model/448_Epoch\n",
      "Total params: 1,769,492\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 0.7457===================================================================] 100.0%\n",
      "[Validation] Epoch: 0, LossG: 0.7457                                      \n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 0.7456===================================================================] 100.0%\n",
      "[Validation] Epoch: 1, LossG: 0.7456                                      \n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 0.7456===================================================================] 100.0%\n",
      "[Validation] Epoch: 2, LossG: 0.7456                                      \n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 0.7455===================================================================] 100.0%\n",
      "[Validation] Epoch: 3, LossG: 0.7455                                      \n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 0.7456===================================================================] 100.0%\n",
      "[Validation] Epoch: 4, LossG: 0.7456                                      \n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 0.7456===================================================================] 100.0%\n",
      "[Validation] Epoch: 5, LossG: 0.7456                                      \n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 0.7456===================================================================] 100.0%\n",
      "[Validation] Epoch: 6, LossG: 0.7456                                      \n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 0.7457===================================================================] 100.0%\n",
      "[Validation] Epoch: 7, LossG: 0.7457                                      \n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 0.7456===================================================================] 100.0%\n",
      "[Validation] Epoch: 8, LossG: 0.7456                                      \n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 0.7456===================================================================] 100.0%\n",
      "[Validation] Epoch: 9, LossG: 0.7456                                      \n",
      "[Training] Epoch: 10 [DONE]                                 \n",
      "[Training] Epoch: 10, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 10, LossG: 0.7455                                    \n",
      "[Training] Epoch: 11 [DONE]                                 \n",
      "[Training] Epoch: 11, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 11, LossG: 0.7455                                    \n",
      "[Training] Epoch: 12 [DONE]                                 \n",
      "[Training] Epoch: 12, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 12, LossG: 0.7456                                    \n",
      "[Training] Epoch: 13 [DONE]                                 \n",
      "[Training] Epoch: 13, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 13, LossG: 0.7456                                    \n",
      "[Training] Epoch: 14 [DONE]                                 \n",
      "[Training] Epoch: 14, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 14, LossG: 0.7456                                    \n",
      "[Training] Epoch: 15 [DONE]                                 \n",
      "[Training] Epoch: 15, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 15, LossG: 0.7456                                    \n",
      "[Training] Epoch: 16 [DONE]                                 \n",
      "[Training] Epoch: 16, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 16, LossG: 0.7458                                    \n",
      "[Training] Epoch: 17 [DONE]                                 \n",
      "[Training] Epoch: 17, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 17, LossG: 0.7456                                    \n",
      "[Training] Epoch: 18 [DONE]                                 \n",
      "[Training] Epoch: 18, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 18, LossG: 0.7456                                    \n",
      "[Training] Epoch: 19 [DONE]                                 \n",
      "[Training] Epoch: 19, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 19, LossG: 0.7457                                    \n",
      "[Training] Epoch: 20 [DONE]                                 \n",
      "[Training] Epoch: 20, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 20, LossG: 0.7456                                    \n",
      "[Training] Epoch: 21 [DONE]                                 \n",
      "[Training] Epoch: 21, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 21, LossG: 0.7456                                    \n",
      "[Training] Epoch: 22 [DONE]                                 \n",
      "[Training] Epoch: 22, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 22, LossG: 0.7456                                    \n",
      "[Training] Epoch: 23 [DONE]                                 \n",
      "[Training] Epoch: 23, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 23, LossG: 0.7455                                    \n",
      "[Training] Epoch: 24 [DONE]                                 \n",
      "[Training] Epoch: 24, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 24, LossG: 0.7455                                    \n",
      "[Training] Epoch: 25 [DONE]                                 \n",
      "[Training] Epoch: 25, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 25, LossG: 0.7455                                    \n",
      "[Training] Epoch: 26 [DONE]                                 \n",
      "[Training] Epoch: 26, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 26, LossG: 0.7455                                    \n",
      "[Training] Epoch: 27 [DONE]                                 \n",
      "[Training] Epoch: 27, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 27, LossG: 0.7456                                    \n",
      "[Training] Epoch: 28 [DONE]                                 \n",
      "[Training] Epoch: 28, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 28, LossG: 0.7459                                    \n",
      "[Training] Epoch: 29 [DONE]                                 \n",
      "[Training] Epoch: 29, LossG: 0.7465==================================================================] 100.0%\n",
      "[Validation] Epoch: 29, LossG: 0.7465                                    \n",
      "[Training] Epoch: 30 [DONE]                                 \n",
      "[Training] Epoch: 30, LossG: 0.7461==================================================================] 100.0%\n",
      "[Validation] Epoch: 30, LossG: 0.7461                                    \n",
      "[Training] Epoch: 31 [DONE]                                 \n",
      "[Training] Epoch: 31, LossG: 0.7459==================================================================] 100.0%\n",
      "[Validation] Epoch: 31, LossG: 0.7459                                    \n",
      "[Training] Epoch: 32 [DONE]                                 \n",
      "[Training] Epoch: 32, LossG: 0.7458==================================================================] 100.0%\n",
      "[Validation] Epoch: 32, LossG: 0.7458                                    \n",
      "[Training] Epoch: 33 [DONE]                                 \n",
      "[Training] Epoch: 33, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 33, LossG: 0.7457                                    \n",
      "[Training] Epoch: 34 [DONE]                                 \n",
      "[Training] Epoch: 34, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 34, LossG: 0.7456                                    \n",
      "[Training] Epoch: 35 [DONE]                                 \n",
      "[Training] Epoch: 35, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 35, LossG: 0.7456                                    \n",
      "[Training] Epoch: 36 [DONE]                                 \n",
      "[Training] Epoch: 36, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 36, LossG: 0.7456                                    \n",
      "[Training] Epoch: 37 [DONE]                                 \n",
      "[Training] Epoch: 37, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 37, LossG: 0.7455                                    \n",
      "[Training] Epoch: 38 [DONE]                                 \n",
      "[Training] Epoch: 38, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 38, LossG: 0.7455                                    \n",
      "[Training] Epoch: 39 [DONE]                                 \n",
      "[Training] Epoch: 39, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 39, LossG: 0.7456                                    \n",
      "[Training] Epoch: 40 [DONE]                                 \n",
      "[Training] Epoch: 40, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 40, LossG: 0.7455                                    \n",
      "[Training] Epoch: 41 [DONE]                                 \n",
      "[Training] Epoch: 41, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 41, LossG: 0.7456                                    \n",
      "[Training] Epoch: 42 [DONE]                                 \n",
      "[Training] Epoch: 42, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 42, LossG: 0.7456                                    \n",
      "[Training] Epoch: 43 [DONE]                                 \n",
      "[Training] Epoch: 43, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 43, LossG: 0.7454                                    \n",
      "[Training] Epoch: 44 [DONE]                                 \n",
      "[Training] Epoch: 44, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 44, LossG: 0.7456                                    \n",
      "[Training] Epoch: 45 [DONE]                                 \n",
      "[Training] Epoch: 45, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 45, LossG: 0.7456                                    \n",
      "[Training] Epoch: 46 [DONE]                                 \n",
      "[Training] Epoch: 46, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 46, LossG: 0.7456                                    \n",
      "[Training] Epoch: 47 [DONE]                                 \n",
      "[Training] Epoch: 47, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 47, LossG: 0.7456                                    \n",
      "[Training] Epoch: 48 [DONE]                                 \n",
      "[Training] Epoch: 48, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 48, LossG: 0.7456                                    \n",
      "[Training] Epoch: 49 [DONE]                                 \n",
      "[Training] Epoch: 49, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 49, LossG: 0.7457                                    \n",
      "[Training] Epoch: 50 [DONE]                                 \n",
      "[Training] Epoch: 50, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 50, LossG: 0.7457                                    \n",
      "[Training] Epoch: 51 [DONE]                                 \n",
      "[Training] Epoch: 51, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 51, LossG: 0.7456                                    \n",
      "[Training] Epoch: 52 [DONE]                                 \n",
      "[Training] Epoch: 52, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 52, LossG: 0.7456                                    \n",
      "[Training] Epoch: 53 [DONE]                                 \n",
      "[Training] Epoch: 53, LossG: 0.7457==================================================================] 100.0%\n",
      "[Validation] Epoch: 53, LossG: 0.7457                                    \n",
      "[Training] Epoch: 54 [DONE]                                 \n",
      "[Training] Epoch: 54, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 54, LossG: 0.7456                                    \n",
      "[Training] Epoch: 55 [DONE]                                 \n",
      "[Training] Epoch: 55, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 55, LossG: 0.7456                                    \n",
      "[Training] Epoch: 56 [DONE]                                 \n",
      "[Training] Epoch: 56, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 56, LossG: 0.7455                                    \n",
      "[Training] Epoch: 57 [DONE]                                 \n",
      "[Training] Epoch: 57, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 57, LossG: 0.7455                                    \n",
      "[Training] Epoch: 58 [DONE]                                 \n",
      "[Training] Epoch: 58, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 58, LossG: 0.7455                                    \n",
      "[Training] Epoch: 59 [DONE]                                 \n",
      "[Training] Epoch: 59, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 59, LossG: 0.7455                                    \n",
      "[Training] Epoch: 60 [DONE]                                 \n",
      "[Training] Epoch: 60, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 60, LossG: 0.7455                                    \n",
      "[Training] Epoch: 61 [DONE]                                 \n",
      "[Training] Epoch: 61, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 61, LossG: 0.7454                                    \n",
      "[Training] Epoch: 62 [DONE]                                 \n",
      "[Training] Epoch: 62, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 62, LossG: 0.7455                                    \n",
      "[Training] Epoch: 63 [DONE]                                 \n",
      "[Training] Epoch: 63, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 63, LossG: 0.7455                                    \n",
      "[Training] Epoch: 64 [DONE]                                 \n",
      "[Training] Epoch: 64, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 64, LossG: 0.7455                                    \n",
      "[Training] Epoch: 65 [DONE]                                 \n",
      "[Training] Epoch: 65, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 65, LossG: 0.7455                                    \n",
      "[Training] Epoch: 66 [DONE]                                 \n",
      "[Training] Epoch: 66, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 66, LossG: 0.7455                                    \n",
      "[Training] Epoch: 67 [DONE]                                 \n",
      "[Training] Epoch: 67, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 67, LossG: 0.7455                                    \n",
      "[Training] Epoch: 68 [DONE]                                 \n",
      "[Training] Epoch: 68, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 68, LossG: 0.7455                                    \n",
      "[Training] Epoch: 69 [DONE]                                 \n",
      "[Training] Epoch: 69, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 69, LossG: 0.7455                                    \n",
      "[Training] Epoch: 70 [DONE]                                 \n",
      "[Training] Epoch: 70, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 70, LossG: 0.7455                                    \n",
      "[Training] Epoch: 71 [DONE]                                 \n",
      "[Training] Epoch: 71, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 71, LossG: 0.7454                                    \n",
      "[Training] Epoch: 72 [DONE]                                 \n",
      "[Training] Epoch: 72, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 72, LossG: 0.7455                                    \n",
      "[Training] Epoch: 73 [DONE]                                 \n",
      "[Training] Epoch: 73, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 73, LossG: 0.7454                                    \n",
      "[Training] Epoch: 74 [DONE]                                 \n",
      "[Training] Epoch: 74, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 74, LossG: 0.7455                                    \n",
      "[Training] Epoch: 75 [DONE]                                 \n",
      "[Training] Epoch: 75, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 75, LossG: 0.7455                                    \n",
      "[Training] Epoch: 76 [DONE]                                 \n",
      "[Training] Epoch: 76, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 76, LossG: 0.7455                                    \n",
      "[Training] Epoch: 77 [DONE]                                 \n",
      "[Training] Epoch: 77, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 77, LossG: 0.7455                                    \n",
      "[Training] Epoch: 78 [DONE]                                 \n",
      "[Training] Epoch: 78, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 78, LossG: 0.7455                                    \n",
      "[Training] Epoch: 79 [DONE]                                 \n",
      "[Training] Epoch: 79, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 79, LossG: 0.7455                                    \n",
      "[Training] Epoch: 80 [DONE]                                 \n",
      "[Training] Epoch: 80, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 80, LossG: 0.7455                                    \n",
      "[Training] Epoch: 81 [DONE]                                 \n",
      "[Training] Epoch: 81, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 81, LossG: 0.7455                                    \n",
      "[Training] Epoch: 82 [DONE]                                 \n",
      "[Training] Epoch: 82, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 82, LossG: 0.7455                                    \n",
      "[Training] Epoch: 83 [DONE]                                 \n",
      "[Training] Epoch: 83, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 83, LossG: 0.7454                                    \n",
      "[Training] Epoch: 84 [DONE]                                 \n",
      "[Training] Epoch: 84, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 84, LossG: 0.7455                                    \n",
      "[Training] Epoch: 85 [DONE]                                 \n",
      "[Training] Epoch: 85, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 85, LossG: 0.7454                                    \n",
      "[Training] Epoch: 86 [DONE]                                 \n",
      "[Training] Epoch: 86, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 86, LossG: 0.7454                                    \n",
      "[Training] Epoch: 87 [DONE]                                 \n",
      "[Training] Epoch: 87, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 87, LossG: 0.7454                                    \n",
      "[Training] Epoch: 88 [DONE]                                 \n",
      "[Training] Epoch: 88, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 88, LossG: 0.7454                                    \n",
      "[Training] Epoch: 89 [DONE]                                 \n",
      "[Training] Epoch: 89, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 89, LossG: 0.7455                                    \n",
      "[Training] Epoch: 90 [DONE]                                 \n",
      "[Training] Epoch: 90, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 90, LossG: 0.7454                                    \n",
      "[Training] Epoch: 91 [DONE]                                 \n",
      "[Training] Epoch: 91, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 91, LossG: 0.7454                                    \n",
      "[Training] Epoch: 92 [DONE]                                 \n",
      "[Training] Epoch: 92, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 92, LossG: 0.7455                                    \n",
      "[Training] Epoch: 93 [DONE]                                 \n",
      "[Training] Epoch: 93, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 93, LossG: 0.7454                                    \n",
      "[Training] Epoch: 94 [DONE]                                 \n",
      "[Training] Epoch: 94, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 94, LossG: 0.7454                                    \n",
      "[Training] Epoch: 95 [DONE]                                 \n",
      "[Training] Epoch: 95, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 95, LossG: 0.7455                                    \n",
      "[Training] Epoch: 96 [DONE]                                 \n",
      "[Training] Epoch: 96, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 96, LossG: 0.7455                                    \n",
      "[Training] Epoch: 97 [DONE]                                 \n",
      "[Training] Epoch: 97, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 97, LossG: 0.7453                                    \n",
      "[Training] Epoch: 98 [DONE]                                 \n",
      "[Training] Epoch: 98, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 98, LossG: 0.7454                                    \n",
      "[Training] Epoch: 99 [DONE]                                 \n",
      "[Training] Epoch: 99, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 99, LossG: 0.7454                                    \n",
      "[Training] Epoch: 100 [DONE]                                 \n",
      "[Training] Epoch: 100, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 100, LossG: 0.7454                                  \n",
      "[Training] Epoch: 101 [DONE]                                 \n",
      "[Training] Epoch: 101, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 101, LossG: 0.7455                                  \n",
      "[Training] Epoch: 102 [DONE]                                 \n",
      "[Training] Epoch: 102, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 102, LossG: 0.7454                                  \n",
      "[Training] Epoch: 103 [DONE]                                 \n",
      "[Training] Epoch: 103, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 103, LossG: 0.7455                                  \n",
      "[Training] Epoch: 104 [DONE]                                 \n",
      "[Training] Epoch: 104, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 104, LossG: 0.7455                                  \n",
      "[Training] Epoch: 105 [DONE]                                 \n",
      "[Training] Epoch: 105, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 105, LossG: 0.7454                                  \n",
      "[Training] Epoch: 106 [DONE]                                 \n",
      "[Training] Epoch: 106, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 106, LossG: 0.7455                                  \n",
      "[Training] Epoch: 107 [DONE]                                 \n",
      "[Training] Epoch: 107, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 107, LossG: 0.7454                                  \n",
      "[Training] Epoch: 108 [DONE]                                 \n",
      "[Training] Epoch: 108, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 108, LossG: 0.7455                                  \n",
      "[Training] Epoch: 109 [DONE]                                 \n",
      "[Training] Epoch: 109, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 109, LossG: 0.7455                                  \n",
      "[Training] Epoch: 110 [DONE]                                 \n",
      "[Training] Epoch: 110, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 110, LossG: 0.7455                                  \n",
      "[Training] Epoch: 111 [DONE]                                 \n",
      "[Training] Epoch: 111, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 111, LossG: 0.7455                                  \n",
      "[Training] Epoch: 112 [DONE]                                 \n",
      "[Training] Epoch: 112, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 112, LossG: 0.7454                                  \n",
      "[Training] Epoch: 113 [DONE]                                 \n",
      "[Training] Epoch: 113, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 113, LossG: 0.7455                                  \n",
      "[Training] Epoch: 114 [DONE]                                 \n",
      "[Training] Epoch: 114, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 114, LossG: 0.7455                                  \n",
      "[Training] Epoch: 115 [DONE]                                 \n",
      "[Training] Epoch: 115, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 115, LossG: 0.7455                                  \n",
      "[Training] Epoch: 116 [DONE]                                 \n",
      "[Training] Epoch: 116, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 116, LossG: 0.7455                                  \n",
      "[Training] Epoch: 117 [DONE]                                 \n",
      "[Training] Epoch: 117, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 117, LossG: 0.7455                                  \n",
      "[Training] Epoch: 118 [DONE]                                 \n",
      "[Training] Epoch: 118, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 118, LossG: 0.7455                                  \n",
      "[Training] Epoch: 119 [DONE]                                 \n",
      "[Training] Epoch: 119, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 119, LossG: 0.7454                                  \n",
      "[Training] Epoch: 120 [DONE]                                 \n",
      "[Training] Epoch: 120, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 120, LossG: 0.7455                                  \n",
      "[Training] Epoch: 121 [DONE]                                 \n",
      "[Training] Epoch: 121, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 121, LossG: 0.7454                                  \n",
      "[Training] Epoch: 122 [DONE]                                 \n",
      "[Training] Epoch: 122, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 122, LossG: 0.7455                                  \n",
      "[Training] Epoch: 123 [DONE]                                 \n",
      "[Training] Epoch: 123, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 123, LossG: 0.7455                                  \n",
      "[Training] Epoch: 124 [DONE]                                 \n",
      "[Training] Epoch: 124, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 124, LossG: 0.7454                                  \n",
      "[Training] Epoch: 125 [DONE]                                 \n",
      "[Training] Epoch: 125, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 125, LossG: 0.7454                                  \n",
      "[Training] Epoch: 126 [DONE]                                 \n",
      "[Training] Epoch: 126, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 126, LossG: 0.7455                                  \n",
      "[Training] Epoch: 127 [DONE]                                 \n",
      "[Training] Epoch: 127, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 127, LossG: 0.7455                                  \n",
      "[Training] Epoch: 128 [DONE]                                 \n",
      "[Training] Epoch: 128, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 128, LossG: 0.7454                                  \n",
      "[Training] Epoch: 129 [DONE]                                 \n",
      "[Training] Epoch: 129, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 129, LossG: 0.7455                                  \n",
      "[Training] Epoch: 130 [DONE]                                 \n",
      "[Training] Epoch: 130, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 130, LossG: 0.7455                                  \n",
      "[Training] Epoch: 131 [DONE]                                 \n",
      "[Training] Epoch: 131, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 131, LossG: 0.7454                                  \n",
      "[Training] Epoch: 132 [DONE]                                 \n",
      "[Training] Epoch: 132, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 132, LossG: 0.7454                                  \n",
      "[Training] Epoch: 133 [DONE]                                 \n",
      "[Training] Epoch: 133, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 133, LossG: 0.7455                                  \n",
      "[Training] Epoch: 134 [DONE]                                 \n",
      "[Training] Epoch: 134, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 134, LossG: 0.7454                                  \n",
      "[Training] Epoch: 135 [DONE]                                 \n",
      "[Training] Epoch: 135, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 135, LossG: 0.7455                                  \n",
      "[Training] Epoch: 136 [DONE]                                 \n",
      "[Training] Epoch: 136, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 136, LossG: 0.7454                                  \n",
      "[Training] Epoch: 137 [DONE]                                 \n",
      "[Training] Epoch: 137, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 137, LossG: 0.7454                                  \n",
      "[Training] Epoch: 138 [DONE]                                 \n",
      "[Training] Epoch: 138, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 138, LossG: 0.7455                                  \n",
      "[Training] Epoch: 139 [DONE]                                 \n",
      "[Training] Epoch: 139, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 139, LossG: 0.7454                                  \n",
      "[Training] Epoch: 140 [DONE]                                 \n",
      "[Training] Epoch: 140, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 140, LossG: 0.7454                                  \n",
      "[Training] Epoch: 141 [DONE]                                 \n",
      "[Training] Epoch: 141, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 141, LossG: 0.7454                                  \n",
      "[Training] Epoch: 142 [DONE]                                 \n",
      "[Training] Epoch: 142, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 142, LossG: 0.7454                                  \n",
      "[Training] Epoch: 143 [DONE]                                 \n",
      "[Training] Epoch: 143, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 143, LossG: 0.7454                                  \n",
      "[Training] Epoch: 144 [DONE]                                 \n",
      "[Training] Epoch: 144, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 144, LossG: 0.7454                                  \n",
      "[Training] Epoch: 145 [DONE]                                 \n",
      "[Training] Epoch: 145, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 145, LossG: 0.7455                                  \n",
      "[Training] Epoch: 146 [DONE]                                 \n",
      "[Training] Epoch: 146, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 146, LossG: 0.7455                                  \n",
      "[Training] Epoch: 147 [DONE]                                 \n",
      "[Training] Epoch: 147, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 147, LossG: 0.7454                                  \n",
      "[Training] Epoch: 148 [DONE]                                 \n",
      "[Training] Epoch: 148, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 148, LossG: 0.7455                                  \n",
      "[Training] Epoch: 149 [DONE]                                 \n",
      "[Training] Epoch: 149, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 149, LossG: 0.7454                                  \n",
      "[Training] Epoch: 150 [DONE]                                 \n",
      "[Training] Epoch: 150, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 150, LossG: 0.7455                                  \n",
      "[Training] Epoch: 151 [DONE]                                 \n",
      "[Training] Epoch: 151, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 151, LossG: 0.7455                                  \n",
      "[Training] Epoch: 152 [DONE]                                 \n",
      "[Training] Epoch: 152, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 152, LossG: 0.7454                                  \n",
      "[Training] Epoch: 153 [DONE]                                 \n",
      "[Training] Epoch: 153, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 153, LossG: 0.7454                                  \n",
      "[Training] Epoch: 154 [DONE]                                 \n",
      "[Training] Epoch: 154, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 154, LossG: 0.7454                                  \n",
      "[Training] Epoch: 155 [DONE]                                 \n",
      "[Training] Epoch: 155, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 155, LossG: 0.7455                                  \n",
      "[Training] Epoch: 156 [DONE]                                 \n",
      "[Training] Epoch: 156, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 156, LossG: 0.7456                                  \n",
      "[Training] Epoch: 157 [DONE]                                 \n",
      "[Training] Epoch: 157, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 157, LossG: 0.7456                                  \n",
      "[Training] Epoch: 158 [DONE]                                 \n",
      "[Training] Epoch: 158, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 158, LossG: 0.7456                                  \n",
      "[Training] Epoch: 159 [DONE]                                 \n",
      "[Training] Epoch: 159, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 159, LossG: 0.7455                                  \n",
      "[Training] Epoch: 160 [DONE]                                 \n",
      "[Training] Epoch: 160, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 160, LossG: 0.7458                                  \n",
      "[Training] Epoch: 161 [DONE]                                 \n",
      "[Training] Epoch: 161, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 161, LossG: 0.7457                                  \n",
      "[Training] Epoch: 162 [DONE]                                 \n",
      "[Training] Epoch: 162, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 162, LossG: 0.7456                                  \n",
      "[Training] Epoch: 163 [DONE]                                 \n",
      "[Training] Epoch: 163, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 163, LossG: 0.7456                                  \n",
      "[Training] Epoch: 164 [DONE]                                 \n",
      "[Training] Epoch: 164, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 164, LossG: 0.7456                                  \n",
      "[Training] Epoch: 165 [DONE]                                 \n",
      "[Training] Epoch: 165, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 165, LossG: 0.7455                                  \n",
      "[Training] Epoch: 166 [DONE]                                 \n",
      "[Training] Epoch: 166, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 166, LossG: 0.7455                                  \n",
      "[Training] Epoch: 167 [DONE]                                 \n",
      "[Training] Epoch: 167, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 167, LossG: 0.7455                                  \n",
      "[Training] Epoch: 168 [DONE]                                 \n",
      "[Training] Epoch: 168, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 168, LossG: 0.7457                                  \n",
      "[Training] Epoch: 169 [DONE]                                 \n",
      "[Training] Epoch: 169, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 169, LossG: 0.7458                                  \n",
      "[Training] Epoch: 170 [DONE]                                 \n",
      "[Training] Epoch: 170, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 170, LossG: 0.7458                                  \n",
      "[Training] Epoch: 171 [DONE]                                 \n",
      "[Training] Epoch: 171, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 171, LossG: 0.7457                                  \n",
      "[Training] Epoch: 172 [DONE]                                 \n",
      "[Training] Epoch: 172, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 172, LossG: 0.7456                                  \n",
      "[Training] Epoch: 173 [DONE]                                 \n",
      "[Training] Epoch: 173, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 173, LossG: 0.7456                                  \n",
      "[Training] Epoch: 174 [DONE]                                 \n",
      "[Training] Epoch: 174, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 174, LossG: 0.7455                                  \n",
      "[Training] Epoch: 175 [DONE]                                 \n",
      "[Training] Epoch: 175, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 175, LossG: 0.7455                                  \n",
      "[Training] Epoch: 176 [DONE]                                 \n",
      "[Training] Epoch: 176, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 176, LossG: 0.7455                                  \n",
      "[Training] Epoch: 177 [DONE]                                 \n",
      "[Training] Epoch: 177, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 177, LossG: 0.7456                                  \n",
      "[Training] Epoch: 178 [DONE]                                 \n",
      "[Training] Epoch: 178, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 178, LossG: 0.7455                                  \n",
      "[Training] Epoch: 179 [DONE]                                 \n",
      "[Training] Epoch: 179, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 179, LossG: 0.7456                                  \n",
      "[Training] Epoch: 180 [DONE]                                 \n",
      "[Training] Epoch: 180, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 180, LossG: 0.7455                                  \n",
      "[Training] Epoch: 181 [DONE]                                 \n",
      "[Training] Epoch: 181, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 181, LossG: 0.7455                                  \n",
      "[Training] Epoch: 182 [DONE]                                 \n",
      "[Training] Epoch: 182, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 182, LossG: 0.7455                                  \n",
      "[Training] Epoch: 183 [DONE]                                 \n",
      "[Training] Epoch: 183, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 183, LossG: 0.7455                                  \n",
      "[Training] Epoch: 184 [DONE]                                 \n",
      "[Training] Epoch: 184, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 184, LossG: 0.7455                                  \n",
      "[Training] Epoch: 185 [DONE]                                 \n",
      "[Training] Epoch: 185, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 185, LossG: 0.7455                                  \n",
      "[Training] Epoch: 186 [DONE]                                 \n",
      "[Training] Epoch: 186, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 186, LossG: 0.7454                                  \n",
      "[Training] Epoch: 187 [DONE]                                 \n",
      "[Training] Epoch: 187, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 187, LossG: 0.7454                                  \n",
      "[Training] Epoch: 188 [DONE]                                 \n",
      "[Training] Epoch: 188, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 188, LossG: 0.7454                                  \n",
      "[Training] Epoch: 189 [DONE]                                 \n",
      "[Training] Epoch: 189, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 189, LossG: 0.7455                                  \n",
      "[Training] Epoch: 190 [DONE]                                 \n",
      "[Training] Epoch: 190, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 190, LossG: 0.7455                                  \n",
      "[Training] Epoch: 191 [DONE]                                 \n",
      "[Training] Epoch: 191, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 191, LossG: 0.7455                                  \n",
      "[Training] Epoch: 192 [DONE]                                 \n",
      "[Training] Epoch: 192, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 192, LossG: 0.7454                                  \n",
      "[Training] Epoch: 193 [DONE]                                 \n",
      "[Training] Epoch: 193, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 193, LossG: 0.7456                                  \n",
      "[Training] Epoch: 194 [DONE]                                 \n",
      "[Training] Epoch: 194, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 194, LossG: 0.7455                                  \n",
      "[Training] Epoch: 195 [DONE]                                 \n",
      "[Training] Epoch: 195, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 195, LossG: 0.7455                                  \n",
      "[Training] Epoch: 196 [DONE]                                 \n",
      "[Training] Epoch: 196, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 196, LossG: 0.7456                                  \n",
      "[Training] Epoch: 197 [DONE]                                 \n",
      "[Training] Epoch: 197, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 197, LossG: 0.7456                                  \n",
      "[Training] Epoch: 198 [DONE]                                 \n",
      "[Training] Epoch: 198, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 198, LossG: 0.7456                                  \n",
      "[Training] Epoch: 199 [DONE]                                 \n",
      "[Training] Epoch: 199, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 199, LossG: 0.7456                                  \n",
      "[Training] Epoch: 200 [DONE]                                 \n",
      "[Training] Epoch: 200, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 200, LossG: 0.7455                                  \n",
      "[Training] Epoch: 201 [DONE]                                 \n",
      "[Training] Epoch: 201, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 201, LossG: 0.7455                                  \n",
      "[Training] Epoch: 202 [DONE]                                 \n",
      "[Training] Epoch: 202, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 202, LossG: 0.7455                                  \n",
      "[Training] Epoch: 203 [DONE]                                 \n",
      "[Training] Epoch: 203, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 203, LossG: 0.7455                                  \n",
      "[Training] Epoch: 204 [DONE]                                 \n",
      "[Training] Epoch: 204, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 204, LossG: 0.7454                                  \n",
      "[Training] Epoch: 205 [DONE]                                 \n",
      "[Training] Epoch: 205, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 205, LossG: 0.7454                                  \n",
      "[Training] Epoch: 206 [DONE]                                 \n",
      "[Training] Epoch: 206, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 206, LossG: 0.7455                                  \n",
      "[Training] Epoch: 207 [DONE]                                 \n",
      "[Training] Epoch: 207, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 207, LossG: 0.7455                                  \n",
      "[Training] Epoch: 208 [DONE]                                 \n",
      "[Training] Epoch: 208, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 208, LossG: 0.7455                                  \n",
      "[Training] Epoch: 209 [DONE]                                 \n",
      "[Training] Epoch: 209, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 209, LossG: 0.7454                                  \n",
      "[Training] Epoch: 210 [DONE]                                 \n",
      "[Training] Epoch: 210, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 210, LossG: 0.7454                                  \n",
      "[Training] Epoch: 211 [DONE]                                 \n",
      "[Training] Epoch: 211, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 211, LossG: 0.7454                                  \n",
      "[Training] Epoch: 212 [DONE]                                 \n",
      "[Training] Epoch: 212, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 212, LossG: 0.7454                                  \n",
      "[Training] Epoch: 213 [DONE]                                 \n",
      "[Training] Epoch: 213, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 213, LossG: 0.7454                                  \n",
      "[Training] Epoch: 214 [DONE]                                 \n",
      "[Training] Epoch: 214, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 214, LossG: 0.7454                                  \n",
      "[Training] Epoch: 215 [DONE]                                 \n",
      "[Training] Epoch: 215, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 215, LossG: 0.7454                                  \n",
      "[Training] Epoch: 216 [DONE]                                 \n",
      "[Training] Epoch: 216, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 216, LossG: 0.7454                                  \n",
      "[Training] Epoch: 217 [DONE]                                 \n",
      "[Training] Epoch: 217, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 217, LossG: 0.7454                                  \n",
      "[Training] Epoch: 218 [DONE]                                 \n",
      "[Training] Epoch: 218, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 218, LossG: 0.7455                                  \n",
      "[Training] Epoch: 219 [DONE]                                 \n",
      "[Training] Epoch: 219, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 219, LossG: 0.7454                                  \n",
      "[Training] Epoch: 220 [DONE]                                 \n",
      "[Training] Epoch: 220, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 220, LossG: 0.7455                                  \n",
      "[Training] Epoch: 221 [DONE]                                 \n",
      "[Training] Epoch: 221, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 221, LossG: 0.7454                                  \n",
      "[Training] Epoch: 222 [DONE]                                 \n",
      "[Training] Epoch: 222, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 222, LossG: 0.7454                                  \n",
      "[Training] Epoch: 223 [DONE]                                 \n",
      "[Training] Epoch: 223, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 223, LossG: 0.7454                                  \n",
      "[Training] Epoch: 224 [DONE]                                 \n",
      "[Training] Epoch: 224, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 224, LossG: 0.7455                                  \n",
      "[Training] Epoch: 225 [DONE]                                 \n",
      "[Training] Epoch: 225, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 225, LossG: 0.7454                                  \n",
      "[Training] Epoch: 226 [DONE]                                 \n",
      "[Training] Epoch: 226, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 226, LossG: 0.7454                                  \n",
      "[Training] Epoch: 227 [DONE]                                 \n",
      "[Training] Epoch: 227, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 227, LossG: 0.7454                                  \n",
      "[Training] Epoch: 228 [DONE]                                 \n",
      "[Training] Epoch: 228, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 228, LossG: 0.7454                                  \n",
      "[Training] Epoch: 229 [DONE]                                 \n",
      "[Training] Epoch: 229, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 229, LossG: 0.7454                                  \n",
      "[Training] Epoch: 230 [DONE]                                 \n",
      "[Training] Epoch: 230, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 230, LossG: 0.7454                                  \n",
      "[Training] Epoch: 231 [DONE]                                 \n",
      "[Training] Epoch: 231, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 231, LossG: 0.7454                                  \n",
      "[Training] Epoch: 232 [DONE]                                 \n",
      "[Training] Epoch: 232, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 232, LossG: 0.7454                                  \n",
      "[Training] Epoch: 233 [DONE]                                 \n",
      "[Training] Epoch: 233, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 233, LossG: 0.7454                                  \n",
      "[Training] Epoch: 234 [DONE]                                 \n",
      "[Training] Epoch: 234, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 234, LossG: 0.7454                                  \n",
      "[Training] Epoch: 235 [DONE]                                 \n",
      "[Training] Epoch: 235, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 235, LossG: 0.7454                                  \n",
      "[Training] Epoch: 236 [DONE]                                 \n",
      "[Training] Epoch: 236, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 236, LossG: 0.7454                                  \n",
      "[Training] Epoch: 237 [DONE]                                 \n",
      "[Training] Epoch: 237, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 237, LossG: 0.7454                                  \n",
      "[Training] Epoch: 238 [DONE]                                 \n",
      "[Training] Epoch: 238, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 238, LossG: 0.7454                                  \n",
      "[Training] Epoch: 239 [DONE]                                 \n",
      "[Training] Epoch: 239, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 239, LossG: 0.7454                                  \n",
      "[Training] Epoch: 240 [DONE]                                 \n",
      "[Training] Epoch: 240, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 240, LossG: 0.7454                                  \n",
      "[Training] Epoch: 241 [DONE]                                 \n",
      "[Training] Epoch: 241, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 241, LossG: 0.7454                                  \n",
      "[Training] Epoch: 242 [DONE]                                 \n",
      "[Training] Epoch: 242, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 242, LossG: 0.7455                                  \n",
      "[Training] Epoch: 243 [DONE]                                 \n",
      "[Training] Epoch: 243, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 243, LossG: 0.7454                                  \n",
      "[Training] Epoch: 244 [DONE]                                 \n",
      "[Training] Epoch: 244, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 244, LossG: 0.7454                                  \n",
      "[Training] Epoch: 245 [DONE]                                 \n",
      "[Training] Epoch: 245, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 245, LossG: 0.7454                                  \n",
      "[Training] Epoch: 246 [DONE]                                 \n",
      "[Training] Epoch: 246, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 246, LossG: 0.7454                                  \n",
      "[Training] Epoch: 247 [DONE]                                 \n",
      "[Training] Epoch: 247, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 247, LossG: 0.7454                                  \n",
      "[Training] Epoch: 248 [DONE]                                 \n",
      "[Training] Epoch: 248, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 248, LossG: 0.7454                                  \n",
      "[Training] Epoch: 249 [DONE]                                 \n",
      "[Training] Epoch: 249, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 249, LossG: 0.7454                                  \n",
      "[Training] Epoch: 250 [DONE]                                 \n",
      "[Training] Epoch: 250, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 250, LossG: 0.7454                                  \n",
      "[Training] Epoch: 251 [DONE]                                 \n",
      "[Training] Epoch: 251, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 251, LossG: 0.7454                                  \n",
      "[Training] Epoch: 252 [DONE]                                 \n",
      "[Training] Epoch: 252, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 252, LossG: 0.7454                                  \n",
      "[Training] Epoch: 253 [DONE]                                 \n",
      "[Training] Epoch: 253, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 253, LossG: 0.7454                                  \n",
      "[Training] Epoch: 254 [DONE]                                 \n",
      "[Training] Epoch: 254, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 254, LossG: 0.7454                                  \n",
      "[Training] Epoch: 255 [DONE]                                 \n",
      "[Training] Epoch: 255, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 255, LossG: 0.7454                                  \n",
      "[Training] Epoch: 256 [DONE]                                 \n",
      "[Training] Epoch: 256, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 256, LossG: 0.7455                                  \n",
      "[Training] Epoch: 257 [DONE]                                 \n",
      "[Training] Epoch: 257, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 257, LossG: 0.7454                                  \n",
      "[Training] Epoch: 258 [DONE]                                 \n",
      "[Training] Epoch: 258, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 258, LossG: 0.7455                                  \n",
      "[Training] Epoch: 259 [DONE]                                 \n",
      "[Training] Epoch: 259, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 259, LossG: 0.7454                                  \n",
      "[Training] Epoch: 260 [DONE]                                 \n",
      "[Training] Epoch: 260, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 260, LossG: 0.7454                                  \n",
      "[Training] Epoch: 261 [DONE]                                 \n",
      "[Training] Epoch: 261, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 261, LossG: 0.7454                                  \n",
      "[Training] Epoch: 262 [DONE]                                 \n",
      "[Training] Epoch: 262, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 262, LossG: 0.7454                                  \n",
      "[Training] Epoch: 263 [DONE]                                 \n",
      "[Training] Epoch: 263, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 263, LossG: 0.7454                                  \n",
      "[Training] Epoch: 264 [DONE]                                 \n",
      "[Training] Epoch: 264, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 264, LossG: 0.7455                                  \n",
      "[Training] Epoch: 265 [DONE]                                 \n",
      "[Training] Epoch: 265, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 265, LossG: 0.7454                                  \n",
      "[Training] Epoch: 266 [DONE]                                 \n",
      "[Training] Epoch: 266, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 266, LossG: 0.7454                                  \n",
      "[Training] Epoch: 267 [DONE]                                 \n",
      "[Training] Epoch: 267, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 267, LossG: 0.7455                                  \n",
      "[Training] Epoch: 268 [DONE]                                 \n",
      "[Training] Epoch: 268, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 268, LossG: 0.7454                                  \n",
      "[Training] Epoch: 269 [DONE]                                 \n",
      "[Training] Epoch: 269, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 269, LossG: 0.7455                                  \n",
      "[Training] Epoch: 270 [DONE]                                 \n",
      "[Training] Epoch: 270, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 270, LossG: 0.7454                                  \n",
      "[Training] Epoch: 271 [DONE]                                 \n",
      "[Training] Epoch: 271, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 271, LossG: 0.7454                                  \n",
      "[Training] Epoch: 272 [DONE]                                 \n",
      "[Training] Epoch: 272, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 272, LossG: 0.7454                                  \n",
      "[Training] Epoch: 273 [DONE]                                 \n",
      "[Training] Epoch: 273, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 273, LossG: 0.7455                                  \n",
      "[Training] Epoch: 274 [DONE]                                 \n",
      "[Training] Epoch: 274, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 274, LossG: 0.7455                                  \n",
      "[Training] Epoch: 275 [DONE]                                 \n",
      "[Training] Epoch: 275, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 275, LossG: 0.7455                                  \n",
      "[Training] Epoch: 276 [DONE]                                 \n",
      "[Training] Epoch: 276, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 276, LossG: 0.7455                                  \n",
      "[Training] Epoch: 277 [DONE]                                 \n",
      "[Training] Epoch: 277, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 277, LossG: 0.7454                                  \n",
      "[Training] Epoch: 278 [DONE]                                 \n",
      "[Training] Epoch: 278, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 278, LossG: 0.7454                                  \n",
      "[Training] Epoch: 279 [DONE]                                 \n",
      "[Training] Epoch: 279, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 279, LossG: 0.7454                                  \n",
      "[Training] Epoch: 280 [DONE]                                 \n",
      "[Training] Epoch: 280, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 280, LossG: 0.7454                                  \n",
      "[Training] Epoch: 281 [DONE]                                 \n",
      "[Training] Epoch: 281, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 281, LossG: 0.7454                                  \n",
      "[Training] Epoch: 282 [DONE]                                 \n",
      "[Training] Epoch: 282, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 282, LossG: 0.7454                                  \n",
      "[Training] Epoch: 283 [DONE]                                 \n",
      "[Training] Epoch: 283, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 283, LossG: 0.7454                                  \n",
      "[Training] Epoch: 284 [DONE]                                 \n",
      "[Training] Epoch: 284, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 284, LossG: 0.7454                                  \n",
      "[Training] Epoch: 285 [DONE]                                 \n",
      "[Training] Epoch: 285, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 285, LossG: 0.7454                                  \n",
      "[Training] Epoch: 286 [DONE]                                 \n",
      "[Training] Epoch: 286, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 286, LossG: 0.7454                                  \n",
      "[Training] Epoch: 287 [DONE]                                 \n",
      "[Training] Epoch: 287, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 287, LossG: 0.7454                                  \n",
      "[Training] Epoch: 288 [DONE]                                 \n",
      "[Training] Epoch: 288, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 288, LossG: 0.7454                                  \n",
      "[Training] Epoch: 289 [DONE]                                 \n",
      "[Training] Epoch: 289, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 289, LossG: 0.7453                                  \n",
      "[Training] Epoch: 290 [DONE]                                 \n",
      "[Training] Epoch: 290, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 290, LossG: 0.7454                                  \n",
      "[Training] Epoch: 291 [DONE]                                 \n",
      "[Training] Epoch: 291, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 291, LossG: 0.7454                                  \n",
      "[Training] Epoch: 292 [DONE]                                 \n",
      "[Training] Epoch: 292, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 292, LossG: 0.7454                                  \n",
      "[Training] Epoch: 293 [DONE]                                 \n",
      "[Training] Epoch: 293, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 293, LossG: 0.7454                                  \n",
      "[Training] Epoch: 294 [DONE]                                 \n",
      "[Training] Epoch: 294, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 294, LossG: 0.7455                                  \n",
      "[Training] Epoch: 295 [DONE]                                 \n",
      "[Training] Epoch: 295, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 295, LossG: 0.7454                                  \n",
      "[Training] Epoch: 296 [DONE]                                 \n",
      "[Training] Epoch: 296, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 296, LossG: 0.7454                                  \n",
      "[Training] Epoch: 297 [DONE]                                 \n",
      "[Training] Epoch: 297, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 297, LossG: 0.7454                                  \n",
      "[Training] Epoch: 298 [DONE]                                 \n",
      "[Training] Epoch: 298, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 298, LossG: 0.7454                                  \n",
      "[Training] Epoch: 299 [DONE]                                 \n",
      "[Training] Epoch: 299, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 299, LossG: 0.7454                                  \n",
      "[Training] Epoch: 300 [DONE]                                 \n",
      "[Training] Epoch: 300, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 300, LossG: 0.7454                                  \n",
      "[Training] Epoch: 301 [DONE]                                 \n",
      "[Training] Epoch: 301, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 301, LossG: 0.7454                                  \n",
      "[Training] Epoch: 302 [DONE]                                 \n",
      "[Training] Epoch: 302, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 302, LossG: 0.7454                                  \n",
      "[Training] Epoch: 303 [DONE]                                 \n",
      "[Training] Epoch: 303, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 303, LossG: 0.7454                                  \n",
      "[Training] Epoch: 304 [DONE]                                 \n",
      "[Training] Epoch: 304, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 304, LossG: 0.7453                                  \n",
      "[Training] Epoch: 305 [DONE]                                 \n",
      "[Training] Epoch: 305, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 305, LossG: 0.7454                                  \n",
      "[Training] Epoch: 306 [DONE]                                 \n",
      "[Training] Epoch: 306, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 306, LossG: 0.7454                                  \n",
      "[Training] Epoch: 307 [DONE]                                 \n",
      "[Training] Epoch: 307, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 307, LossG: 0.7454                                  \n",
      "[Training] Epoch: 308 [DONE]                                 \n",
      "[Training] Epoch: 308, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 308, LossG: 0.7454                                  \n",
      "[Training] Epoch: 309 [DONE]                                 \n",
      "[Training] Epoch: 309, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 309, LossG: 0.7454                                  \n",
      "[Training] Epoch: 310 [DONE]                                 \n",
      "[Training] Epoch: 310, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 310, LossG: 0.7454                                  \n",
      "[Training] Epoch: 311 [DONE]                                 \n",
      "[Training] Epoch: 311, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 311, LossG: 0.7454                                  \n",
      "[Training] Epoch: 312 [DONE]                                 \n",
      "[Training] Epoch: 312, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 312, LossG: 0.7453                                  \n",
      "[Training] Epoch: 313 [DONE]                                 \n",
      "[Training] Epoch: 313, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 313, LossG: 0.7453                                  \n",
      "[Training] Epoch: 314 [DONE]                                 \n",
      "[Training] Epoch: 314, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 314, LossG: 0.7454                                  \n",
      "[Training] Epoch: 315 [DONE]                                 \n",
      "[Training] Epoch: 315, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 315, LossG: 0.7454                                  \n",
      "[Training] Epoch: 316 [DONE]                                 \n",
      "[Training] Epoch: 316, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 316, LossG: 0.7454                                  \n",
      "[Training] Epoch: 317 [DONE]                                 \n",
      "[Training] Epoch: 317, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 317, LossG: 0.7453                                  \n",
      "[Training] Epoch: 318 [DONE]                                 \n",
      "[Training] Epoch: 318, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 318, LossG: 0.7454                                  \n",
      "[Training] Epoch: 319 [DONE]                                 \n",
      "[Training] Epoch: 319, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 319, LossG: 0.7453                                  \n",
      "[Training] Epoch: 320 [DONE]                                 \n",
      "[Training] Epoch: 320, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 320, LossG: 0.7453                                  \n",
      "[Training] Epoch: 321 [DONE]                                 \n",
      "[Training] Epoch: 321, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 321, LossG: 0.7454                                  \n",
      "[Training] Epoch: 322 [DONE]                                 \n",
      "[Training] Epoch: 322, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 322, LossG: 0.7454                                  \n",
      "[Training] Epoch: 323 [DONE]                                 \n",
      "[Training] Epoch: 323, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 323, LossG: 0.7454                                  \n",
      "[Training] Epoch: 324 [DONE]                                 \n",
      "[Training] Epoch: 324, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 324, LossG: 0.7454                                  \n",
      "[Training] Epoch: 325 [DONE]                                 \n",
      "[Training] Epoch: 325, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 325, LossG: 0.7454                                  \n",
      "[Training] Epoch: 326 [DONE]                                 \n",
      "[Training] Epoch: 326, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 326, LossG: 0.7453                                  \n",
      "[Training] Epoch: 327 [DONE]                                 \n",
      "[Training] Epoch: 327, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 327, LossG: 0.7454                                  \n",
      "[Training] Epoch: 328 [DONE]                                 \n",
      "[Training] Epoch: 328, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 328, LossG: 0.7454                                  \n",
      "[Training] Epoch: 329 [DONE]                                 \n",
      "[Training] Epoch: 329, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 329, LossG: 0.7454                                  \n",
      "[Training] Epoch: 330 [DONE]                                 \n",
      "[Training] Epoch: 330, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 330, LossG: 0.7454                                  \n",
      "[Training] Epoch: 331 [DONE]                                 \n",
      "[Training] Epoch: 331, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 331, LossG: 0.7454                                  \n",
      "[Training] Epoch: 332 [DONE]                                 \n",
      "[Training] Epoch: 332, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 332, LossG: 0.7453                                  \n",
      "[Training] Epoch: 333 [DONE]                                 \n",
      "[Training] Epoch: 333, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 333, LossG: 0.7454                                  \n",
      "[Training] Epoch: 334 [DONE]                                 \n",
      "[Training] Epoch: 334, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 334, LossG: 0.7453                                  \n",
      "[Training] Epoch: 335 [DONE]                                 \n",
      "[Training] Epoch: 335, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 335, LossG: 0.7454                                  \n",
      "[Training] Epoch: 336 [DONE]                                 \n",
      "[Training] Epoch: 336, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 336, LossG: 0.7454                                  \n",
      "[Training] Epoch: 337 [DONE]                                 \n",
      "[Training] Epoch: 337, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 337, LossG: 0.7453                                  \n",
      "[Training] Epoch: 338 [DONE]                                 \n",
      "[Training] Epoch: 338, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 338, LossG: 0.7454                                  \n",
      "[Training] Epoch: 339 [DONE]                                 \n",
      "[Training] Epoch: 339, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 339, LossG: 0.7454                                  \n",
      "[Training] Epoch: 340 [DONE]                                 \n",
      "[Training] Epoch: 340, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 340, LossG: 0.7453                                  \n",
      "[Training] Epoch: 341 [DONE]                                 \n",
      "[Training] Epoch: 341, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 341, LossG: 0.7454                                  \n",
      "[Training] Epoch: 342 [DONE]                                 \n",
      "[Training] Epoch: 342, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 342, LossG: 0.7454                                  \n",
      "[Training] Epoch: 343 [DONE]                                 \n",
      "[Training] Epoch: 343, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 343, LossG: 0.7454                                  \n",
      "[Training] Epoch: 344 [DONE]                                 \n",
      "[Training] Epoch: 344, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 344, LossG: 0.7454                                  \n",
      "[Training] Epoch: 345 [DONE]                                 \n",
      "[Training] Epoch: 345, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 345, LossG: 0.7454                                  \n",
      "[Training] Epoch: 346 [DONE]                                 \n",
      "[Training] Epoch: 346, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 346, LossG: 0.7454                                  \n",
      "[Training] Epoch: 347 [DONE]                                 \n",
      "[Training] Epoch: 347, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 347, LossG: 0.7454                                  \n",
      "[Training] Epoch: 348 [DONE]                                 \n",
      "[Training] Epoch: 348, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 348, LossG: 0.7454                                  \n",
      "[Training] Epoch: 349 [DONE]                                 \n",
      "[Training] Epoch: 349, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 349, LossG: 0.7453                                  \n",
      "[Training] Epoch: 350 [DONE]                                 \n",
      "[Training] Epoch: 350, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 350, LossG: 0.7454                                  \n",
      "[Training] Epoch: 351 [DONE]                                 \n",
      "[Training] Epoch: 351, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 351, LossG: 0.7453                                  \n",
      "[Training] Epoch: 352 [DONE]                                 \n",
      "[Training] Epoch: 352, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 352, LossG: 0.7453                                  \n",
      "[Training] Epoch: 353 [DONE]                                 \n",
      "[Training] Epoch: 353, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 353, LossG: 0.7454                                  \n",
      "[Training] Epoch: 354 [DONE]                                 \n",
      "[Training] Epoch: 354, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 354, LossG: 0.7454                                  \n",
      "[Training] Epoch: 355 [DONE]                                 \n",
      "[Training] Epoch: 355, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 355, LossG: 0.7454                                  \n",
      "[Training] Epoch: 356 [DONE]                                 \n",
      "[Training] Epoch: 356, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 356, LossG: 0.7453                                  \n",
      "[Training] Epoch: 357 [DONE]                                 \n",
      "[Training] Epoch: 357, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 357, LossG: 0.7454                                  \n",
      "[Training] Epoch: 358 [DONE]                                 \n",
      "[Training] Epoch: 358, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 358, LossG: 0.7453                                  \n",
      "[Training] Epoch: 359 [DONE]                                 \n",
      "[Training] Epoch: 359, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 359, LossG: 0.7454                                  \n",
      "[Training] Epoch: 360 [DONE]                                 \n",
      "[Training] Epoch: 360, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 360, LossG: 0.7454                                  \n",
      "[Training] Epoch: 361 [DONE]                                 \n",
      "[Training] Epoch: 361, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 361, LossG: 0.7454                                  \n",
      "[Training] Epoch: 362 [DONE]                                 \n",
      "[Training] Epoch: 362, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 362, LossG: 0.7454                                  \n",
      "[Training] Epoch: 363 [DONE]                                 \n",
      "[Training] Epoch: 363, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 363, LossG: 0.7453                                  \n",
      "[Training] Epoch: 364 [DONE]                                 \n",
      "[Training] Epoch: 364, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 364, LossG: 0.7454                                  \n",
      "[Training] Epoch: 365 [DONE]                                 \n",
      "[Training] Epoch: 365, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 365, LossG: 0.7454                                  \n",
      "[Training] Epoch: 366 [DONE]                                 \n",
      "[Training] Epoch: 366, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 366, LossG: 0.7454                                  \n",
      "[Training] Epoch: 367 [DONE]                                 \n",
      "[Training] Epoch: 367, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 367, LossG: 0.7454                                  \n",
      "[Training] Epoch: 368 [DONE]                                 \n",
      "[Training] Epoch: 368, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 368, LossG: 0.7453                                  \n",
      "[Training] Epoch: 369 [DONE]                                 \n",
      "[Training] Epoch: 369, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 369, LossG: 0.7454                                  \n",
      "[Training] Epoch: 370 [DONE]                                 \n",
      "[Training] Epoch: 370, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 370, LossG: 0.7454                                  \n",
      "[Training] Epoch: 371 [DONE]                                 \n",
      "[Training] Epoch: 371, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 371, LossG: 0.7454                                  \n",
      "[Training] Epoch: 372 [DONE]                                 \n",
      "[Training] Epoch: 372, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 372, LossG: 0.7454                                  \n",
      "[Training] Epoch: 373 [DONE]                                 \n",
      "[Training] Epoch: 373, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 373, LossG: 0.7454                                  \n",
      "[Training] Epoch: 374 [DONE]                                 \n",
      "[Training] Epoch: 374, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 374, LossG: 0.7454                                  \n",
      "[Training] Epoch: 375 [DONE]                                 \n",
      "[Training] Epoch: 375, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 375, LossG: 0.7454                                  \n",
      "[Training] Epoch: 376 [DONE]                                 \n",
      "[Training] Epoch: 376, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 376, LossG: 0.7453                                  \n",
      "[Training] Epoch: 377 [DONE]                                 \n",
      "[Training] Epoch: 377, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 377, LossG: 0.7454                                  \n",
      "[Training] Epoch: 378 [DONE]                                 \n",
      "[Training] Epoch: 378, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 378, LossG: 0.7454                                  \n",
      "[Training] Epoch: 379 [DONE]                                 \n",
      "[Training] Epoch: 379, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 379, LossG: 0.7454                                  \n",
      "[Training] Epoch: 380 [DONE]                                 \n",
      "[Training] Epoch: 380, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 380, LossG: 0.7454                                  \n",
      "[Training] Epoch: 381 [DONE]                                 \n",
      "[Training] Epoch: 381, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 381, LossG: 0.7454                                  \n",
      "[Training] Epoch: 382 [DONE]                                 \n",
      "[Training] Epoch: 382, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 382, LossG: 0.7454                                  \n",
      "[Training] Epoch: 383 [DONE]                                 \n",
      "[Training] Epoch: 383, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 383, LossG: 0.7454                                  \n",
      "[Training] Epoch: 384 [DONE]                                 \n",
      "[Training] Epoch: 384, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 384, LossG: 0.7454                                  \n",
      "[Training] Epoch: 385 [DONE]                                 \n",
      "[Training] Epoch: 385, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 385, LossG: 0.7454                                  \n",
      "[Training] Epoch: 386 [DONE]                                 \n",
      "[Training] Epoch: 386, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 386, LossG: 0.7454                                  \n",
      "[Training] Epoch: 387 [DONE]                                 \n",
      "[Training] Epoch: 387, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 387, LossG: 0.7454                                  \n",
      "[Training] Epoch: 388 [DONE]                                 \n",
      "[Training] Epoch: 388, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 388, LossG: 0.7455                                  \n",
      "[Training] Epoch: 389 [DONE]                                 \n",
      "[Training] Epoch: 389, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 389, LossG: 0.7456                                  \n",
      "[Training] Epoch: 390 [DONE]                                 \n",
      "[Training] Epoch: 390, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 390, LossG: 0.7457                                  \n",
      "[Training] Epoch: 391 [DONE]                                 \n",
      "[Training] Epoch: 391, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 391, LossG: 0.7459                                  \n",
      "[Training] Epoch: 392 [DONE]                                 \n",
      "[Training] Epoch: 392, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 392, LossG: 0.7462                                  \n",
      "[Training] Epoch: 393 [DONE]                                 \n",
      "[Training] Epoch: 393, LossG: 0.7462=================================================================] 100.0%\n",
      "[Validation] Epoch: 393, LossG: 0.7462                                  \n",
      "[Training] Epoch: 394 [DONE]                                 \n",
      "[Training] Epoch: 394, LossG: 0.7459=================================================================] 100.0%\n",
      "[Validation] Epoch: 394, LossG: 0.7459                                  \n",
      "[Training] Epoch: 395 [DONE]                                 \n",
      "[Training] Epoch: 395, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 395, LossG: 0.7458                                  \n",
      "[Training] Epoch: 396 [DONE]                                 \n",
      "[Training] Epoch: 396, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 396, LossG: 0.7458                                  \n",
      "[Training] Epoch: 397 [DONE]                                 \n",
      "[Training] Epoch: 397, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 397, LossG: 0.7457                                  \n",
      "[Training] Epoch: 398 [DONE]                                 \n",
      "[Training] Epoch: 398, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 398, LossG: 0.7457                                  \n",
      "[Training] Epoch: 399 [DONE]                                 \n",
      "[Training] Epoch: 399, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 399, LossG: 0.7458                                  \n",
      "[Training] Epoch: 400 [DONE]                                 \n",
      "[Training] Epoch: 400, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 400, LossG: 0.7458                                  \n",
      "[Training] Epoch: 401 [DONE]                                 \n",
      "[Training] Epoch: 401, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 401, LossG: 0.7460                                  \n",
      "[Training] Epoch: 402 [DONE]                                 \n",
      "[Training] Epoch: 402, LossG: 0.7458=================================================================] 100.0%\n",
      "[Validation] Epoch: 402, LossG: 0.7458                                  \n",
      "[Training] Epoch: 403 [DONE]                                 \n",
      "[Training] Epoch: 403, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 403, LossG: 0.7456                                  \n",
      "[Training] Epoch: 404 [DONE]                                 \n",
      "[Training] Epoch: 404, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 404, LossG: 0.7457                                  \n",
      "[Training] Epoch: 405 [DONE]                                 \n",
      "[Training] Epoch: 405, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 405, LossG: 0.7456                                  \n",
      "[Training] Epoch: 406 [DONE]                                 \n",
      "[Training] Epoch: 406, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 406, LossG: 0.7455                                  \n",
      "[Training] Epoch: 407 [DONE]                                 \n",
      "[Training] Epoch: 407, LossG: 0.7456=================================================================] 100.0%\n",
      "[Validation] Epoch: 407, LossG: 0.7456                                  \n",
      "[Training] Epoch: 408 [DONE]                                 \n",
      "[Training] Epoch: 408, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 408, LossG: 0.7455                                  \n",
      "[Training] Epoch: 409 [DONE]                                 \n",
      "[Training] Epoch: 409, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 409, LossG: 0.7455                                  \n",
      "[Training] Epoch: 410 [DONE]                                 \n",
      "[Training] Epoch: 410, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 410, LossG: 0.7455                                  \n",
      "[Training] Epoch: 411 [DONE]                                 \n",
      "[Training] Epoch: 411, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 411, LossG: 0.7455                                  \n",
      "[Training] Epoch: 412 [DONE]                                 \n",
      "[Training] Epoch: 412, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 412, LossG: 0.7454                                  \n",
      "[Training] Epoch: 413 [DONE]                                 \n",
      "[Training] Epoch: 413, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 413, LossG: 0.7455                                  \n",
      "[Training] Epoch: 414 [DONE]                                 \n",
      "[Training] Epoch: 414, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 414, LossG: 0.7454                                  \n",
      "[Training] Epoch: 415 [DONE]                                 \n",
      "[Training] Epoch: 415, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 415, LossG: 0.7455                                  \n",
      "[Training] Epoch: 416 [DONE]                                 \n",
      "[Training] Epoch: 416, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 416, LossG: 0.7454                                  \n",
      "[Training] Epoch: 417 [DONE]                                 \n",
      "[Training] Epoch: 417, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 417, LossG: 0.7454                                  \n",
      "[Training] Epoch: 418 [DONE]                                 \n",
      "[Training] Epoch: 418, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 418, LossG: 0.7454                                  \n",
      "[Training] Epoch: 419 [DONE]                                 \n",
      "[Training] Epoch: 419, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 419, LossG: 0.7454                                  \n",
      "[Training] Epoch: 420 [DONE]                                 \n",
      "[Training] Epoch: 420, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 420, LossG: 0.7454                                  \n",
      "[Training] Epoch: 421 [DONE]                                 \n",
      "[Training] Epoch: 421, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 421, LossG: 0.7454                                  \n",
      "[Training] Epoch: 422 [DONE]                                 \n",
      "[Training] Epoch: 422, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 422, LossG: 0.7454                                  \n",
      "[Training] Epoch: 423 [DONE]                                 \n",
      "[Training] Epoch: 423, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 423, LossG: 0.7454                                  \n",
      "[Training] Epoch: 424 [DONE]                                 \n",
      "[Training] Epoch: 424, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 424, LossG: 0.7454                                  \n",
      "[Training] Epoch: 425 [DONE]                                 \n",
      "[Training] Epoch: 425, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 425, LossG: 0.7454                                  \n",
      "[Training] Epoch: 426 [DONE]                                 \n",
      "[Training] Epoch: 426, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 426, LossG: 0.7454                                  \n",
      "[Training] Epoch: 427 [DONE]                                 \n",
      "[Training] Epoch: 427, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 427, LossG: 0.7453                                  \n",
      "[Training] Epoch: 428 [DONE]                                 \n",
      "[Training] Epoch: 428, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 428, LossG: 0.7453                                  \n",
      "[Training] Epoch: 429 [DONE]                                 \n",
      "[Training] Epoch: 429, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 429, LossG: 0.7454                                  \n",
      "[Training] Epoch: 430 [DONE]                                 \n",
      "[Training] Epoch: 430, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 430, LossG: 0.7453                                  \n",
      "[Training] Epoch: 431 [DONE]                                 \n",
      "[Training] Epoch: 431, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 431, LossG: 0.7453                                  \n",
      "[Training] Epoch: 432 [DONE]                                 \n",
      "[Training] Epoch: 432, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 432, LossG: 0.7454                                  \n",
      "[Training] Epoch: 433 [DONE]                                 \n",
      "[Training] Epoch: 433, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 433, LossG: 0.7454                                  \n",
      "[Training] Epoch: 434 [DONE]                                 \n",
      "[Training] Epoch: 434, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 434, LossG: 0.7454                                  \n",
      "[Training] Epoch: 435 [DONE]                                 \n",
      "[Training] Epoch: 435, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 435, LossG: 0.7453                                  \n",
      "[Training] Epoch: 436 [DONE]                                 \n",
      "[Training] Epoch: 436, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 436, LossG: 0.7454                                  \n",
      "[Training] Epoch: 437 [DONE]                                 \n",
      "[Training] Epoch: 437, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 437, LossG: 0.7454                                  \n",
      "[Training] Epoch: 438 [DONE]                                 \n",
      "[Training] Epoch: 438, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 438, LossG: 0.7454                                  \n",
      "[Training] Epoch: 439 [DONE]                                 \n",
      "[Training] Epoch: 439, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 439, LossG: 0.7453                                  \n",
      "[Training] Epoch: 440 [DONE]                                 \n",
      "[Training] Epoch: 440, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 440, LossG: 0.7454                                  \n",
      "[Training] Epoch: 441 [DONE]                                 \n",
      "[Training] Epoch: 441, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 441, LossG: 0.7454                                  \n",
      "[Training] Epoch: 442 [DONE]                                 \n",
      "[Training] Epoch: 442, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 442, LossG: 0.7453                                  \n",
      "[Training] Epoch: 443 [DONE]                                 \n",
      "[Training] Epoch: 443, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 443, LossG: 0.7454                                  \n",
      "[Training] Epoch: 444 [DONE]                                 \n",
      "[Training] Epoch: 444, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 444, LossG: 0.7455                                  \n",
      "[Training] Epoch: 445 [DONE]                                 \n",
      "[Training] Epoch: 445, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 445, LossG: 0.7454                                  \n",
      "[Training] Epoch: 446 [DONE]                                 \n",
      "[Training] Epoch: 446, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 446, LossG: 0.7453                                  \n",
      "[Training] Epoch: 447 [DONE]                                 \n",
      "[Training] Epoch: 447, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 447, LossG: 0.7453                                  \n",
      "Epoch: 447\n",
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      " Model loaded: ./models/Test_Model/447_Epoch\n",
      "Total params: 1,769,492\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 0, LossG: 0.7454                                      \n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 1, LossG: 0.7454                                      \n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 2, LossG: 0.7454                                      \n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 3, LossG: 0.7454                                      \n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 4, LossG: 0.7454                                      \n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 5, LossG: 0.7454                                      \n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 6, LossG: 0.7454                                      \n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 7, LossG: 0.7454                                      \n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 8, LossG: 0.7454                                      \n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 0.7453===================================================================] 100.0%\n",
      "[Validation] Epoch: 9, LossG: 0.7453                                      \n",
      "[Training] Epoch: 10 [DONE]                                 \n",
      "[Training] Epoch: 10, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 10, LossG: 0.7454                                    \n",
      "[Training] Epoch: 11 [DONE]                                 \n",
      "[Training] Epoch: 11, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 11, LossG: 0.7454                                    \n",
      "[Training] Epoch: 12 [DONE]                                 \n",
      "[Training] Epoch: 12, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 12, LossG: 0.7453                                    \n",
      "[Training] Epoch: 13 [DONE]                                 \n",
      "[Training] Epoch: 13, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 13, LossG: 0.7455                                    \n",
      "[Training] Epoch: 14 [DONE]                                 \n",
      "[Training] Epoch: 14, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 14, LossG: 0.7453                                    \n",
      "[Training] Epoch: 15 [DONE]                                 \n",
      "[Training] Epoch: 15, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 15, LossG: 0.7454                                    \n",
      "[Training] Epoch: 16 [DONE]                                 \n",
      "[Training] Epoch: 16, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 16, LossG: 0.7453                                    \n",
      "[Training] Epoch: 17 [DONE]                                 \n",
      "[Training] Epoch: 17, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 17, LossG: 0.7454                                    \n",
      "[Training] Epoch: 18 [DONE]                                 \n",
      "[Training] Epoch: 18, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 18, LossG: 0.7454                                    \n",
      "[Training] Epoch: 19 [DONE]                                 \n",
      "[Training] Epoch: 19, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 19, LossG: 0.7453                                    \n",
      "[Training] Epoch: 20 [DONE]                                 \n",
      "[Training] Epoch: 20, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 20, LossG: 0.7454                                    \n",
      "[Training] Epoch: 21 [DONE]                                 \n",
      "[Training] Epoch: 21, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 21, LossG: 0.7453                                    \n",
      "[Training] Epoch: 22 [DONE]                                 \n",
      "[Training] Epoch: 22, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 22, LossG: 0.7454                                    \n",
      "[Training] Epoch: 23 [DONE]                                 \n",
      "[Training] Epoch: 23, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 23, LossG: 0.7453                                    \n",
      "[Training] Epoch: 24 [DONE]                                 \n",
      "[Training] Epoch: 24, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 24, LossG: 0.7453                                    \n",
      "[Training] Epoch: 25 [DONE]                                 \n",
      "[Training] Epoch: 25, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 25, LossG: 0.7453                                    \n",
      "[Training] Epoch: 26 [DONE]                                 \n",
      "[Training] Epoch: 26, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 26, LossG: 0.7453                                    \n",
      "[Training] Epoch: 27 [DONE]                                 \n",
      "[Training] Epoch: 27, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 27, LossG: 0.7453                                    \n",
      "[Training] Epoch: 28 [DONE]                                 \n",
      "[Training] Epoch: 28, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 28, LossG: 0.7453                                    \n",
      "[Training] Epoch: 29 [DONE]                                 \n",
      "[Training] Epoch: 29, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 29, LossG: 0.7454                                    \n",
      "[Training] Epoch: 30 [DONE]                                 \n",
      "[Training] Epoch: 30, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 30, LossG: 0.7454                                    \n",
      "[Training] Epoch: 31 [DONE]                                 \n",
      "[Training] Epoch: 31, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 31, LossG: 0.7454                                    \n",
      "[Training] Epoch: 32 [DONE]                                 \n",
      "[Training] Epoch: 32, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 32, LossG: 0.7454                                    \n",
      "[Training] Epoch: 33 [DONE]                                 \n",
      "[Training] Epoch: 33, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 33, LossG: 0.7454                                    \n",
      "[Training] Epoch: 34 [DONE]                                 \n",
      "[Training] Epoch: 34, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 34, LossG: 0.7454                                    \n",
      "[Training] Epoch: 35 [DONE]                                 \n",
      "[Training] Epoch: 35, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 35, LossG: 0.7454                                    \n",
      "[Training] Epoch: 36 [DONE]                                 \n",
      "[Training] Epoch: 36, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 36, LossG: 0.7454                                    \n",
      "[Training] Epoch: 37 [DONE]                                 \n",
      "[Training] Epoch: 37, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 37, LossG: 0.7455                                    \n",
      "[Training] Epoch: 38 [DONE]                                 \n",
      "[Training] Epoch: 38, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 38, LossG: 0.7455                                    \n",
      "[Training] Epoch: 39 [DONE]                                 \n",
      "[Training] Epoch: 39, LossG: 0.7456==================================================================] 100.0%\n",
      "[Validation] Epoch: 39, LossG: 0.7456                                    \n",
      "[Training] Epoch: 40 [DONE]                                 \n",
      "[Training] Epoch: 40, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 40, LossG: 0.7455                                    \n",
      "[Training] Epoch: 41 [DONE]                                 \n",
      "[Training] Epoch: 41, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 41, LossG: 0.7455                                    \n",
      "[Training] Epoch: 42 [DONE]                                 \n",
      "[Training] Epoch: 42, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 42, LossG: 0.7454                                    \n",
      "[Training] Epoch: 43 [DONE]                                 \n",
      "[Training] Epoch: 43, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 43, LossG: 0.7454                                    \n",
      "[Training] Epoch: 44 [DONE]                                 \n",
      "[Training] Epoch: 44, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 44, LossG: 0.7454                                    \n",
      "[Training] Epoch: 45 [DONE]                                 \n",
      "[Training] Epoch: 45, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 45, LossG: 0.7453                                    \n",
      "[Training] Epoch: 46 [DONE]                                 \n",
      "[Training] Epoch: 46, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 46, LossG: 0.7454                                    \n",
      "[Training] Epoch: 47 [DONE]                                 \n",
      "[Training] Epoch: 47, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 47, LossG: 0.7454                                    \n",
      "[Training] Epoch: 48 [DONE]                                 \n",
      "[Training] Epoch: 48, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 48, LossG: 0.7453                                    \n",
      "[Training] Epoch: 49 [DONE]                                 \n",
      "[Training] Epoch: 49, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 49, LossG: 0.7453                                    \n",
      "[Training] Epoch: 50 [DONE]                                 \n",
      "[Training] Epoch: 50, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 50, LossG: 0.7454                                    \n",
      "[Training] Epoch: 51 [DONE]                                 \n",
      "[Training] Epoch: 51, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 51, LossG: 0.7454                                    \n",
      "[Training] Epoch: 52 [DONE]                                 \n",
      "[Training] Epoch: 52, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 52, LossG: 0.7453                                    \n",
      "[Training] Epoch: 53 [DONE]                                 \n",
      "[Training] Epoch: 53, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 53, LossG: 0.7453                                    \n",
      "[Training] Epoch: 54 [DONE]                                 \n",
      "[Training] Epoch: 54, LossG: 0.7455==================================================================] 100.0%\n",
      "[Validation] Epoch: 54, LossG: 0.7455                                    \n",
      "[Training] Epoch: 55 [DONE]                                 \n",
      "[Training] Epoch: 55, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 55, LossG: 0.7454                                    \n",
      "[Training] Epoch: 56 [DONE]                                 \n",
      "[Training] Epoch: 56, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 56, LossG: 0.7453                                    \n",
      "[Training] Epoch: 57 [DONE]                                 \n",
      "[Training] Epoch: 57, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 57, LossG: 0.7454                                    \n",
      "[Training] Epoch: 58 [DONE]                                 \n",
      "[Training] Epoch: 58, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 58, LossG: 0.7454                                    \n",
      "[Training] Epoch: 59 [DONE]                                 \n",
      "[Training] Epoch: 59, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 59, LossG: 0.7454                                    \n",
      "[Training] Epoch: 60 [DONE]                                 \n",
      "[Training] Epoch: 60, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 60, LossG: 0.7453                                    \n",
      "[Training] Epoch: 61 [DONE]                                 \n",
      "[Training] Epoch: 61, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 61, LossG: 0.7452                                    \n",
      "[Training] Epoch: 62 [DONE]                                 \n",
      "[Training] Epoch: 62, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 62, LossG: 0.7453                                    \n",
      "[Training] Epoch: 63 [DONE]                                 \n",
      "[Training] Epoch: 63, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 63, LossG: 0.7454                                    \n",
      "[Training] Epoch: 64 [DONE]                                 \n",
      "[Training] Epoch: 64, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 64, LossG: 0.7453                                    \n",
      "[Training] Epoch: 65 [DONE]                                 \n",
      "[Training] Epoch: 65, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 65, LossG: 0.7453                                    \n",
      "[Training] Epoch: 66 [DONE]                                 \n",
      "[Training] Epoch: 66, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 66, LossG: 0.7453                                    \n",
      "[Training] Epoch: 67 [DONE]                                 \n",
      "[Training] Epoch: 67, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 67, LossG: 0.7453                                    \n",
      "[Training] Epoch: 68 [DONE]                                 \n",
      "[Training] Epoch: 68, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 68, LossG: 0.7454                                    \n",
      "[Training] Epoch: 69 [DONE]                                 \n",
      "[Training] Epoch: 69, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 69, LossG: 0.7453                                    \n",
      "[Training] Epoch: 70 [DONE]                                 \n",
      "[Training] Epoch: 70, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 70, LossG: 0.7453                                    \n",
      "[Training] Epoch: 71 [DONE]                                 \n",
      "[Training] Epoch: 71, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 71, LossG: 0.7453                                    \n",
      "[Training] Epoch: 72 [DONE]                                 \n",
      "[Training] Epoch: 72, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 72, LossG: 0.7454                                    \n",
      "[Training] Epoch: 73 [DONE]                                 \n",
      "[Training] Epoch: 73, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 73, LossG: 0.7454                                    \n",
      "[Training] Epoch: 74 [DONE]                                 \n",
      "[Training] Epoch: 74, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 74, LossG: 0.7454                                    \n",
      "[Training] Epoch: 75 [DONE]                                 \n",
      "[Training] Epoch: 75, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 75, LossG: 0.7453                                    \n",
      "[Training] Epoch: 76 [DONE]                                 \n",
      "[Training] Epoch: 76, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 76, LossG: 0.7453                                    \n",
      "[Training] Epoch: 77 [DONE]                                 \n",
      "[Training] Epoch: 77, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 77, LossG: 0.7453                                    \n",
      "[Training] Epoch: 78 [DONE]                                 \n",
      "[Training] Epoch: 78, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 78, LossG: 0.7454                                    \n",
      "[Training] Epoch: 79 [DONE]                                 \n",
      "[Training] Epoch: 79, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 79, LossG: 0.7453                                    \n",
      "[Training] Epoch: 80 [DONE]                                 \n",
      "[Training] Epoch: 80, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 80, LossG: 0.7453                                    \n",
      "[Training] Epoch: 81 [DONE]                                 \n",
      "[Training] Epoch: 81, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 81, LossG: 0.7453                                    \n",
      "[Training] Epoch: 82 [DONE]                                 \n",
      "[Training] Epoch: 82, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 82, LossG: 0.7454                                    \n",
      "[Training] Epoch: 83 [DONE]                                 \n",
      "[Training] Epoch: 83, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 83, LossG: 0.7453                                    \n",
      "[Training] Epoch: 84 [DONE]                                 \n",
      "[Training] Epoch: 84, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 84, LossG: 0.7453                                    \n",
      "[Training] Epoch: 85 [DONE]                                 \n",
      "[Training] Epoch: 85, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 85, LossG: 0.7454                                    \n",
      "[Training] Epoch: 86 [DONE]                                 \n",
      "[Training] Epoch: 86, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 86, LossG: 0.7454                                    \n",
      "[Training] Epoch: 87 [DONE]                                 \n",
      "[Training] Epoch: 87, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 87, LossG: 0.7453                                    \n",
      "[Training] Epoch: 88 [DONE]                                 \n",
      "[Training] Epoch: 88, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 88, LossG: 0.7454                                    \n",
      "[Training] Epoch: 89 [DONE]                                 \n",
      "[Training] Epoch: 89, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 89, LossG: 0.7453                                    \n",
      "[Training] Epoch: 90 [DONE]                                 \n",
      "[Training] Epoch: 90, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 90, LossG: 0.7454                                    \n",
      "[Training] Epoch: 91 [DONE]                                 \n",
      "[Training] Epoch: 91, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 91, LossG: 0.7453                                    \n",
      "[Training] Epoch: 92 [DONE]                                 \n",
      "[Training] Epoch: 92, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 92, LossG: 0.7453                                    \n",
      "[Training] Epoch: 93 [DONE]                                 \n",
      "[Training] Epoch: 93, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 93, LossG: 0.7453                                    \n",
      "[Training] Epoch: 94 [DONE]                                 \n",
      "[Training] Epoch: 94, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 94, LossG: 0.7453                                    \n",
      "[Training] Epoch: 95 [DONE]                                 \n",
      "[Training] Epoch: 95, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 95, LossG: 0.7453                                    \n",
      "[Training] Epoch: 96 [DONE]                                 \n",
      "[Training] Epoch: 96, LossG: 0.7454==================================================================] 100.0%\n",
      "[Validation] Epoch: 96, LossG: 0.7454                                    \n",
      "[Training] Epoch: 97 [DONE]                                 \n",
      "[Training] Epoch: 97, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 97, LossG: 0.7453                                    \n",
      "[Training] Epoch: 98 [DONE]                                 \n",
      "[Training] Epoch: 98, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 98, LossG: 0.7453                                    \n",
      "[Training] Epoch: 99 [DONE]                                 \n",
      "[Training] Epoch: 99, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 99, LossG: 0.7453                                    \n",
      "[Training] Epoch: 100 [DONE]                                 \n",
      "[Training] Epoch: 100, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 100, LossG: 0.7454                                  \n",
      "[Training] Epoch: 101 [DONE]                                 \n",
      "[Training] Epoch: 101, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 101, LossG: 0.7454                                  \n",
      "[Training] Epoch: 102 [DONE]                                 \n",
      "[Training] Epoch: 102, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 102, LossG: 0.7453                                  \n",
      "[Training] Epoch: 103 [DONE]                                 \n",
      "[Training] Epoch: 103, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 103, LossG: 0.7453                                  \n",
      "[Training] Epoch: 104 [DONE]                                 \n",
      "[Training] Epoch: 104, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 104, LossG: 0.7453                                  \n",
      "[Training] Epoch: 105 [DONE]                                 \n",
      "[Training] Epoch: 105, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 105, LossG: 0.7452                                  \n",
      "[Training] Epoch: 106 [DONE]                                 \n",
      "[Training] Epoch: 106, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 106, LossG: 0.7453                                  \n",
      "[Training] Epoch: 107 [DONE]                                 \n",
      "[Training] Epoch: 107, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 107, LossG: 0.7453                                  \n",
      "[Training] Epoch: 108 [DONE]                                 \n",
      "[Training] Epoch: 108, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 108, LossG: 0.7453                                  \n",
      "[Training] Epoch: 109 [DONE]                                 \n",
      "[Training] Epoch: 109, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 109, LossG: 0.7453                                  \n",
      "[Training] Epoch: 110 [DONE]                                 \n",
      "[Training] Epoch: 110, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 110, LossG: 0.7453                                  \n",
      "[Training] Epoch: 111 [DONE]                                 \n",
      "[Training] Epoch: 111, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 111, LossG: 0.7453                                  \n",
      "[Training] Epoch: 112 [DONE]                                 \n",
      "[Training] Epoch: 112, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 112, LossG: 0.7453                                  \n",
      "[Training] Epoch: 113 [DONE]                                 \n",
      "[Training] Epoch: 113, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 113, LossG: 0.7453                                  \n",
      "[Training] Epoch: 114 [DONE]                                 \n",
      "[Training] Epoch: 114, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 114, LossG: 0.7453                                  \n",
      "[Training] Epoch: 115 [DONE]                                 \n",
      "[Training] Epoch: 115, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 115, LossG: 0.7453                                  \n",
      "[Training] Epoch: 116 [DONE]                                 \n",
      "[Training] Epoch: 116, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 116, LossG: 0.7453                                  \n",
      "[Training] Epoch: 117 [DONE]                                 \n",
      "[Training] Epoch: 117, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 117, LossG: 0.7453                                  \n",
      "[Training] Epoch: 118 [DONE]                                 \n",
      "[Training] Epoch: 118, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 118, LossG: 0.7453                                  \n",
      "[Training] Epoch: 119 [DONE]                                 \n",
      "[Training] Epoch: 119, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 119, LossG: 0.7453                                  \n",
      "[Training] Epoch: 120 [DONE]                                 \n",
      "[Training] Epoch: 120, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 120, LossG: 0.7453                                  \n",
      "[Training] Epoch: 121 [DONE]                                 \n",
      "[Training] Epoch: 121, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 121, LossG: 0.7453                                  \n",
      "[Training] Epoch: 122 [DONE]                                 \n",
      "[Training] Epoch: 122, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 122, LossG: 0.7454                                  \n",
      "[Training] Epoch: 123 [DONE]                                 \n",
      "[Training] Epoch: 123, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 123, LossG: 0.7454                                  \n",
      "[Training] Epoch: 124 [DONE]                                 \n",
      "[Training] Epoch: 124, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 124, LossG: 0.7454                                  \n",
      "[Training] Epoch: 125 [DONE]                                 \n",
      "[Training] Epoch: 125, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 125, LossG: 0.7453                                  \n",
      "[Training] Epoch: 126 [DONE]                                 \n",
      "[Training] Epoch: 126, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 126, LossG: 0.7453                                  \n",
      "[Training] Epoch: 127 [DONE]                                 \n",
      "[Training] Epoch: 127, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 127, LossG: 0.7453                                  \n",
      "[Training] Epoch: 128 [DONE]                                 \n",
      "[Training] Epoch: 128, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 128, LossG: 0.7453                                  \n",
      "[Training] Epoch: 129 [DONE]                                 \n",
      "[Training] Epoch: 129, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 129, LossG: 0.7453                                  \n",
      "[Training] Epoch: 130 [DONE]                                 \n",
      "[Training] Epoch: 130, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 130, LossG: 0.7453                                  \n",
      "[Training] Epoch: 131 [DONE]                                 \n",
      "[Training] Epoch: 131, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 131, LossG: 0.7453                                  \n",
      "[Training] Epoch: 132 [DONE]                                 \n",
      "[Training] Epoch: 132, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 132, LossG: 0.7453                                  \n",
      "[Training] Epoch: 133 [DONE]                                 \n",
      "[Training] Epoch: 133, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 133, LossG: 0.7453                                  \n",
      "[Training] Epoch: 134 [DONE]                                 \n",
      "[Training] Epoch: 134, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 134, LossG: 0.7453                                  \n",
      "[Training] Epoch: 135 [DONE]                                 \n",
      "[Training] Epoch: 135, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 135, LossG: 0.7453                                  \n",
      "[Training] Epoch: 136 [DONE]                                 \n",
      "[Training] Epoch: 136, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 136, LossG: 0.7453                                  \n",
      "[Training] Epoch: 137 [DONE]                                 \n",
      "[Training] Epoch: 137, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 137, LossG: 0.7453                                  \n",
      "[Training] Epoch: 138 [DONE]                                 \n",
      "[Training] Epoch: 138, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 138, LossG: 0.7453                                  \n",
      "[Training] Epoch: 139 [DONE]                                 \n",
      "[Training] Epoch: 139, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 139, LossG: 0.7453                                  \n",
      "[Training] Epoch: 140 [DONE]                                 \n",
      "[Training] Epoch: 140, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 140, LossG: 0.7453                                  \n",
      "[Training] Epoch: 141 [DONE]                                 \n",
      "[Training] Epoch: 141, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 141, LossG: 0.7453                                  \n",
      "[Training] Epoch: 142 [DONE]                                 \n",
      "[Training] Epoch: 142, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 142, LossG: 0.7453                                  \n",
      "[Training] Epoch: 143 [DONE]                                 \n",
      "[Training] Epoch: 143, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 143, LossG: 0.7453                                  \n",
      "[Training] Epoch: 144 [DONE]                                 \n",
      "[Training] Epoch: 144, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 144, LossG: 0.7453                                  \n",
      "[Training] Epoch: 145 [DONE]                                 \n",
      "[Training] Epoch: 145, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 145, LossG: 0.7453                                  \n",
      "[Training] Epoch: 146 [DONE]                                 \n",
      "[Training] Epoch: 146, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 146, LossG: 0.7453                                  \n",
      "[Training] Epoch: 147 [DONE]                                 \n",
      "[Training] Epoch: 147, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 147, LossG: 0.7453                                  \n",
      "[Training] Epoch: 148 [DONE]                                 \n",
      "[Training] Epoch: 148, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 148, LossG: 0.7453                                  \n",
      "[Training] Epoch: 149 [DONE]                                 \n",
      "[Training] Epoch: 149, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 149, LossG: 0.7453                                  \n",
      "[Training] Epoch: 150 [DONE]                                 \n",
      "[Training] Epoch: 150, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 150, LossG: 0.7454                                  \n",
      "[Training] Epoch: 151 [DONE]                                 \n",
      "[Training] Epoch: 151, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 151, LossG: 0.7453                                  \n",
      "[Training] Epoch: 152 [DONE]                                 \n",
      "[Training] Epoch: 152, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 152, LossG: 0.7453                                  \n",
      "[Training] Epoch: 153 [DONE]                                 \n",
      "[Training] Epoch: 153, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 153, LossG: 0.7453                                  \n",
      "[Training] Epoch: 154 [DONE]                                 \n",
      "[Training] Epoch: 154, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 154, LossG: 0.7453                                  \n",
      "[Training] Epoch: 155 [DONE]                                 \n",
      "[Training] Epoch: 155, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 155, LossG: 0.7453                                  \n",
      "[Training] Epoch: 156 [DONE]                                 \n",
      "[Training] Epoch: 156, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 156, LossG: 0.7453                                  \n",
      "[Training] Epoch: 157 [DONE]                                 \n",
      "[Training] Epoch: 157, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 157, LossG: 0.7453                                  \n",
      "[Training] Epoch: 158 [DONE]                                 \n",
      "[Training] Epoch: 158, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 158, LossG: 0.7453                                  \n",
      "[Training] Epoch: 159 [DONE]                                 \n",
      "[Training] Epoch: 159, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 159, LossG: 0.7453                                  \n",
      "[Training] Epoch: 160 [DONE]                                 \n",
      "[Training] Epoch: 160, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 160, LossG: 0.7453                                  \n",
      "[Training] Epoch: 161 [DONE]                                 \n",
      "[Training] Epoch: 161, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 161, LossG: 0.7453                                  \n",
      "[Training] Epoch: 162 [DONE]                                 \n",
      "[Training] Epoch: 162, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 162, LossG: 0.7453                                  \n",
      "[Training] Epoch: 163 [DONE]                                 \n",
      "[Training] Epoch: 163, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 163, LossG: 0.7453                                  \n",
      "[Training] Epoch: 164 [DONE]                                 \n",
      "[Training] Epoch: 164, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 164, LossG: 0.7453                                  \n",
      "[Training] Epoch: 165 [DONE]                                 \n",
      "[Training] Epoch: 165, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 165, LossG: 0.7453                                  \n",
      "[Training] Epoch: 166 [DONE]                                 \n",
      "[Training] Epoch: 166, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 166, LossG: 0.7453                                  \n",
      "[Training] Epoch: 167 [DONE]                                 \n",
      "[Training] Epoch: 167, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 167, LossG: 0.7453                                  \n",
      "[Training] Epoch: 168 [DONE]                                 \n",
      "[Training] Epoch: 168, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 168, LossG: 0.7453                                  \n",
      "[Training] Epoch: 169 [DONE]                                 \n",
      "[Training] Epoch: 169, LossG: 0.7457=================================================================] 100.0%\n",
      "[Validation] Epoch: 169, LossG: 0.7457                                  \n",
      "[Training] Epoch: 170 [DONE]                                 \n",
      "[Training] Epoch: 170, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 170, LossG: 0.7455                                  \n",
      "[Training] Epoch: 171 [DONE]                                 \n",
      "[Training] Epoch: 171, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 171, LossG: 0.7455                                  \n",
      "[Training] Epoch: 172 [DONE]                                 \n",
      "[Training] Epoch: 172, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 172, LossG: 0.7454                                  \n",
      "[Training] Epoch: 173 [DONE]                                 \n",
      "[Training] Epoch: 173, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 173, LossG: 0.7454                                  \n",
      "[Training] Epoch: 174 [DONE]                                 \n",
      "[Training] Epoch: 174, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 174, LossG: 0.7454                                  \n",
      "[Training] Epoch: 175 [DONE]                                 \n",
      "[Training] Epoch: 175, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 175, LossG: 0.7454                                  \n",
      "[Training] Epoch: 176 [DONE]                                 \n",
      "[Training] Epoch: 176, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 176, LossG: 0.7453                                  \n",
      "[Training] Epoch: 177 [DONE]                                 \n",
      "[Training] Epoch: 177, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 177, LossG: 0.7453                                  \n",
      "[Training] Epoch: 178 [DONE]                                 \n",
      "[Training] Epoch: 178, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 178, LossG: 0.7453                                  \n",
      "[Training] Epoch: 179 [DONE]                                 \n",
      "[Training] Epoch: 179, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 179, LossG: 0.7454                                  \n",
      "[Training] Epoch: 180 [DONE]                                 \n",
      "[Training] Epoch: 180, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 180, LossG: 0.7455                                  \n",
      "[Training] Epoch: 181 [DONE]                                 \n",
      "[Training] Epoch: 181, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 181, LossG: 0.7454                                  \n",
      "[Training] Epoch: 182 [DONE]                                 \n",
      "[Training] Epoch: 182, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 182, LossG: 0.7455                                  \n",
      "[Training] Epoch: 183 [DONE]                                 \n",
      "[Training] Epoch: 183, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 183, LossG: 0.7453                                  \n",
      "[Training] Epoch: 184 [DONE]                                 \n",
      "[Training] Epoch: 184, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 184, LossG: 0.7453                                  \n",
      "[Training] Epoch: 185 [DONE]                                 \n",
      "[Training] Epoch: 185, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 185, LossG: 0.7454                                  \n",
      "[Training] Epoch: 186 [DONE]                                 \n",
      "[Training] Epoch: 186, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 186, LossG: 0.7453                                  \n",
      "[Training] Epoch: 187 [DONE]                                 \n",
      "[Training] Epoch: 187, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 187, LossG: 0.7454                                  \n",
      "[Training] Epoch: 188 [DONE]                                 \n",
      "[Training] Epoch: 188, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 188, LossG: 0.7452                                  \n",
      "[Training] Epoch: 189 [DONE]                                 \n",
      "[Training] Epoch: 189, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 189, LossG: 0.7454                                  \n",
      "[Training] Epoch: 190 [DONE]                                 \n",
      "[Training] Epoch: 190, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 190, LossG: 0.7453                                  \n",
      "[Training] Epoch: 191 [DONE]                                 \n",
      "[Training] Epoch: 191, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 191, LossG: 0.7453                                  \n",
      "[Training] Epoch: 192 [DONE]                                 \n",
      "[Training] Epoch: 192, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 192, LossG: 0.7452                                  \n",
      "[Training] Epoch: 193 [DONE]                                 \n",
      "[Training] Epoch: 193, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 193, LossG: 0.7453                                  \n",
      "[Training] Epoch: 194 [DONE]                                 \n",
      "[Training] Epoch: 194, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 194, LossG: 0.7453                                  \n",
      "[Training] Epoch: 195 [DONE]                                 \n",
      "[Training] Epoch: 195, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 195, LossG: 0.7453                                  \n",
      "[Training] Epoch: 196 [DONE]                                 \n",
      "[Training] Epoch: 196, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 196, LossG: 0.7454                                  \n",
      "[Training] Epoch: 197 [DONE]                                 \n",
      "[Training] Epoch: 197, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 197, LossG: 0.7453                                  \n",
      "[Training] Epoch: 198 [DONE]                                 \n",
      "[Training] Epoch: 198, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 198, LossG: 0.7453                                  \n",
      "[Training] Epoch: 199 [DONE]                                 \n",
      "[Training] Epoch: 199, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 199, LossG: 0.7453                                  \n",
      "[Training] Epoch: 200 [DONE]                                 \n",
      "[Training] Epoch: 200, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 200, LossG: 0.7453                                  \n",
      "[Training] Epoch: 201 [DONE]                                 \n",
      "[Training] Epoch: 201, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 201, LossG: 0.7453                                  \n",
      "[Training] Epoch: 202 [DONE]                                 \n",
      "[Training] Epoch: 202, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 202, LossG: 0.7453                                  \n",
      "[Training] Epoch: 203 [DONE]                                 \n",
      "[Training] Epoch: 203, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 203, LossG: 0.7453                                  \n",
      "[Training] Epoch: 204 [DONE]                                 \n",
      "[Training] Epoch: 204, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 204, LossG: 0.7454                                  \n",
      "[Training] Epoch: 205 [DONE]                                 \n",
      "[Training] Epoch: 205, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 205, LossG: 0.7453                                  \n",
      "[Training] Epoch: 206 [DONE]                                 \n",
      "[Training] Epoch: 206, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 206, LossG: 0.7453                                  \n",
      "[Training] Epoch: 207 [DONE]                                 \n",
      "[Training] Epoch: 207, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 207, LossG: 0.7452                                  \n",
      "[Training] Epoch: 208 [DONE]                                 \n",
      "[Training] Epoch: 208, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 208, LossG: 0.7454                                  \n",
      "[Training] Epoch: 209 [DONE]                                 \n",
      "[Training] Epoch: 209, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 209, LossG: 0.7453                                  \n",
      "[Training] Epoch: 210 [DONE]                                 \n",
      "[Training] Epoch: 210, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 210, LossG: 0.7452                                  \n",
      "[Training] Epoch: 211 [DONE]                                 \n",
      "[Training] Epoch: 211, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 211, LossG: 0.7453                                  \n",
      "[Training] Epoch: 212 [DONE]                                 \n",
      "[Training] Epoch: 212, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 212, LossG: 0.7454                                  \n",
      "[Training] Epoch: 213 [DONE]                                 \n",
      "[Training] Epoch: 213, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 213, LossG: 0.7453                                  \n",
      "[Training] Epoch: 214 [DONE]                                 \n",
      "[Training] Epoch: 214, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 214, LossG: 0.7452                                  \n",
      "[Training] Epoch: 215 [DONE]                                 \n",
      "[Training] Epoch: 215, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 215, LossG: 0.7452                                  \n",
      "[Training] Epoch: 216 [DONE]                                 \n",
      "[Training] Epoch: 216, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 216, LossG: 0.7453                                  \n",
      "[Training] Epoch: 217 [DONE]                                 \n",
      "[Training] Epoch: 217, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 217, LossG: 0.7452                                  \n",
      "[Training] Epoch: 218 [DONE]                                 \n",
      "[Training] Epoch: 218, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 218, LossG: 0.7453                                  \n",
      "[Training] Epoch: 219 [DONE]                                 \n",
      "[Training] Epoch: 219, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 219, LossG: 0.7452                                  \n",
      "[Training] Epoch: 220 [DONE]                                 \n",
      "[Training] Epoch: 220, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 220, LossG: 0.7453                                  \n",
      "[Training] Epoch: 221 [DONE]                                 \n",
      "[Training] Epoch: 221, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 221, LossG: 0.7453                                  \n",
      "[Training] Epoch: 222 [DONE]                                 \n",
      "[Training] Epoch: 222, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 222, LossG: 0.7453                                  \n",
      "[Training] Epoch: 223 [DONE]                                 \n",
      "[Training] Epoch: 223, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 223, LossG: 0.7453                                  \n",
      "[Training] Epoch: 224 [DONE]                                 \n",
      "[Training] Epoch: 224, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 224, LossG: 0.7453                                  \n",
      "[Training] Epoch: 225 [DONE]                                 \n",
      "[Training] Epoch: 225, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 225, LossG: 0.7453                                  \n",
      "[Training] Epoch: 226 [DONE]                                 \n",
      "[Training] Epoch: 226, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 226, LossG: 0.7454                                  \n",
      "[Training] Epoch: 227 [DONE]                                 \n",
      "[Training] Epoch: 227, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 227, LossG: 0.7453                                  \n",
      "[Training] Epoch: 228 [DONE]                                 \n",
      "[Training] Epoch: 228, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 228, LossG: 0.7453                                  \n",
      "[Training] Epoch: 229 [DONE]                                 \n",
      "[Training] Epoch: 229, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 229, LossG: 0.7453                                  \n",
      "[Training] Epoch: 230 [DONE]                                 \n",
      "[Training] Epoch: 230, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 230, LossG: 0.7452                                  \n",
      "[Training] Epoch: 231 [DONE]                                 \n",
      "[Training] Epoch: 231, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 231, LossG: 0.7453                                  \n",
      "[Training] Epoch: 232 [DONE]                                 \n",
      "[Training] Epoch: 232, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 232, LossG: 0.7453                                  \n",
      "[Training] Epoch: 233 [DONE]                                 \n",
      "[Training] Epoch: 233, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 233, LossG: 0.7452                                  \n",
      "[Training] Epoch: 234 [DONE]                                 \n",
      "[Training] Epoch: 234, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 234, LossG: 0.7453                                  \n",
      "[Training] Epoch: 235 [DONE]                                 \n",
      "[Training] Epoch: 235, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 235, LossG: 0.7453                                  \n",
      "[Training] Epoch: 236 [DONE]                                 \n",
      "[Training] Epoch: 236, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 236, LossG: 0.7453                                  \n",
      "[Training] Epoch: 237 [DONE]                                 \n",
      "[Training] Epoch: 237, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 237, LossG: 0.7453                                  \n",
      "[Training] Epoch: 238 [DONE]                                 \n",
      "[Training] Epoch: 238, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 238, LossG: 0.7452                                  \n",
      "[Training] Epoch: 239 [DONE]                                 \n",
      "[Training] Epoch: 239, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 239, LossG: 0.7452                                  \n",
      "[Training] Epoch: 240 [DONE]                                 \n",
      "[Training] Epoch: 240, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 240, LossG: 0.7452                                  \n",
      "[Training] Epoch: 241 [DONE]                                 \n",
      "[Training] Epoch: 241, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 241, LossG: 0.7452                                  \n",
      "[Training] Epoch: 242 [DONE]                                 \n",
      "[Training] Epoch: 242, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 242, LossG: 0.7452                                  \n",
      "[Training] Epoch: 243 [DONE]                                 \n",
      "[Training] Epoch: 243, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 243, LossG: 0.7453                                  \n",
      "[Training] Epoch: 244 [DONE]                                 \n",
      "[Training] Epoch: 244, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 244, LossG: 0.7452                                  \n",
      "[Training] Epoch: 245 [DONE]                                 \n",
      "[Training] Epoch: 245, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 245, LossG: 0.7452                                  \n",
      "[Training] Epoch: 246 [DONE]                                 \n",
      "[Training] Epoch: 246, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 246, LossG: 0.7453                                  \n",
      "[Training] Epoch: 247 [DONE]                                 \n",
      "[Training] Epoch: 247, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 247, LossG: 0.7453                                  \n",
      "[Training] Epoch: 248 [DONE]                                 \n",
      "[Training] Epoch: 248, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 248, LossG: 0.7453                                  \n",
      "[Training] Epoch: 249 [DONE]                                 \n",
      "[Training] Epoch: 249, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 249, LossG: 0.7454                                  \n",
      "[Training] Epoch: 250 [DONE]                                 \n",
      "[Training] Epoch: 250, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 250, LossG: 0.7454                                  \n",
      "[Training] Epoch: 251 [DONE]                                 \n",
      "[Training] Epoch: 251, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 251, LossG: 0.7453                                  \n",
      "[Training] Epoch: 252 [DONE]                                 \n",
      "[Training] Epoch: 252, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 252, LossG: 0.7453                                  \n",
      "[Training] Epoch: 253 [DONE]                                 \n",
      "[Training] Epoch: 253, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 253, LossG: 0.7452                                  \n",
      "[Training] Epoch: 254 [DONE]                                 \n",
      "[Training] Epoch: 254, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 254, LossG: 0.7453                                  \n",
      "[Training] Epoch: 255 [DONE]                                 \n",
      "[Training] Epoch: 255, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 255, LossG: 0.7453                                  \n",
      "[Training] Epoch: 256 [DONE]                                 \n",
      "[Training] Epoch: 256, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 256, LossG: 0.7454                                  \n",
      "[Training] Epoch: 257 [DONE]                                 \n",
      "[Training] Epoch: 257, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 257, LossG: 0.7453                                  \n",
      "[Training] Epoch: 258 [DONE]                                 \n",
      "[Training] Epoch: 258, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 258, LossG: 0.7453                                  \n",
      "[Training] Epoch: 259 [DONE]                                 \n",
      "[Training] Epoch: 259, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 259, LossG: 0.7453                                  \n",
      "[Training] Epoch: 260 [DONE]                                 \n",
      "[Training] Epoch: 260, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 260, LossG: 0.7453                                  \n",
      "[Training] Epoch: 261 [DONE]                                 \n",
      "[Training] Epoch: 261, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 261, LossG: 0.7453                                  \n",
      "[Training] Epoch: 262 [DONE]                                 \n",
      "[Training] Epoch: 262, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 262, LossG: 0.7452                                  \n",
      "[Training] Epoch: 263 [DONE]                                 \n",
      "[Training] Epoch: 263, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 263, LossG: 0.7453                                  \n",
      "[Training] Epoch: 264 [DONE]                                 \n",
      "[Training] Epoch: 264, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 264, LossG: 0.7452                                  \n",
      "[Training] Epoch: 265 [DONE]                                 \n",
      "[Training] Epoch: 265, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 265, LossG: 0.7453                                  \n",
      "[Training] Epoch: 266 [DONE]                                 \n",
      "[Training] Epoch: 266, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 266, LossG: 0.7453                                  \n",
      "[Training] Epoch: 267 [DONE]                                 \n",
      "[Training] Epoch: 267, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 267, LossG: 0.7453                                  \n",
      "[Training] Epoch: 268 [DONE]                                 \n",
      "[Training] Epoch: 268, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 268, LossG: 0.7452                                  \n",
      "[Training] Epoch: 269 [DONE]                                 \n",
      "[Training] Epoch: 269, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 269, LossG: 0.7454                                  \n",
      "[Training] Epoch: 270 [DONE]                                 \n",
      "[Training] Epoch: 270, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 270, LossG: 0.7454                                  \n",
      "[Training] Epoch: 271 [DONE]                                 \n",
      "[Training] Epoch: 271, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 271, LossG: 0.7454                                  \n",
      "[Training] Epoch: 272 [DONE]                                 \n",
      "[Training] Epoch: 272, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 272, LossG: 0.7453                                  \n",
      "[Training] Epoch: 273 [DONE]                                 \n",
      "[Training] Epoch: 273, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 273, LossG: 0.7453                                  \n",
      "[Training] Epoch: 274 [DONE]                                 \n",
      "[Training] Epoch: 274, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 274, LossG: 0.7453                                  \n",
      "[Training] Epoch: 275 [DONE]                                 \n",
      "[Training] Epoch: 275, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 275, LossG: 0.7453                                  \n",
      "[Training] Epoch: 276 [DONE]                                 \n",
      "[Training] Epoch: 276, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 276, LossG: 0.7453                                  \n",
      "[Training] Epoch: 277 [DONE]                                 \n",
      "[Training] Epoch: 277, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 277, LossG: 0.7452                                  \n",
      "[Training] Epoch: 278 [DONE]                                 \n",
      "[Training] Epoch: 278, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 278, LossG: 0.7453                                  \n",
      "[Training] Epoch: 279 [DONE]                                 \n",
      "[Training] Epoch: 279, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 279, LossG: 0.7454                                  \n",
      "[Training] Epoch: 280 [DONE]                                 \n",
      "[Training] Epoch: 280, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 280, LossG: 0.7453                                  \n",
      "[Training] Epoch: 281 [DONE]                                 \n",
      "[Training] Epoch: 281, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 281, LossG: 0.7453                                  \n",
      "[Training] Epoch: 282 [DONE]                                 \n",
      "[Training] Epoch: 282, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 282, LossG: 0.7453                                  \n",
      "[Training] Epoch: 283 [DONE]                                 \n",
      "[Training] Epoch: 283, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 283, LossG: 0.7453                                  \n",
      "[Training] Epoch: 284 [DONE]                                 \n",
      "[Training] Epoch: 284, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 284, LossG: 0.7453                                  \n",
      "[Training] Epoch: 285 [DONE]                                 \n",
      "[Training] Epoch: 285, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 285, LossG: 0.7452                                  \n",
      "[Training] Epoch: 286 [DONE]                                 \n",
      "[Training] Epoch: 286, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 286, LossG: 0.7453                                  \n",
      "[Training] Epoch: 287 [DONE]                                 \n",
      "[Training] Epoch: 287, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 287, LossG: 0.7452                                  \n",
      "[Training] Epoch: 288 [DONE]                                 \n",
      "[Training] Epoch: 288, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 288, LossG: 0.7453                                  \n",
      "[Training] Epoch: 289 [DONE]                                 \n",
      "[Training] Epoch: 289, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 289, LossG: 0.7453                                  \n",
      "[Training] Epoch: 290 [DONE]                                 \n",
      "[Training] Epoch: 290, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 290, LossG: 0.7452                                  \n",
      "[Training] Epoch: 291 [DONE]                                 \n",
      "[Training] Epoch: 291, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 291, LossG: 0.7452                                  \n",
      "[Training] Epoch: 292 [DONE]                                 \n",
      "[Training] Epoch: 292, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 292, LossG: 0.7452                                  \n",
      "[Training] Epoch: 293 [DONE]                                 \n",
      "[Training] Epoch: 293, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 293, LossG: 0.7452                                  \n",
      "[Training] Epoch: 294 [DONE]                                 \n",
      "[Training] Epoch: 294, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 294, LossG: 0.7452                                  \n",
      "[Training] Epoch: 295 [DONE]                                 \n",
      "[Training] Epoch: 295, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 295, LossG: 0.7453                                  \n",
      "[Training] Epoch: 296 [DONE]                                 \n",
      "[Training] Epoch: 296, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 296, LossG: 0.7453                                  \n",
      "[Training] Epoch: 297 [DONE]                                 \n",
      "[Training] Epoch: 297, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 297, LossG: 0.7452                                  \n",
      "[Training] Epoch: 298 [DONE]                                 \n",
      "[Training] Epoch: 298, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 298, LossG: 0.7452                                  \n",
      "[Training] Epoch: 299 [DONE]                                 \n",
      "[Training] Epoch: 299, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 299, LossG: 0.7453                                  \n",
      "[Training] Epoch: 300 [DONE]                                 \n",
      "[Training] Epoch: 300, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 300, LossG: 0.7453                                  \n",
      "[Training] Epoch: 301 [DONE]                                 \n",
      "[Training] Epoch: 301, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 301, LossG: 0.7453                                  \n",
      "[Training] Epoch: 302 [DONE]                                 \n",
      "[Training] Epoch: 302, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 302, LossG: 0.7452                                  \n",
      "[Training] Epoch: 303 [DONE]                                 \n",
      "[Training] Epoch: 303, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 303, LossG: 0.7453                                  \n",
      "[Training] Epoch: 304 [DONE]                                 \n",
      "[Training] Epoch: 304, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 304, LossG: 0.7453                                  \n",
      "[Training] Epoch: 305 [DONE]                                 \n",
      "[Training] Epoch: 305, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 305, LossG: 0.7453                                  \n",
      "[Training] Epoch: 306 [DONE]                                 \n",
      "[Training] Epoch: 306, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 306, LossG: 0.7452                                  \n",
      "[Training] Epoch: 307 [DONE]                                 \n",
      "[Training] Epoch: 307, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 307, LossG: 0.7452                                  \n",
      "[Training] Epoch: 308 [DONE]                                 \n",
      "[Training] Epoch: 308, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 308, LossG: 0.7453                                  \n",
      "[Training] Epoch: 309 [DONE]                                 \n",
      "[Training] Epoch: 309, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 309, LossG: 0.7453                                  \n",
      "[Training] Epoch: 310 [DONE]                                 \n",
      "[Training] Epoch: 310, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 310, LossG: 0.7453                                  \n",
      "[Training] Epoch: 311 [DONE]                                 \n",
      "[Training] Epoch: 311, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 311, LossG: 0.7452                                  \n",
      "[Training] Epoch: 312 [DONE]                                 \n",
      "[Training] Epoch: 312, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 312, LossG: 0.7452                                  \n",
      "[Training] Epoch: 313 [DONE]                                 \n",
      "[Training] Epoch: 313, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 313, LossG: 0.7453                                  \n",
      "[Training] Epoch: 314 [DONE]                                 \n",
      "[Training] Epoch: 314, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 314, LossG: 0.7453                                  \n",
      "[Training] Epoch: 315 [DONE]                                 \n",
      "[Training] Epoch: 315, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 315, LossG: 0.7453                                  \n",
      "[Training] Epoch: 316 [DONE]                                 \n",
      "[Training] Epoch: 316, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 316, LossG: 0.7452                                  \n",
      "[Training] Epoch: 317 [DONE]                                 \n",
      "[Training] Epoch: 317, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 317, LossG: 0.7452                                  \n",
      "[Training] Epoch: 318 [DONE]                                 \n",
      "[Training] Epoch: 318, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 318, LossG: 0.7452                                  \n",
      "[Training] Epoch: 319 [DONE]                                 \n",
      "[Training] Epoch: 319, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 319, LossG: 0.7452                                  \n",
      "[Training] Epoch: 320 [DONE]                                 \n",
      "[Training] Epoch: 320, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 320, LossG: 0.7452                                  \n",
      "[Training] Epoch: 321 [DONE]                                 \n",
      "[Training] Epoch: 321, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 321, LossG: 0.7453                                  \n",
      "[Training] Epoch: 322 [DONE]                                 \n",
      "[Training] Epoch: 322, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 322, LossG: 0.7452                                  \n",
      "[Training] Epoch: 323 [DONE]                                 \n",
      "[Training] Epoch: 323, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 323, LossG: 0.7453                                  \n",
      "[Training] Epoch: 324 [DONE]                                 \n",
      "[Training] Epoch: 324, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 324, LossG: 0.7452                                  \n",
      "[Training] Epoch: 325 [DONE]                                 \n",
      "[Training] Epoch: 325, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 325, LossG: 0.7452                                  \n",
      "[Training] Epoch: 326 [DONE]                                 \n",
      "[Training] Epoch: 326, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 326, LossG: 0.7452                                  \n",
      "[Training] Epoch: 327 [DONE]                                 \n",
      "[Training] Epoch: 327, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 327, LossG: 0.7453                                  \n",
      "[Training] Epoch: 328 [DONE]                                 \n",
      "[Training] Epoch: 328, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 328, LossG: 0.7452                                  \n",
      "[Training] Epoch: 329 [DONE]                                 \n",
      "[Training] Epoch: 329, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 329, LossG: 0.7453                                  \n",
      "[Training] Epoch: 330 [DONE]                                 \n",
      "[Training] Epoch: 330, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 330, LossG: 0.7452                                  \n",
      "[Training] Epoch: 331 [DONE]                                 \n",
      "[Training] Epoch: 331, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 331, LossG: 0.7452                                  \n",
      "[Training] Epoch: 332 [DONE]                                 \n",
      "[Training] Epoch: 332, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 332, LossG: 0.7452                                  \n",
      "[Training] Epoch: 333 [DONE]                                 \n",
      "[Training] Epoch: 333, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 333, LossG: 0.7453                                  \n",
      "[Training] Epoch: 334 [DONE]                                 \n",
      "[Training] Epoch: 334, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 334, LossG: 0.7452                                  \n",
      "[Training] Epoch: 335 [DONE]                                 \n",
      "[Training] Epoch: 335, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 335, LossG: 0.7452                                  \n",
      "[Training] Epoch: 336 [DONE]                                 \n",
      "[Training] Epoch: 336, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 336, LossG: 0.7453                                  \n",
      "[Training] Epoch: 337 [DONE]                                 \n",
      "[Training] Epoch: 337, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 337, LossG: 0.7452                                  \n",
      "[Training] Epoch: 338 [DONE]                                 \n",
      "[Training] Epoch: 338, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 338, LossG: 0.7453                                  \n",
      "[Training] Epoch: 339 [DONE]                                 \n",
      "[Training] Epoch: 339, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 339, LossG: 0.7453                                  \n",
      "[Training] Epoch: 340 [DONE]                                 \n",
      "[Training] Epoch: 340, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 340, LossG: 0.7453                                  \n",
      "[Training] Epoch: 341 [DONE]                                 \n",
      "[Training] Epoch: 341, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 341, LossG: 0.7452                                  \n",
      "[Training] Epoch: 342 [DONE]                                 \n",
      "[Training] Epoch: 342, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 342, LossG: 0.7453                                  \n",
      "[Training] Epoch: 343 [DONE]                                 \n",
      "[Training] Epoch: 343, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 343, LossG: 0.7452                                  \n",
      "[Training] Epoch: 344 [DONE]                                 \n",
      "[Training] Epoch: 344, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 344, LossG: 0.7452                                  \n",
      "[Training] Epoch: 345 [DONE]                                 \n",
      "[Training] Epoch: 345, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 345, LossG: 0.7452                                  \n",
      "[Training] Epoch: 346 [DONE]                                 \n",
      "[Training] Epoch: 346, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 346, LossG: 0.7452                                  \n",
      "[Training] Epoch: 347 [DONE]                                 \n",
      "[Training] Epoch: 347, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 347, LossG: 0.7452                                  \n",
      "[Training] Epoch: 348 [DONE]                                 \n",
      "[Training] Epoch: 348, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 348, LossG: 0.7452                                  \n",
      "[Training] Epoch: 349 [DONE]                                 \n",
      "[Training] Epoch: 349, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 349, LossG: 0.7453                                  \n",
      "[Training] Epoch: 350 [DONE]                                 \n",
      "[Training] Epoch: 350, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 350, LossG: 0.7453                                  \n",
      "[Training] Epoch: 351 [DONE]                                 \n",
      "[Training] Epoch: 351, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 351, LossG: 0.7452                                  \n",
      "[Training] Epoch: 352 [DONE]                                 \n",
      "[Training] Epoch: 352, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 352, LossG: 0.7452                                  \n",
      "[Training] Epoch: 353 [DONE]                                 \n",
      "[Training] Epoch: 353, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 353, LossG: 0.7452                                  \n",
      "[Training] Epoch: 354 [DONE]                                 \n",
      "[Training] Epoch: 354, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 354, LossG: 0.7452                                  \n",
      "[Training] Epoch: 355 [DONE]                                 \n",
      "[Training] Epoch: 355, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 355, LossG: 0.7453                                  \n",
      "[Training] Epoch: 356 [DONE]                                 \n",
      "[Training] Epoch: 356, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 356, LossG: 0.7452                                  \n",
      "[Training] Epoch: 357 [DONE]                                 \n",
      "[Training] Epoch: 357, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 357, LossG: 0.7452                                  \n",
      "[Training] Epoch: 358 [DONE]                                 \n",
      "[Training] Epoch: 358, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 358, LossG: 0.7452                                  \n",
      "[Training] Epoch: 359 [DONE]                                 \n",
      "[Training] Epoch: 359, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 359, LossG: 0.7452                                  \n",
      "[Training] Epoch: 360 [DONE]                                 \n",
      "[Training] Epoch: 360, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 360, LossG: 0.7452                                  \n",
      "[Training] Epoch: 361 [DONE]                                 \n",
      "[Training] Epoch: 361, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 361, LossG: 0.7452                                  \n",
      "[Training] Epoch: 362 [DONE]                                 \n",
      "[Training] Epoch: 362, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 362, LossG: 0.7452                                  \n",
      "[Training] Epoch: 363 [DONE]                                 \n",
      "[Training] Epoch: 363, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 363, LossG: 0.7452                                  \n",
      "[Training] Epoch: 364 [DONE]                                 \n",
      "[Training] Epoch: 364, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 364, LossG: 0.7452                                  \n",
      "[Training] Epoch: 365 [DONE]                                 \n",
      "[Training] Epoch: 365, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 365, LossG: 0.7452                                  \n",
      "[Training] Epoch: 366 [DONE]                                 \n",
      "[Training] Epoch: 366, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 366, LossG: 0.7453                                  \n",
      "[Training] Epoch: 367 [DONE]                                 \n",
      "[Training] Epoch: 367, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 367, LossG: 0.7452                                  \n",
      "[Training] Epoch: 368 [DONE]                                 \n",
      "[Training] Epoch: 368, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 368, LossG: 0.7452                                  \n",
      "[Training] Epoch: 369 [DONE]                                 \n",
      "[Training] Epoch: 369, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 369, LossG: 0.7453                                  \n",
      "[Training] Epoch: 370 [DONE]                                 \n",
      "[Training] Epoch: 370, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 370, LossG: 0.7452                                  \n",
      "[Training] Epoch: 371 [DONE]                                 \n",
      "[Training] Epoch: 371, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 371, LossG: 0.7452                                  \n",
      "[Training] Epoch: 372 [DONE]                                 \n",
      "[Training] Epoch: 372, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 372, LossG: 0.7452                                  \n",
      "[Training] Epoch: 373 [DONE]                                 \n",
      "[Training] Epoch: 373, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 373, LossG: 0.7452                                  \n",
      "[Training] Epoch: 374 [DONE]                                 \n",
      "[Training] Epoch: 374, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 374, LossG: 0.7452                                  \n",
      "[Training] Epoch: 375 [DONE]                                 \n",
      "[Training] Epoch: 375, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 375, LossG: 0.7453                                  \n",
      "[Training] Epoch: 376 [DONE]                                 \n",
      "[Training] Epoch: 376, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 376, LossG: 0.7452                                  \n",
      "[Training] Epoch: 377 [DONE]                                 \n",
      "[Training] Epoch: 377, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 377, LossG: 0.7452                                  \n",
      "[Training] Epoch: 378 [DONE]                                 \n",
      "[Training] Epoch: 378, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 378, LossG: 0.7453                                  \n",
      "[Training] Epoch: 379 [DONE]                                 \n",
      "[Training] Epoch: 379, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 379, LossG: 0.7454                                  \n",
      "[Training] Epoch: 380 [DONE]                                 \n",
      "[Training] Epoch: 380, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 380, LossG: 0.7453                                  \n",
      "[Training] Epoch: 381 [DONE]                                 \n",
      "[Training] Epoch: 381, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 381, LossG: 0.7453                                  \n",
      "[Training] Epoch: 382 [DONE]                                 \n",
      "[Training] Epoch: 382, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 382, LossG: 0.7452                                  \n",
      "[Training] Epoch: 383 [DONE]                                 \n",
      "[Training] Epoch: 383, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 383, LossG: 0.7453                                  \n",
      "[Training] Epoch: 384 [DONE]                                 \n",
      "[Training] Epoch: 384, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 384, LossG: 0.7453                                  \n",
      "[Training] Epoch: 385 [DONE]                                 \n",
      "[Training] Epoch: 385, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 385, LossG: 0.7452                                  \n",
      "[Training] Epoch: 386 [DONE]                                 \n",
      "[Training] Epoch: 386, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 386, LossG: 0.7453                                  \n",
      "[Training] Epoch: 387 [DONE]                                 \n",
      "[Training] Epoch: 387, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 387, LossG: 0.7454                                  \n",
      "[Training] Epoch: 388 [DONE]                                 \n",
      "[Training] Epoch: 388, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 388, LossG: 0.7453                                  \n",
      "[Training] Epoch: 389 [DONE]                                 \n",
      "[Training] Epoch: 389, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 389, LossG: 0.7454                                  \n",
      "[Training] Epoch: 390 [DONE]                                 \n",
      "[Training] Epoch: 390, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 390, LossG: 0.7453                                  \n",
      "[Training] Epoch: 391 [DONE]                                 \n",
      "[Training] Epoch: 391, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 391, LossG: 0.7452                                  \n",
      "[Training] Epoch: 392 [DONE]                                 \n",
      "[Training] Epoch: 392, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 392, LossG: 0.7453                                  \n",
      "[Training] Epoch: 393 [DONE]                                 \n",
      "[Training] Epoch: 393, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 393, LossG: 0.7452                                  \n",
      "[Training] Epoch: 394 [DONE]                                 \n",
      "[Training] Epoch: 394, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 394, LossG: 0.7453                                  \n",
      "[Training] Epoch: 395 [DONE]                                 \n",
      "[Training] Epoch: 395, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 395, LossG: 0.7452                                  \n",
      "[Training] Epoch: 396 [DONE]                                 \n",
      "[Training] Epoch: 396, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 396, LossG: 0.7453                                  \n",
      "[Training] Epoch: 397 [DONE]                                 \n",
      "[Training] Epoch: 397, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 397, LossG: 0.7453                                  \n",
      "[Training] Epoch: 398 [DONE]                                 \n",
      "[Training] Epoch: 398, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 398, LossG: 0.7455                                  \n",
      "[Training] Epoch: 399 [DONE]                                 \n",
      "[Training] Epoch: 399, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 399, LossG: 0.7454                                  \n",
      "[Training] Epoch: 400 [DONE]                                 \n",
      "[Training] Epoch: 400, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 400, LossG: 0.7453                                  \n",
      "[Training] Epoch: 401 [DONE]                                 \n",
      "[Training] Epoch: 401, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 401, LossG: 0.7453                                  \n",
      "[Training] Epoch: 402 [DONE]                                 \n",
      "[Training] Epoch: 402, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 402, LossG: 0.7453                                  \n",
      "[Training] Epoch: 403 [DONE]                                 \n",
      "[Training] Epoch: 403, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 403, LossG: 0.7455                                  \n",
      "[Training] Epoch: 404 [DONE]                                 \n",
      "[Training] Epoch: 404, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 404, LossG: 0.7455                                  \n",
      "[Training] Epoch: 405 [DONE]                                 \n",
      "[Training] Epoch: 405, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 405, LossG: 0.7455                                  \n",
      "[Training] Epoch: 406 [DONE]                                 \n",
      "[Training] Epoch: 406, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 406, LossG: 0.7454                                  \n",
      "[Training] Epoch: 407 [DONE]                                 \n",
      "[Training] Epoch: 407, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 407, LossG: 0.7454                                  \n",
      "[Training] Epoch: 408 [DONE]                                 \n",
      "[Training] Epoch: 408, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 408, LossG: 0.7453                                  \n",
      "[Training] Epoch: 409 [DONE]                                 \n",
      "[Training] Epoch: 409, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 409, LossG: 0.7453                                  \n",
      "[Training] Epoch: 410 [DONE]                                 \n",
      "[Training] Epoch: 410, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 410, LossG: 0.7453                                  \n",
      "[Training] Epoch: 411 [DONE]                                 \n",
      "[Training] Epoch: 411, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 411, LossG: 0.7453                                  \n",
      "[Training] Epoch: 412 [DONE]                                 \n",
      "[Training] Epoch: 412, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 412, LossG: 0.7453                                  \n",
      "[Training] Epoch: 413 [DONE]                                 \n",
      "[Training] Epoch: 413, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 413, LossG: 0.7452                                  \n",
      "[Training] Epoch: 414 [DONE]                                 \n",
      "[Training] Epoch: 414, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 414, LossG: 0.7453                                  \n",
      "[Training] Epoch: 415 [DONE]                                 \n",
      "[Training] Epoch: 415, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 415, LossG: 0.7453                                  \n",
      "[Training] Epoch: 416 [DONE]                                 \n",
      "[Training] Epoch: 416, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 416, LossG: 0.7453                                  \n",
      "[Training] Epoch: 417 [DONE]                                 \n",
      "[Training] Epoch: 417, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 417, LossG: 0.7452                                  \n",
      "[Training] Epoch: 418 [DONE]                                 \n",
      "[Training] Epoch: 418, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 418, LossG: 0.7453                                  \n",
      "[Training] Epoch: 419 [DONE]                                 \n",
      "[Training] Epoch: 419, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 419, LossG: 0.7453                                  \n",
      "[Training] Epoch: 420 [DONE]                                 \n",
      "[Training] Epoch: 420, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 420, LossG: 0.7452                                  \n",
      "[Training] Epoch: 421 [DONE]                                 \n",
      "[Training] Epoch: 421, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 421, LossG: 0.7453                                  \n",
      "[Training] Epoch: 422 [DONE]                                 \n",
      "[Training] Epoch: 422, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 422, LossG: 0.7453                                  \n",
      "[Training] Epoch: 423 [DONE]                                 \n",
      "[Training] Epoch: 423, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 423, LossG: 0.7452                                  \n",
      "[Training] Epoch: 424 [DONE]                                 \n",
      "[Training] Epoch: 424, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 424, LossG: 0.7453                                  \n",
      "[Training] Epoch: 425 [DONE]                                 \n",
      "[Training] Epoch: 425, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 425, LossG: 0.7453                                  \n",
      "[Training] Epoch: 426 [DONE]                                 \n",
      "[Training] Epoch: 426, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 426, LossG: 0.7453                                  \n",
      "[Training] Epoch: 427 [DONE]                                 \n",
      "[Training] Epoch: 427, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 427, LossG: 0.7452                                  \n",
      "[Training] Epoch: 428 [DONE]                                 \n",
      "[Training] Epoch: 428, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 428, LossG: 0.7452                                  \n",
      "[Training] Epoch: 429 [DONE]                                 \n",
      "[Training] Epoch: 429, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 429, LossG: 0.7452                                  \n",
      "[Training] Epoch: 430 [DONE]                                 \n",
      "[Training] Epoch: 430, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 430, LossG: 0.7452                                  \n",
      "[Training] Epoch: 431 [DONE]                                 \n",
      "[Training] Epoch: 431, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 431, LossG: 0.7452                                  \n",
      "[Training] Epoch: 432 [DONE]                                 \n",
      "[Training] Epoch: 432, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 432, LossG: 0.7452                                  \n",
      "[Training] Epoch: 433 [DONE]                                 \n",
      "[Training] Epoch: 433, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 433, LossG: 0.7453                                  \n",
      "[Training] Epoch: 434 [DONE]                                 \n",
      "[Training] Epoch: 434, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 434, LossG: 0.7452                                  \n",
      "[Training] Epoch: 435 [DONE]                                 \n",
      "[Training] Epoch: 435, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 435, LossG: 0.7452                                  \n",
      "[Training] Epoch: 436 [DONE]                                 \n",
      "[Training] Epoch: 436, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 436, LossG: 0.7452                                  \n",
      "[Training] Epoch: 437 [DONE]                                 \n",
      "[Training] Epoch: 437, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 437, LossG: 0.7452                                  \n",
      "[Training] Epoch: 438 [DONE]                                 \n",
      "[Training] Epoch: 438, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 438, LossG: 0.7451                                  \n",
      "[Training] Epoch: 439 [DONE]                                 \n",
      "[Training] Epoch: 439, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 439, LossG: 0.7452                                  \n",
      "[Training] Epoch: 440 [DONE]                                 \n",
      "[Training] Epoch: 440, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 440, LossG: 0.7452                                  \n",
      "[Training] Epoch: 441 [DONE]                                 \n",
      "[Training] Epoch: 441, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 441, LossG: 0.7452                                  \n",
      "[Training] Epoch: 442 [DONE]                                 \n",
      "[Training] Epoch: 442, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 442, LossG: 0.7452                                  \n",
      "[Training] Epoch: 443 [DONE]                                 \n",
      "[Training] Epoch: 443, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 443, LossG: 0.7452                                  \n",
      "[Training] Epoch: 444 [DONE]                                 \n",
      "[Training] Epoch: 444, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 444, LossG: 0.7452                                  \n",
      "[Training] Epoch: 445 [DONE]                                 \n",
      "[Training] Epoch: 445, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 445, LossG: 0.7452                                  \n",
      "[Training] Epoch: 446 [DONE]                                 \n",
      "[Training] Epoch: 446, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 446, LossG: 0.7452                                  \n",
      "Epoch: 446\n",
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      " Model loaded: ./models/Test_Model/446_Epoch\n",
      "Total params: 1,769,492\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 0.7453===================================================================] 100.0%\n",
      "[Validation] Epoch: 0, LossG: 0.7453                                      \n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 0.7453===================================================================] 100.0%\n",
      "[Validation] Epoch: 1, LossG: 0.7453                                      \n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 0.7453===================================================================] 100.0%\n",
      "[Validation] Epoch: 2, LossG: 0.7453                                      \n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 0.7453===================================================================] 100.0%\n",
      "[Validation] Epoch: 3, LossG: 0.7453                                      \n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 4, LossG: 0.7454                                      \n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 0.7452===================================================================] 100.0%\n",
      "[Validation] Epoch: 5, LossG: 0.7452                                      \n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 0.7452===================================================================] 100.0%\n",
      "[Validation] Epoch: 6, LossG: 0.7452                                      \n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 0.7454===================================================================] 100.0%\n",
      "[Validation] Epoch: 7, LossG: 0.7454                                      \n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 0.7452===================================================================] 100.0%\n",
      "[Validation] Epoch: 8, LossG: 0.7452                                      \n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 0.7452===================================================================] 100.0%\n",
      "[Validation] Epoch: 9, LossG: 0.7452                                      \n",
      "[Training] Epoch: 10 [DONE]                                 \n",
      "[Training] Epoch: 10, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 10, LossG: 0.7452                                    \n",
      "[Training] Epoch: 11 [DONE]                                 \n",
      "[Training] Epoch: 11, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 11, LossG: 0.7453                                    \n",
      "[Training] Epoch: 12 [DONE]                                 \n",
      "[Training] Epoch: 12, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 12, LossG: 0.7453                                    \n",
      "[Training] Epoch: 13 [DONE]                                 \n",
      "[Training] Epoch: 13, LossG: 0.7451==================================================================] 100.0%\n",
      "[Validation] Epoch: 13, LossG: 0.7451                                    \n",
      "[Training] Epoch: 14 [DONE]                                 \n",
      "[Training] Epoch: 14, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 14, LossG: 0.7452                                    \n",
      "[Training] Epoch: 15 [DONE]                                 \n",
      "[Training] Epoch: 15, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 15, LossG: 0.7452                                    \n",
      "[Training] Epoch: 16 [DONE]                                 \n",
      "[Training] Epoch: 16, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 16, LossG: 0.7452                                    \n",
      "[Training] Epoch: 17 [DONE]                                 \n",
      "[Training] Epoch: 17, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 17, LossG: 0.7453                                    \n",
      "[Training] Epoch: 18 [DONE]                                 \n",
      "[Training] Epoch: 18, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 18, LossG: 0.7452                                    \n",
      "[Training] Epoch: 19 [DONE]                                 \n",
      "[Training] Epoch: 19, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 19, LossG: 0.7452                                    \n",
      "[Training] Epoch: 20 [DONE]                                 \n",
      "[Training] Epoch: 20, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 20, LossG: 0.7452                                    \n",
      "[Training] Epoch: 21 [DONE]                                 \n",
      "[Training] Epoch: 21, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 21, LossG: 0.7453                                    \n",
      "[Training] Epoch: 22 [DONE]                                 \n",
      "[Training] Epoch: 22, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 22, LossG: 0.7452                                    \n",
      "[Training] Epoch: 23 [DONE]                                 \n",
      "[Training] Epoch: 23, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 23, LossG: 0.7452                                    \n",
      "[Training] Epoch: 24 [DONE]                                 \n",
      "[Training] Epoch: 24, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 24, LossG: 0.7452                                    \n",
      "[Training] Epoch: 25 [DONE]                                 \n",
      "[Training] Epoch: 25, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 25, LossG: 0.7453                                    \n",
      "[Training] Epoch: 26 [DONE]                                 \n",
      "[Training] Epoch: 26, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 26, LossG: 0.7453                                    \n",
      "[Training] Epoch: 27 [DONE]                                 \n",
      "[Training] Epoch: 27, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 27, LossG: 0.7453                                    \n",
      "[Training] Epoch: 28 [DONE]                                 \n",
      "[Training] Epoch: 28, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 28, LossG: 0.7453                                    \n",
      "[Training] Epoch: 29 [DONE]                                 \n",
      "[Training] Epoch: 29, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 29, LossG: 0.7452                                    \n",
      "[Training] Epoch: 30 [DONE]                                 \n",
      "[Training] Epoch: 30, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 30, LossG: 0.7452                                    \n",
      "[Training] Epoch: 31 [DONE]                                 \n",
      "[Training] Epoch: 31, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 31, LossG: 0.7452                                    \n",
      "[Training] Epoch: 32 [DONE]                                 \n",
      "[Training] Epoch: 32, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 32, LossG: 0.7452                                    \n",
      "[Training] Epoch: 33 [DONE]                                 \n",
      "[Training] Epoch: 33, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 33, LossG: 0.7452                                    \n",
      "[Training] Epoch: 34 [DONE]                                 \n",
      "[Training] Epoch: 34, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 34, LossG: 0.7452                                    \n",
      "[Training] Epoch: 35 [DONE]                                 \n",
      "[Training] Epoch: 35, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 35, LossG: 0.7452                                    \n",
      "[Training] Epoch: 36 [DONE]                                 \n",
      "[Training] Epoch: 36, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 36, LossG: 0.7453                                    \n",
      "[Training] Epoch: 37 [DONE]                                 \n",
      "[Training] Epoch: 37, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 37, LossG: 0.7452                                    \n",
      "[Training] Epoch: 38 [DONE]                                 \n",
      "[Training] Epoch: 38, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 38, LossG: 0.7452                                    \n",
      "[Training] Epoch: 39 [DONE]                                 \n",
      "[Training] Epoch: 39, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 39, LossG: 0.7452                                    \n",
      "[Training] Epoch: 40 [DONE]                                 \n",
      "[Training] Epoch: 40, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 40, LossG: 0.7452                                    \n",
      "[Training] Epoch: 41 [DONE]                                 \n",
      "[Training] Epoch: 41, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 41, LossG: 0.7452                                    \n",
      "[Training] Epoch: 42 [DONE]                                 \n",
      "[Training] Epoch: 42, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 42, LossG: 0.7452                                    \n",
      "[Training] Epoch: 43 [DONE]                                 \n",
      "[Training] Epoch: 43, LossG: 0.7451==================================================================] 100.0%\n",
      "[Validation] Epoch: 43, LossG: 0.7451                                    \n",
      "[Training] Epoch: 44 [DONE]                                 \n",
      "[Training] Epoch: 44, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 44, LossG: 0.7452                                    \n",
      "[Training] Epoch: 45 [DONE]                                 \n",
      "[Training] Epoch: 45, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 45, LossG: 0.7453                                    \n",
      "[Training] Epoch: 46 [DONE]                                 \n",
      "[Training] Epoch: 46, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 46, LossG: 0.7453                                    \n",
      "[Training] Epoch: 47 [DONE]                                 \n",
      "[Training] Epoch: 47, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 47, LossG: 0.7453                                    \n",
      "[Training] Epoch: 48 [DONE]                                 \n",
      "[Training] Epoch: 48, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 48, LossG: 0.7452                                    \n",
      "[Training] Epoch: 49 [DONE]                                 \n",
      "[Training] Epoch: 49, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 49, LossG: 0.7453                                    \n",
      "[Training] Epoch: 50 [DONE]                                 \n",
      "[Training] Epoch: 50, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 50, LossG: 0.7453                                    \n",
      "[Training] Epoch: 51 [DONE]                                 \n",
      "[Training] Epoch: 51, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 51, LossG: 0.7452                                    \n",
      "[Training] Epoch: 52 [DONE]                                 \n",
      "[Training] Epoch: 52, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 52, LossG: 0.7452                                    \n",
      "[Training] Epoch: 53 [DONE]                                 \n",
      "[Training] Epoch: 53, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 53, LossG: 0.7452                                    \n",
      "[Training] Epoch: 54 [DONE]                                 \n",
      "[Training] Epoch: 54, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 54, LossG: 0.7452                                    \n",
      "[Training] Epoch: 55 [DONE]                                 \n",
      "[Training] Epoch: 55, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 55, LossG: 0.7452                                    \n",
      "[Training] Epoch: 56 [DONE]                                 \n",
      "[Training] Epoch: 56, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 56, LossG: 0.7453                                    \n",
      "[Training] Epoch: 57 [DONE]                                 \n",
      "[Training] Epoch: 57, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 57, LossG: 0.7452                                    \n",
      "[Training] Epoch: 58 [DONE]                                 \n",
      "[Training] Epoch: 58, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 58, LossG: 0.7453                                    \n",
      "[Training] Epoch: 59 [DONE]                                 \n",
      "[Training] Epoch: 59, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 59, LossG: 0.7452                                    \n",
      "[Training] Epoch: 60 [DONE]                                 \n",
      "[Training] Epoch: 60, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 60, LossG: 0.7452                                    \n",
      "[Training] Epoch: 61 [DONE]                                 \n",
      "[Training] Epoch: 61, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 61, LossG: 0.7452                                    \n",
      "[Training] Epoch: 62 [DONE]                                 \n",
      "[Training] Epoch: 62, LossG: 0.7451==================================================================] 100.0%\n",
      "[Validation] Epoch: 62, LossG: 0.7451                                    \n",
      "[Training] Epoch: 63 [DONE]                                 \n",
      "[Training] Epoch: 63, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 63, LossG: 0.7453                                    \n",
      "[Training] Epoch: 64 [DONE]                                 \n",
      "[Training] Epoch: 64, LossG: 0.7451==================================================================] 100.0%\n",
      "[Validation] Epoch: 64, LossG: 0.7451                                    \n",
      "[Training] Epoch: 65 [DONE]                                 \n",
      "[Training] Epoch: 65, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 65, LossG: 0.7452                                    \n",
      "[Training] Epoch: 66 [DONE]                                 \n",
      "[Training] Epoch: 66, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 66, LossG: 0.7453                                    \n",
      "[Training] Epoch: 67 [DONE]                                 \n",
      "[Training] Epoch: 67, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 67, LossG: 0.7453                                    \n",
      "[Training] Epoch: 68 [DONE]                                 \n",
      "[Training] Epoch: 68, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 68, LossG: 0.7453                                    \n",
      "[Training] Epoch: 69 [DONE]                                 \n",
      "[Training] Epoch: 69, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 69, LossG: 0.7452                                    \n",
      "[Training] Epoch: 70 [DONE]                                 \n",
      "[Training] Epoch: 70, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 70, LossG: 0.7452                                    \n",
      "[Training] Epoch: 71 [DONE]                                 \n",
      "[Training] Epoch: 71, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 71, LossG: 0.7452                                    \n",
      "[Training] Epoch: 72 [DONE]                                 \n",
      "[Training] Epoch: 72, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 72, LossG: 0.7452                                    \n",
      "[Training] Epoch: 73 [DONE]                                 \n",
      "[Training] Epoch: 73, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 73, LossG: 0.7452                                    \n",
      "[Training] Epoch: 74 [DONE]                                 \n",
      "[Training] Epoch: 74, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 74, LossG: 0.7452                                    \n",
      "[Training] Epoch: 75 [DONE]                                 \n",
      "[Training] Epoch: 75, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 75, LossG: 0.7452                                    \n",
      "[Training] Epoch: 76 [DONE]                                 \n",
      "[Training] Epoch: 76, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 76, LossG: 0.7452                                    \n",
      "[Training] Epoch: 77 [DONE]                                 \n",
      "[Training] Epoch: 77, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 77, LossG: 0.7452                                    \n",
      "[Training] Epoch: 78 [DONE]                                 \n",
      "[Training] Epoch: 78, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 78, LossG: 0.7453                                    \n",
      "[Training] Epoch: 79 [DONE]                                 \n",
      "[Training] Epoch: 79, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 79, LossG: 0.7452                                    \n",
      "[Training] Epoch: 80 [DONE]                                 \n",
      "[Training] Epoch: 80, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 80, LossG: 0.7452                                    \n",
      "[Training] Epoch: 81 [DONE]                                 \n",
      "[Training] Epoch: 81, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 81, LossG: 0.7452                                    \n",
      "[Training] Epoch: 82 [DONE]                                 \n",
      "[Training] Epoch: 82, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 82, LossG: 0.7452                                    \n",
      "[Training] Epoch: 83 [DONE]                                 \n",
      "[Training] Epoch: 83, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 83, LossG: 0.7452                                    \n",
      "[Training] Epoch: 84 [DONE]                                 \n",
      "[Training] Epoch: 84, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 84, LossG: 0.7452                                    \n",
      "[Training] Epoch: 85 [DONE]                                 \n",
      "[Training] Epoch: 85, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 85, LossG: 0.7452                                    \n",
      "[Training] Epoch: 86 [DONE]                                 \n",
      "[Training] Epoch: 86, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 86, LossG: 0.7452                                    \n",
      "[Training] Epoch: 87 [DONE]                                 \n",
      "[Training] Epoch: 87, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 87, LossG: 0.7452                                    \n",
      "[Training] Epoch: 88 [DONE]                                 \n",
      "[Training] Epoch: 88, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 88, LossG: 0.7452                                    \n",
      "[Training] Epoch: 89 [DONE]                                 \n",
      "[Training] Epoch: 89, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 89, LossG: 0.7452                                    \n",
      "[Training] Epoch: 90 [DONE]                                 \n",
      "[Training] Epoch: 90, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 90, LossG: 0.7452                                    \n",
      "[Training] Epoch: 91 [DONE]                                 \n",
      "[Training] Epoch: 91, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 91, LossG: 0.7452                                    \n",
      "[Training] Epoch: 92 [DONE]                                 \n",
      "[Training] Epoch: 92, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 92, LossG: 0.7452                                    \n",
      "[Training] Epoch: 93 [DONE]                                 \n",
      "[Training] Epoch: 93, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 93, LossG: 0.7452                                    \n",
      "[Training] Epoch: 94 [DONE]                                 \n",
      "[Training] Epoch: 94, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 94, LossG: 0.7452                                    \n",
      "[Training] Epoch: 95 [DONE]                                 \n",
      "[Training] Epoch: 95, LossG: 0.7453==================================================================] 100.0%\n",
      "[Validation] Epoch: 95, LossG: 0.7453                                    \n",
      "[Training] Epoch: 96 [DONE]                                 \n",
      "[Training] Epoch: 96, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 96, LossG: 0.7452                                    \n",
      "[Training] Epoch: 97 [DONE]                                 \n",
      "[Training] Epoch: 97, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 97, LossG: 0.7452                                    \n",
      "[Training] Epoch: 98 [DONE]                                 \n",
      "[Training] Epoch: 98, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 98, LossG: 0.7452                                    \n",
      "[Training] Epoch: 99 [DONE]                                 \n",
      "[Training] Epoch: 99, LossG: 0.7452==================================================================] 100.0%\n",
      "[Validation] Epoch: 99, LossG: 0.7452                                    \n",
      "[Training] Epoch: 100 [DONE]                                 \n",
      "[Training] Epoch: 100, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 100, LossG: 0.7452                                  \n",
      "[Training] Epoch: 101 [DONE]                                 \n",
      "[Training] Epoch: 101, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 101, LossG: 0.7452                                  \n",
      "[Training] Epoch: 102 [DONE]                                 \n",
      "[Training] Epoch: 102, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 102, LossG: 0.7452                                  \n",
      "[Training] Epoch: 103 [DONE]                                 \n",
      "[Training] Epoch: 103, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 103, LossG: 0.7452                                  \n",
      "[Training] Epoch: 104 [DONE]                                 \n",
      "[Training] Epoch: 104, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 104, LossG: 0.7453                                  \n",
      "[Training] Epoch: 105 [DONE]                                 \n",
      "[Training] Epoch: 105, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 105, LossG: 0.7452                                  \n",
      "[Training] Epoch: 106 [DONE]                                 \n",
      "[Training] Epoch: 106, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 106, LossG: 0.7451                                  \n",
      "[Training] Epoch: 107 [DONE]                                 \n",
      "[Training] Epoch: 107, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 107, LossG: 0.7452                                  \n",
      "[Training] Epoch: 108 [DONE]                                 \n",
      "[Training] Epoch: 108, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 108, LossG: 0.7452                                  \n",
      "[Training] Epoch: 109 [DONE]                                 \n",
      "[Training] Epoch: 109, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 109, LossG: 0.7452                                  \n",
      "[Training] Epoch: 110 [DONE]                                 \n",
      "[Training] Epoch: 110, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 110, LossG: 0.7452                                  \n",
      "[Training] Epoch: 111 [DONE]                                 \n",
      "[Training] Epoch: 111, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 111, LossG: 0.7452                                  \n",
      "[Training] Epoch: 112 [DONE]                                 \n",
      "[Training] Epoch: 112, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 112, LossG: 0.7452                                  \n",
      "[Training] Epoch: 113 [DONE]                                 \n",
      "[Training] Epoch: 113, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 113, LossG: 0.7452                                  \n",
      "[Training] Epoch: 114 [DONE]                                 \n",
      "[Training] Epoch: 114, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 114, LossG: 0.7451                                  \n",
      "[Training] Epoch: 115 [DONE]                                 \n",
      "[Training] Epoch: 115, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 115, LossG: 0.7452                                  \n",
      "[Training] Epoch: 116 [DONE]                                 \n",
      "[Training] Epoch: 116, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 116, LossG: 0.7452                                  \n",
      "[Training] Epoch: 117 [DONE]                                 \n",
      "[Training] Epoch: 117, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 117, LossG: 0.7452                                  \n",
      "[Training] Epoch: 118 [DONE]                                 \n",
      "[Training] Epoch: 118, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 118, LossG: 0.7452                                  \n",
      "[Training] Epoch: 119 [DONE]                                 \n",
      "[Training] Epoch: 119, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 119, LossG: 0.7452                                  \n",
      "[Training] Epoch: 120 [DONE]                                 \n",
      "[Training] Epoch: 120, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 120, LossG: 0.7452                                  \n",
      "[Training] Epoch: 121 [DONE]                                 \n",
      "[Training] Epoch: 121, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 121, LossG: 0.7452                                  \n",
      "[Training] Epoch: 122 [DONE]                                 \n",
      "[Training] Epoch: 122, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 122, LossG: 0.7451                                  \n",
      "[Training] Epoch: 123 [DONE]                                 \n",
      "[Training] Epoch: 123, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 123, LossG: 0.7452                                  \n",
      "[Training] Epoch: 124 [DONE]                                 \n",
      "[Training] Epoch: 124, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 124, LossG: 0.7452                                  \n",
      "[Training] Epoch: 125 [DONE]                                 \n",
      "[Training] Epoch: 125, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 125, LossG: 0.7452                                  \n",
      "[Training] Epoch: 126 [DONE]                                 \n",
      "[Training] Epoch: 126, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 126, LossG: 0.7452                                  \n",
      "[Training] Epoch: 127 [DONE]                                 \n",
      "[Training] Epoch: 127, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 127, LossG: 0.7452                                  \n",
      "[Training] Epoch: 128 [DONE]                                 \n",
      "[Training] Epoch: 128, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 128, LossG: 0.7452                                  \n",
      "[Training] Epoch: 129 [DONE]                                 \n",
      "[Training] Epoch: 129, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 129, LossG: 0.7452                                  \n",
      "[Training] Epoch: 130 [DONE]                                 \n",
      "[Training] Epoch: 130, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 130, LossG: 0.7452                                  \n",
      "[Training] Epoch: 131 [DONE]                                 \n",
      "[Training] Epoch: 131, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 131, LossG: 0.7452                                  \n",
      "[Training] Epoch: 132 [DONE]                                 \n",
      "[Training] Epoch: 132, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 132, LossG: 0.7452                                  \n",
      "[Training] Epoch: 133 [DONE]                                 \n",
      "[Training] Epoch: 133, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 133, LossG: 0.7451                                  \n",
      "[Training] Epoch: 134 [DONE]                                 \n",
      "[Training] Epoch: 134, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 134, LossG: 0.7451                                  \n",
      "[Training] Epoch: 135 [DONE]                                 \n",
      "[Training] Epoch: 135, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 135, LossG: 0.7452                                  \n",
      "[Training] Epoch: 136 [DONE]                                 \n",
      "[Training] Epoch: 136, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 136, LossG: 0.7452                                  \n",
      "[Training] Epoch: 137 [DONE]                                 \n",
      "[Training] Epoch: 137, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 137, LossG: 0.7452                                  \n",
      "[Training] Epoch: 138 [DONE]                                 \n",
      "[Training] Epoch: 138, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 138, LossG: 0.7451                                  \n",
      "[Training] Epoch: 139 [DONE]                                 \n",
      "[Training] Epoch: 139, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 139, LossG: 0.7452                                  \n",
      "[Training] Epoch: 140 [DONE]                                 \n",
      "[Training] Epoch: 140, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 140, LossG: 0.7451                                  \n",
      "[Training] Epoch: 141 [DONE]                                 \n",
      "[Training] Epoch: 141, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 141, LossG: 0.7451                                  \n",
      "[Training] Epoch: 142 [DONE]                                 \n",
      "[Training] Epoch: 142, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 142, LossG: 0.7452                                  \n",
      "[Training] Epoch: 143 [DONE]                                 \n",
      "[Training] Epoch: 143, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 143, LossG: 0.7452                                  \n",
      "[Training] Epoch: 144 [DONE]                                 \n",
      "[Training] Epoch: 144, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 144, LossG: 0.7453                                  \n",
      "[Training] Epoch: 145 [DONE]                                 \n",
      "[Training] Epoch: 145, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 145, LossG: 0.7452                                  \n",
      "[Training] Epoch: 146 [DONE]                                 \n",
      "[Training] Epoch: 146, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 146, LossG: 0.7453                                  \n",
      "[Training] Epoch: 147 [DONE]                                 \n",
      "[Training] Epoch: 147, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 147, LossG: 0.7452                                  \n",
      "[Training] Epoch: 148 [DONE]                                 \n",
      "[Training] Epoch: 148, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 148, LossG: 0.7452                                  \n",
      "[Training] Epoch: 149 [DONE]                                 \n",
      "[Training] Epoch: 149, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 149, LossG: 0.7452                                  \n",
      "[Training] Epoch: 150 [DONE]                                 \n",
      "[Training] Epoch: 150, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 150, LossG: 0.7452                                  \n",
      "[Training] Epoch: 151 [DONE]                                 \n",
      "[Training] Epoch: 151, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 151, LossG: 0.7452                                  \n",
      "[Training] Epoch: 152 [DONE]                                 \n",
      "[Training] Epoch: 152, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 152, LossG: 0.7452                                  \n",
      "[Training] Epoch: 153 [DONE]                                 \n",
      "[Training] Epoch: 153, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 153, LossG: 0.7452                                  \n",
      "[Training] Epoch: 154 [DONE]                                 \n",
      "[Training] Epoch: 154, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 154, LossG: 0.7453                                  \n",
      "[Training] Epoch: 155 [DONE]                                 \n",
      "[Training] Epoch: 155, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 155, LossG: 0.7452                                  \n",
      "[Training] Epoch: 156 [DONE]                                 \n",
      "[Training] Epoch: 156, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 156, LossG: 0.7453                                  \n",
      "[Training] Epoch: 157 [DONE]                                 \n",
      "[Training] Epoch: 157, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 157, LossG: 0.7452                                  \n",
      "[Training] Epoch: 158 [DONE]                                 \n",
      "[Training] Epoch: 158, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 158, LossG: 0.7452                                  \n",
      "[Training] Epoch: 159 [DONE]                                 \n",
      "[Training] Epoch: 159, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 159, LossG: 0.7452                                  \n",
      "[Training] Epoch: 160 [DONE]                                 \n",
      "[Training] Epoch: 160, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 160, LossG: 0.7452                                  \n",
      "[Training] Epoch: 161 [DONE]                                 \n",
      "[Training] Epoch: 161, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 161, LossG: 0.7452                                  \n",
      "[Training] Epoch: 162 [DONE]                                 \n",
      "[Training] Epoch: 162, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 162, LossG: 0.7452                                  \n",
      "[Training] Epoch: 163 [DONE]                                 \n",
      "[Training] Epoch: 163, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 163, LossG: 0.7452                                  \n",
      "[Training] Epoch: 164 [DONE]                                 \n",
      "[Training] Epoch: 164, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 164, LossG: 0.7451                                  \n",
      "[Training] Epoch: 165 [DONE]                                 \n",
      "[Training] Epoch: 165, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 165, LossG: 0.7452                                  \n",
      "[Training] Epoch: 166 [DONE]                                 \n",
      "[Training] Epoch: 166, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 166, LossG: 0.7453                                  \n",
      "[Training] Epoch: 167 [DONE]                                 \n",
      "[Training] Epoch: 167, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 167, LossG: 0.7452                                  \n",
      "[Training] Epoch: 168 [DONE]                                 \n",
      "[Training] Epoch: 168, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 168, LossG: 0.7452                                  \n",
      "[Training] Epoch: 169 [DONE]                                 \n",
      "[Training] Epoch: 169, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 169, LossG: 0.7452                                  \n",
      "[Training] Epoch: 170 [DONE]                                 \n",
      "[Training] Epoch: 170, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 170, LossG: 0.7453                                  \n",
      "[Training] Epoch: 171 [DONE]                                 \n",
      "[Training] Epoch: 171, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 171, LossG: 0.7452                                  \n",
      "[Training] Epoch: 172 [DONE]                                 \n",
      "[Training] Epoch: 172, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 172, LossG: 0.7452                                  \n",
      "[Training] Epoch: 173 [DONE]                                 \n",
      "[Training] Epoch: 173, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 173, LossG: 0.7451                                  \n",
      "[Training] Epoch: 174 [DONE]                                 \n",
      "[Training] Epoch: 174, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 174, LossG: 0.7452                                  \n",
      "[Training] Epoch: 175 [DONE]                                 \n",
      "[Training] Epoch: 175, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 175, LossG: 0.7452                                  \n",
      "[Training] Epoch: 176 [DONE]                                 \n",
      "[Training] Epoch: 176, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 176, LossG: 0.7452                                  \n",
      "[Training] Epoch: 177 [DONE]                                 \n",
      "[Training] Epoch: 177, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 177, LossG: 0.7452                                  \n",
      "[Training] Epoch: 178 [DONE]                                 \n",
      "[Training] Epoch: 178, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 178, LossG: 0.7452                                  \n",
      "[Training] Epoch: 179 [DONE]                                 \n",
      "[Training] Epoch: 179, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 179, LossG: 0.7452                                  \n",
      "[Training] Epoch: 180 [DONE]                                 \n",
      "[Training] Epoch: 180, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 180, LossG: 0.7451                                  \n",
      "[Training] Epoch: 181 [DONE]                                 \n",
      "[Training] Epoch: 181, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 181, LossG: 0.7452                                  \n",
      "[Training] Epoch: 182 [DONE]                                 \n",
      "[Training] Epoch: 182, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 182, LossG: 0.7451                                  \n",
      "[Training] Epoch: 183 [DONE]                                 \n",
      "[Training] Epoch: 183, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 183, LossG: 0.7452                                  \n",
      "[Training] Epoch: 184 [DONE]                                 \n",
      "[Training] Epoch: 184, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 184, LossG: 0.7451                                  \n",
      "[Training] Epoch: 185 [DONE]                                 \n",
      "[Training] Epoch: 185, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 185, LossG: 0.7452                                  \n",
      "[Training] Epoch: 186 [DONE]                                 \n",
      "[Training] Epoch: 186, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 186, LossG: 0.7451                                  \n",
      "[Training] Epoch: 187 [DONE]                                 \n",
      "[Training] Epoch: 187, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 187, LossG: 0.7451                                  \n",
      "[Training] Epoch: 188 [DONE]                                 \n",
      "[Training] Epoch: 188, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 188, LossG: 0.7452                                  \n",
      "[Training] Epoch: 189 [DONE]                                 \n",
      "[Training] Epoch: 189, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 189, LossG: 0.7452                                  \n",
      "[Training] Epoch: 190 [DONE]                                 \n",
      "[Training] Epoch: 190, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 190, LossG: 0.7452                                  \n",
      "[Training] Epoch: 191 [DONE]                                 \n",
      "[Training] Epoch: 191, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 191, LossG: 0.7452                                  \n",
      "[Training] Epoch: 192 [DONE]                                 \n",
      "[Training] Epoch: 192, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 192, LossG: 0.7452                                  \n",
      "[Training] Epoch: 193 [DONE]                                 \n",
      "[Training] Epoch: 193, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 193, LossG: 0.7452                                  \n",
      "[Training] Epoch: 194 [DONE]                                 \n",
      "[Training] Epoch: 194, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 194, LossG: 0.7452                                  \n",
      "[Training] Epoch: 195 [DONE]                                 \n",
      "[Training] Epoch: 195, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 195, LossG: 0.7452                                  \n",
      "[Training] Epoch: 196 [DONE]                                 \n",
      "[Training] Epoch: 196, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 196, LossG: 0.7452                                  \n",
      "[Training] Epoch: 197 [DONE]                                 \n",
      "[Training] Epoch: 197, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 197, LossG: 0.7452                                  \n",
      "[Training] Epoch: 198 [DONE]                                 \n",
      "[Training] Epoch: 198, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 198, LossG: 0.7452                                  \n",
      "[Training] Epoch: 199 [DONE]                                 \n",
      "[Training] Epoch: 199, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 199, LossG: 0.7451                                  \n",
      "[Training] Epoch: 200 [DONE]                                 \n",
      "[Training] Epoch: 200, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 200, LossG: 0.7452                                  \n",
      "[Training] Epoch: 201 [DONE]                                 \n",
      "[Training] Epoch: 201, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 201, LossG: 0.7452                                  \n",
      "[Training] Epoch: 202 [DONE]                                 \n",
      "[Training] Epoch: 202, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 202, LossG: 0.7451                                  \n",
      "[Training] Epoch: 203 [DONE]                                 \n",
      "[Training] Epoch: 203, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 203, LossG: 0.7452                                  \n",
      "[Training] Epoch: 204 [DONE]                                 \n",
      "[Training] Epoch: 204, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 204, LossG: 0.7452                                  \n",
      "[Training] Epoch: 205 [DONE]                                 \n",
      "[Training] Epoch: 205, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 205, LossG: 0.7451                                  \n",
      "[Training] Epoch: 206 [DONE]                                 \n",
      "[Training] Epoch: 206, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 206, LossG: 0.7452                                  \n",
      "[Training] Epoch: 207 [DONE]                                 \n",
      "[Training] Epoch: 207, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 207, LossG: 0.7452                                  \n",
      "[Training] Epoch: 208 [DONE]                                 \n",
      "[Training] Epoch: 208, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 208, LossG: 0.7452                                  \n",
      "[Training] Epoch: 209 [DONE]                                 \n",
      "[Training] Epoch: 209, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 209, LossG: 0.7452                                  \n",
      "[Training] Epoch: 210 [DONE]                                 \n",
      "[Training] Epoch: 210, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 210, LossG: 0.7452                                  \n",
      "[Training] Epoch: 211 [DONE]                                 \n",
      "[Training] Epoch: 211, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 211, LossG: 0.7451                                  \n",
      "[Training] Epoch: 212 [DONE]                                 \n",
      "[Training] Epoch: 212, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 212, LossG: 0.7452                                  \n",
      "[Training] Epoch: 213 [DONE]                                 \n",
      "[Training] Epoch: 213, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 213, LossG: 0.7452                                  \n",
      "[Training] Epoch: 214 [DONE]                                 \n",
      "[Training] Epoch: 214, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 214, LossG: 0.7452                                  \n",
      "[Training] Epoch: 215 [DONE]                                 \n",
      "[Training] Epoch: 215, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 215, LossG: 0.7452                                  \n",
      "[Training] Epoch: 216 [DONE]                                 \n",
      "[Training] Epoch: 216, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 216, LossG: 0.7452                                  \n",
      "[Training] Epoch: 217 [DONE]                                 \n",
      "[Training] Epoch: 217, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 217, LossG: 0.7452                                  \n",
      "[Training] Epoch: 218 [DONE]                                 \n",
      "[Training] Epoch: 218, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 218, LossG: 0.7452                                  \n",
      "[Training] Epoch: 219 [DONE]                                 \n",
      "[Training] Epoch: 219, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 219, LossG: 0.7452                                  \n",
      "[Training] Epoch: 220 [DONE]                                 \n",
      "[Training] Epoch: 220, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 220, LossG: 0.7451                                  \n",
      "[Training] Epoch: 221 [DONE]                                 \n",
      "[Training] Epoch: 221, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 221, LossG: 0.7452                                  \n",
      "[Training] Epoch: 222 [DONE]                                 \n",
      "[Training] Epoch: 222, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 222, LossG: 0.7451                                  \n",
      "[Training] Epoch: 223 [DONE]                                 \n",
      "[Training] Epoch: 223, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 223, LossG: 0.7452                                  \n",
      "[Training] Epoch: 224 [DONE]                                 \n",
      "[Training] Epoch: 224, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 224, LossG: 0.7452                                  \n",
      "[Training] Epoch: 225 [DONE]                                 \n",
      "[Training] Epoch: 225, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 225, LossG: 0.7451                                  \n",
      "[Training] Epoch: 226 [DONE]                                 \n",
      "[Training] Epoch: 226, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 226, LossG: 0.7452                                  \n",
      "[Training] Epoch: 227 [DONE]                                 \n",
      "[Training] Epoch: 227, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 227, LossG: 0.7451                                  \n",
      "[Training] Epoch: 228 [DONE]                                 \n",
      "[Training] Epoch: 228, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 228, LossG: 0.7452                                  \n",
      "[Training] Epoch: 229 [DONE]                                 \n",
      "[Training] Epoch: 229, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 229, LossG: 0.7452                                  \n",
      "[Training] Epoch: 230 [DONE]                                 \n",
      "[Training] Epoch: 230, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 230, LossG: 0.7452                                  \n",
      "[Training] Epoch: 231 [DONE]                                 \n",
      "[Training] Epoch: 231, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 231, LossG: 0.7451                                  \n",
      "[Training] Epoch: 232 [DONE]                                 \n",
      "[Training] Epoch: 232, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 232, LossG: 0.7452                                  \n",
      "[Training] Epoch: 233 [DONE]                                 \n",
      "[Training] Epoch: 233, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 233, LossG: 0.7452                                  \n",
      "[Training] Epoch: 234 [DONE]                                 \n",
      "[Training] Epoch: 234, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 234, LossG: 0.7452                                  \n",
      "[Training] Epoch: 235 [DONE]                                 \n",
      "[Training] Epoch: 235, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 235, LossG: 0.7452                                  \n",
      "[Training] Epoch: 236 [DONE]                                 \n",
      "[Training] Epoch: 236, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 236, LossG: 0.7451                                  \n",
      "[Training] Epoch: 237 [DONE]                                 \n",
      "[Training] Epoch: 237, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 237, LossG: 0.7451                                  \n",
      "[Training] Epoch: 238 [DONE]                                 \n",
      "[Training] Epoch: 238, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 238, LossG: 0.7452                                  \n",
      "[Training] Epoch: 239 [DONE]                                 \n",
      "[Training] Epoch: 239, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 239, LossG: 0.7451                                  \n",
      "[Training] Epoch: 240 [DONE]                                 \n",
      "[Training] Epoch: 240, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 240, LossG: 0.7452                                  \n",
      "[Training] Epoch: 241 [DONE]                                 \n",
      "[Training] Epoch: 241, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 241, LossG: 0.7451                                  \n",
      "[Training] Epoch: 242 [DONE]                                 \n",
      "[Training] Epoch: 242, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 242, LossG: 0.7452                                  \n",
      "[Training] Epoch: 243 [DONE]                                 \n",
      "[Training] Epoch: 243, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 243, LossG: 0.7452                                  \n",
      "[Training] Epoch: 244 [DONE]                                 \n",
      "[Training] Epoch: 244, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 244, LossG: 0.7452                                  \n",
      "[Training] Epoch: 245 [DONE]                                 \n",
      "[Training] Epoch: 245, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 245, LossG: 0.7452                                  \n",
      "[Training] Epoch: 246 [DONE]                                 \n",
      "[Training] Epoch: 246, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 246, LossG: 0.7451                                  \n",
      "[Training] Epoch: 247 [DONE]                                 \n",
      "[Training] Epoch: 247, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 247, LossG: 0.7452                                  \n",
      "[Training] Epoch: 248 [DONE]                                 \n",
      "[Training] Epoch: 248, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 248, LossG: 0.7452                                  \n",
      "[Training] Epoch: 249 [DONE]                                 \n",
      "[Training] Epoch: 249, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 249, LossG: 0.7451                                  \n",
      "[Training] Epoch: 250 [DONE]                                 \n",
      "[Training] Epoch: 250, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 250, LossG: 0.7452                                  \n",
      "[Training] Epoch: 251 [DONE]                                 \n",
      "[Training] Epoch: 251, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 251, LossG: 0.7452                                  \n",
      "[Training] Epoch: 252 [DONE]                                 \n",
      "[Training] Epoch: 252, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 252, LossG: 0.7452                                  \n",
      "[Training] Epoch: 253 [DONE]                                 \n",
      "[Training] Epoch: 253, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 253, LossG: 0.7453                                  \n",
      "[Training] Epoch: 254 [DONE]                                 \n",
      "[Training] Epoch: 254, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 254, LossG: 0.7452                                  \n",
      "[Training] Epoch: 255 [DONE]                                 \n",
      "[Training] Epoch: 255, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 255, LossG: 0.7452                                  \n",
      "[Training] Epoch: 256 [DONE]                                 \n",
      "[Training] Epoch: 256, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 256, LossG: 0.7451                                  \n",
      "[Training] Epoch: 257 [DONE]                                 \n",
      "[Training] Epoch: 257, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 257, LossG: 0.7451                                  \n",
      "[Training] Epoch: 258 [DONE]                                 \n",
      "[Training] Epoch: 258, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 258, LossG: 0.7452                                  \n",
      "[Training] Epoch: 259 [DONE]                                 \n",
      "[Training] Epoch: 259, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 259, LossG: 0.7452                                  \n",
      "[Training] Epoch: 260 [DONE]                                 \n",
      "[Training] Epoch: 260, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 260, LossG: 0.7452                                  \n",
      "[Training] Epoch: 261 [DONE]                                 \n",
      "[Training] Epoch: 261, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 261, LossG: 0.7452                                  \n",
      "[Training] Epoch: 262 [DONE]                                 \n",
      "[Training] Epoch: 262, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 262, LossG: 0.7452                                  \n",
      "[Training] Epoch: 263 [DONE]                                 \n",
      "[Training] Epoch: 263, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 263, LossG: 0.7452                                  \n",
      "[Training] Epoch: 264 [DONE]                                 \n",
      "[Training] Epoch: 264, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 264, LossG: 0.7451                                  \n",
      "[Training] Epoch: 265 [DONE]                                 \n",
      "[Training] Epoch: 265, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 265, LossG: 0.7452                                  \n",
      "[Training] Epoch: 266 [DONE]                                 \n",
      "[Training] Epoch: 266, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 266, LossG: 0.7451                                  \n",
      "[Training] Epoch: 267 [DONE]                                 \n",
      "[Training] Epoch: 267, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 267, LossG: 0.7452                                  \n",
      "[Training] Epoch: 268 [DONE]                                 \n",
      "[Training] Epoch: 268, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 268, LossG: 0.7452                                  \n",
      "[Training] Epoch: 269 [DONE]                                 \n",
      "[Training] Epoch: 269, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 269, LossG: 0.7452                                  \n",
      "[Training] Epoch: 270 [DONE]                                 \n",
      "[Training] Epoch: 270, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 270, LossG: 0.7452                                  \n",
      "[Training] Epoch: 271 [DONE]                                 \n",
      "[Training] Epoch: 271, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 271, LossG: 0.7452                                  \n",
      "[Training] Epoch: 272 [DONE]                                 \n",
      "[Training] Epoch: 272, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 272, LossG: 0.7452                                  \n",
      "[Training] Epoch: 273 [DONE]                                 \n",
      "[Training] Epoch: 273, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 273, LossG: 0.7453                                  \n",
      "[Training] Epoch: 274 [DONE]                                 \n",
      "[Training] Epoch: 274, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 274, LossG: 0.7453                                  \n",
      "[Training] Epoch: 275 [DONE]                                 \n",
      "[Training] Epoch: 275, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 275, LossG: 0.7453                                  \n",
      "[Training] Epoch: 276 [DONE]                                 \n",
      "[Training] Epoch: 276, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 276, LossG: 0.7452                                  \n",
      "[Training] Epoch: 277 [DONE]                                 \n",
      "[Training] Epoch: 277, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 277, LossG: 0.7452                                  \n",
      "[Training] Epoch: 278 [DONE]                                 \n",
      "[Training] Epoch: 278, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 278, LossG: 0.7452                                  \n",
      "[Training] Epoch: 279 [DONE]                                 \n",
      "[Training] Epoch: 279, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 279, LossG: 0.7452                                  \n",
      "[Training] Epoch: 280 [DONE]                                 \n",
      "[Training] Epoch: 280, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 280, LossG: 0.7452                                  \n",
      "[Training] Epoch: 281 [DONE]                                 \n",
      "[Training] Epoch: 281, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 281, LossG: 0.7453                                  \n",
      "[Training] Epoch: 282 [DONE]                                 \n",
      "[Training] Epoch: 282, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 282, LossG: 0.7452                                  \n",
      "[Training] Epoch: 283 [DONE]                                 \n",
      "[Training] Epoch: 283, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 283, LossG: 0.7452                                  \n",
      "[Training] Epoch: 284 [DONE]                                 \n",
      "[Training] Epoch: 284, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 284, LossG: 0.7451                                  \n",
      "[Training] Epoch: 285 [DONE]                                 \n",
      "[Training] Epoch: 285, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 285, LossG: 0.7453                                  \n",
      "[Training] Epoch: 286 [DONE]                                 \n",
      "[Training] Epoch: 286, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 286, LossG: 0.7452                                  \n",
      "[Training] Epoch: 287 [DONE]                                 \n",
      "[Training] Epoch: 287, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 287, LossG: 0.7452                                  \n",
      "[Training] Epoch: 288 [DONE]                                 \n",
      "[Training] Epoch: 288, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 288, LossG: 0.7452                                  \n",
      "[Training] Epoch: 289 [DONE]                                 \n",
      "[Training] Epoch: 289, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 289, LossG: 0.7452                                  \n",
      "[Training] Epoch: 290 [DONE]                                 \n",
      "[Training] Epoch: 290, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 290, LossG: 0.7453                                  \n",
      "[Training] Epoch: 291 [DONE]                                 \n",
      "[Training] Epoch: 291, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 291, LossG: 0.7453                                  \n",
      "[Training] Epoch: 292 [DONE]                                 \n",
      "[Training] Epoch: 292, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 292, LossG: 0.7452                                  \n",
      "[Training] Epoch: 293 [DONE]                                 \n",
      "[Training] Epoch: 293, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 293, LossG: 0.7452                                  \n",
      "[Training] Epoch: 294 [DONE]                                 \n",
      "[Training] Epoch: 294, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 294, LossG: 0.7453                                  \n",
      "[Training] Epoch: 295 [DONE]                                 \n",
      "[Training] Epoch: 295, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 295, LossG: 0.7453                                  \n",
      "[Training] Epoch: 296 [DONE]                                 \n",
      "[Training] Epoch: 296, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 296, LossG: 0.7453                                  \n",
      "[Training] Epoch: 297 [DONE]                                 \n",
      "[Training] Epoch: 297, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 297, LossG: 0.7454                                  \n",
      "[Training] Epoch: 298 [DONE]                                 \n",
      "[Training] Epoch: 298, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 298, LossG: 0.7455                                  \n",
      "[Training] Epoch: 299 [DONE]                                 \n",
      "[Training] Epoch: 299, LossG: 0.7460=================================================================] 100.0%\n",
      "[Validation] Epoch: 299, LossG: 0.7460                                  \n",
      "[Training] Epoch: 300 [DONE]                                 \n",
      "[Training] Epoch: 300, LossG: 0.7455=================================================================] 100.0%\n",
      "[Validation] Epoch: 300, LossG: 0.7455                                  \n",
      "[Training] Epoch: 301 [DONE]                                 \n",
      "[Training] Epoch: 301, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 301, LossG: 0.7454                                  \n",
      "[Training] Epoch: 302 [DONE]                                 \n",
      "[Training] Epoch: 302, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 302, LossG: 0.7454                                  \n",
      "[Training] Epoch: 303 [DONE]                                 \n",
      "[Training] Epoch: 303, LossG: 0.7454=================================================================] 100.0%\n",
      "[Validation] Epoch: 303, LossG: 0.7454                                  \n",
      "[Training] Epoch: 304 [DONE]                                 \n",
      "[Training] Epoch: 304, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 304, LossG: 0.7453                                  \n",
      "[Training] Epoch: 305 [DONE]                                 \n",
      "[Training] Epoch: 305, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 305, LossG: 0.7453                                  \n",
      "[Training] Epoch: 306 [DONE]                                 \n",
      "[Training] Epoch: 306, LossG: 0.7453=================================================================] 100.0%\n",
      "[Validation] Epoch: 306, LossG: 0.7453                                  \n",
      "[Training] Epoch: 307 [DONE]                                 \n",
      "[Training] Epoch: 307, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 307, LossG: 0.7452                                  \n",
      "[Training] Epoch: 308 [DONE]                                 \n",
      "[Training] Epoch: 308, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 308, LossG: 0.7452                                  \n",
      "[Training] Epoch: 309 [DONE]                                 \n",
      "[Training] Epoch: 309, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 309, LossG: 0.7452                                  \n",
      "[Training] Epoch: 310 [DONE]                                 \n",
      "[Training] Epoch: 310, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 310, LossG: 0.7452                                  \n",
      "[Training] Epoch: 311 [DONE]                                 \n",
      "[Training] Epoch: 311, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 311, LossG: 0.7452                                  \n",
      "[Training] Epoch: 312 [DONE]                                 \n",
      "[Training] Epoch: 312, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 312, LossG: 0.7452                                  \n",
      "[Training] Epoch: 313 [DONE]                                 \n",
      "[Training] Epoch: 313, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 313, LossG: 0.7452                                  \n",
      "[Training] Epoch: 314 [DONE]                                 \n",
      "[Training] Epoch: 314, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 314, LossG: 0.7452                                  \n",
      "[Training] Epoch: 315 [DONE]                                 \n",
      "[Training] Epoch: 315, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 315, LossG: 0.7452                                  \n",
      "[Training] Epoch: 316 [DONE]                                 \n",
      "[Training] Epoch: 316, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 316, LossG: 0.7451                                  \n",
      "[Training] Epoch: 317 [DONE]                                 \n",
      "[Training] Epoch: 317, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 317, LossG: 0.7451                                  \n",
      "[Training] Epoch: 318 [DONE]                                 \n",
      "[Training] Epoch: 318, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 318, LossG: 0.7451                                  \n",
      "[Training] Epoch: 319 [DONE]                                 \n",
      "[Training] Epoch: 319, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 319, LossG: 0.7452                                  \n",
      "[Training] Epoch: 320 [DONE]                                 \n",
      "[Training] Epoch: 320, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 320, LossG: 0.7451                                  \n",
      "[Training] Epoch: 321 [DONE]                                 \n",
      "[Training] Epoch: 321, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 321, LossG: 0.7452                                  \n",
      "[Training] Epoch: 322 [DONE]                                 \n",
      "[Training] Epoch: 322, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 322, LossG: 0.7452                                  \n",
      "[Training] Epoch: 323 [DONE]                                 \n",
      "[Training] Epoch: 323, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 323, LossG: 0.7452                                  \n",
      "[Training] Epoch: 324 [DONE]                                 \n",
      "[Training] Epoch: 324, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 324, LossG: 0.7452                                  \n",
      "[Training] Epoch: 325 [DONE]                                 \n",
      "[Training] Epoch: 325, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 325, LossG: 0.7452                                  \n",
      "[Training] Epoch: 326 [DONE]                                 \n",
      "[Training] Epoch: 326, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 326, LossG: 0.7451                                  \n",
      "[Training] Epoch: 327 [DONE]                                 \n",
      "[Training] Epoch: 327, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 327, LossG: 0.7451                                  \n",
      "[Training] Epoch: 328 [DONE]                                 \n",
      "[Training] Epoch: 328, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 328, LossG: 0.7451                                  \n",
      "[Training] Epoch: 329 [DONE]                                 \n",
      "[Training] Epoch: 329, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 329, LossG: 0.7451                                  \n",
      "[Training] Epoch: 330 [DONE]                                 \n",
      "[Training] Epoch: 330, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 330, LossG: 0.7451                                  \n",
      "[Training] Epoch: 331 [DONE]                                 \n",
      "[Training] Epoch: 331, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 331, LossG: 0.7452                                  \n",
      "[Training] Epoch: 332 [DONE]                                 \n",
      "[Training] Epoch: 332, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 332, LossG: 0.7452                                  \n",
      "[Training] Epoch: 333 [DONE]                                 \n",
      "[Training] Epoch: 333, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 333, LossG: 0.7451                                  \n",
      "[Training] Epoch: 334 [DONE]                                 \n",
      "[Training] Epoch: 334, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 334, LossG: 0.7451                                  \n",
      "[Training] Epoch: 335 [DONE]                                 \n",
      "[Training] Epoch: 335, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 335, LossG: 0.7451                                  \n",
      "[Training] Epoch: 336 [DONE]                                 \n",
      "[Training] Epoch: 336, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 336, LossG: 0.7452                                  \n",
      "[Training] Epoch: 337 [DONE]                                 \n",
      "[Training] Epoch: 337, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 337, LossG: 0.7451                                  \n",
      "[Training] Epoch: 338 [DONE]                                 \n",
      "[Training] Epoch: 338, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 338, LossG: 0.7452                                  \n",
      "[Training] Epoch: 339 [DONE]                                 \n",
      "[Training] Epoch: 339, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 339, LossG: 0.7452                                  \n",
      "[Training] Epoch: 340 [DONE]                                 \n",
      "[Training] Epoch: 340, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 340, LossG: 0.7451                                  \n",
      "[Training] Epoch: 341 [DONE]                                 \n",
      "[Training] Epoch: 341, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 341, LossG: 0.7452                                  \n",
      "[Training] Epoch: 342 [DONE]                                 \n",
      "[Training] Epoch: 342, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 342, LossG: 0.7452                                  \n",
      "[Training] Epoch: 343 [DONE]                                 \n",
      "[Training] Epoch: 343, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 343, LossG: 0.7452                                  \n",
      "[Training] Epoch: 344 [DONE]                                 \n",
      "[Training] Epoch: 344, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 344, LossG: 0.7452                                  \n",
      "[Training] Epoch: 345 [DONE]                                 \n",
      "[Training] Epoch: 345, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 345, LossG: 0.7451                                  \n",
      "[Training] Epoch: 346 [DONE]                                 \n",
      "[Training] Epoch: 346, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 346, LossG: 0.7451                                  \n",
      "[Training] Epoch: 347 [DONE]                                 \n",
      "[Training] Epoch: 347, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 347, LossG: 0.7452                                  \n",
      "[Training] Epoch: 348 [DONE]                                 \n",
      "[Training] Epoch: 348, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 348, LossG: 0.7452                                  \n",
      "[Training] Epoch: 349 [DONE]                                 \n",
      "[Training] Epoch: 349, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 349, LossG: 0.7451                                  \n",
      "[Training] Epoch: 350 [DONE]                                 \n",
      "[Training] Epoch: 350, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 350, LossG: 0.7452                                  \n",
      "[Training] Epoch: 351 [DONE]                                 \n",
      "[Training] Epoch: 351, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 351, LossG: 0.7451                                  \n",
      "[Training] Epoch: 352 [DONE]                                 \n",
      "[Training] Epoch: 352, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 352, LossG: 0.7452                                  \n",
      "[Training] Epoch: 353 [DONE]                                 \n",
      "[Training] Epoch: 353, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 353, LossG: 0.7451                                  \n",
      "[Training] Epoch: 354 [DONE]                                 \n",
      "[Training] Epoch: 354, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 354, LossG: 0.7451                                  \n",
      "[Training] Epoch: 355 [DONE]                                 \n",
      "[Training] Epoch: 355, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 355, LossG: 0.7452                                  \n",
      "[Training] Epoch: 356 [DONE]                                 \n",
      "[Training] Epoch: 356, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 356, LossG: 0.7451                                  \n",
      "[Training] Epoch: 357 [DONE]                                 \n",
      "[Training] Epoch: 357, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 357, LossG: 0.7451                                  \n",
      "[Training] Epoch: 358 [DONE]                                 \n",
      "[Training] Epoch: 358, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 358, LossG: 0.7452                                  \n",
      "[Training] Epoch: 359 [DONE]                                 \n",
      "[Training] Epoch: 359, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 359, LossG: 0.7452                                  \n",
      "[Training] Epoch: 360 [DONE]                                 \n",
      "[Training] Epoch: 360, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 360, LossG: 0.7451                                  \n",
      "[Training] Epoch: 361 [DONE]                                 \n",
      "[Training] Epoch: 361, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 361, LossG: 0.7451                                  \n",
      "[Training] Epoch: 362 [DONE]                                 \n",
      "[Training] Epoch: 362, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 362, LossG: 0.7452                                  \n",
      "[Training] Epoch: 363 [DONE]                                 \n",
      "[Training] Epoch: 363, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 363, LossG: 0.7451                                  \n",
      "[Training] Epoch: 364 [DONE]                                 \n",
      "[Training] Epoch: 364, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 364, LossG: 0.7452                                  \n",
      "[Training] Epoch: 365 [DONE]                                 \n",
      "[Training] Epoch: 365, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 365, LossG: 0.7451                                  \n",
      "[Training] Epoch: 366 [DONE]                                 \n",
      "[Training] Epoch: 366, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 366, LossG: 0.7451                                  \n",
      "[Training] Epoch: 367 [DONE]                                 \n",
      "[Training] Epoch: 367, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 367, LossG: 0.7452                                  \n",
      "[Training] Epoch: 368 [DONE]                                 \n",
      "[Training] Epoch: 368, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 368, LossG: 0.7451                                  \n",
      "[Training] Epoch: 369 [DONE]                                 \n",
      "[Training] Epoch: 369, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 369, LossG: 0.7452                                  \n",
      "[Training] Epoch: 370 [DONE]                                 \n",
      "[Training] Epoch: 370, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 370, LossG: 0.7452                                  \n",
      "[Training] Epoch: 371 [DONE]                                 \n",
      "[Training] Epoch: 371, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 371, LossG: 0.7451                                  \n",
      "[Training] Epoch: 372 [DONE]                                 \n",
      "[Training] Epoch: 372, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 372, LossG: 0.7451                                  \n",
      "[Training] Epoch: 373 [DONE]                                 \n",
      "[Training] Epoch: 373, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 373, LossG: 0.7452                                  \n",
      "[Training] Epoch: 374 [DONE]                                 \n",
      "[Training] Epoch: 374, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 374, LossG: 0.7451                                  \n",
      "[Training] Epoch: 375 [DONE]                                 \n",
      "[Training] Epoch: 375, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 375, LossG: 0.7451                                  \n",
      "[Training] Epoch: 376 [DONE]                                 \n",
      "[Training] Epoch: 376, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 376, LossG: 0.7451                                  \n",
      "[Training] Epoch: 377 [DONE]                                 \n",
      "[Training] Epoch: 377, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 377, LossG: 0.7451                                  \n",
      "[Training] Epoch: 378 [DONE]                                 \n",
      "[Training] Epoch: 378, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 378, LossG: 0.7452                                  \n",
      "[Training] Epoch: 379 [DONE]                                 \n",
      "[Training] Epoch: 379, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 379, LossG: 0.7451                                  \n",
      "[Training] Epoch: 380 [DONE]                                 \n",
      "[Training] Epoch: 380, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 380, LossG: 0.7451                                  \n",
      "[Training] Epoch: 381 [DONE]                                 \n",
      "[Training] Epoch: 381, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 381, LossG: 0.7451                                  \n",
      "[Training] Epoch: 382 [DONE]                                 \n",
      "[Training] Epoch: 382, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 382, LossG: 0.7451                                  \n",
      "[Training] Epoch: 383 [DONE]                                 \n",
      "[Training] Epoch: 383, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 383, LossG: 0.7451                                  \n",
      "[Training] Epoch: 384 [DONE]                                 \n",
      "[Training] Epoch: 384, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 384, LossG: 0.7451                                  \n",
      "[Training] Epoch: 385 [DONE]                                 \n",
      "[Training] Epoch: 385, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 385, LossG: 0.7452                                  \n",
      "[Training] Epoch: 386 [DONE]                                 \n",
      "[Training] Epoch: 386, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 386, LossG: 0.7451                                  \n",
      "[Training] Epoch: 387 [DONE]                                 \n",
      "[Training] Epoch: 387, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 387, LossG: 0.7451                                  \n",
      "[Training] Epoch: 388 [DONE]                                 \n",
      "[Training] Epoch: 388, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 388, LossG: 0.7451                                  \n",
      "[Training] Epoch: 389 [DONE]                                 \n",
      "[Training] Epoch: 389, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 389, LossG: 0.7452                                  \n",
      "[Training] Epoch: 390 [DONE]                                 \n",
      "[Training] Epoch: 390, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 390, LossG: 0.7451                                  \n",
      "[Training] Epoch: 391 [DONE]                                 \n",
      "[Training] Epoch: 391, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 391, LossG: 0.7451                                  \n",
      "[Training] Epoch: 392 [DONE]                                 \n",
      "[Training] Epoch: 392, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 392, LossG: 0.7451                                  \n",
      "[Training] Epoch: 393 [DONE]                                 \n",
      "[Training] Epoch: 393, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 393, LossG: 0.7452                                  \n",
      "[Training] Epoch: 394 [DONE]                                 \n",
      "[Training] Epoch: 394, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 394, LossG: 0.7452                                  \n",
      "[Training] Epoch: 395 [DONE]                                 \n",
      "[Training] Epoch: 395, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 395, LossG: 0.7451                                  \n",
      "[Training] Epoch: 396 [DONE]                                 \n",
      "[Training] Epoch: 396, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 396, LossG: 0.7451                                  \n",
      "[Training] Epoch: 397 [DONE]                                 \n",
      "[Training] Epoch: 397, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 397, LossG: 0.7452                                  \n",
      "[Training] Epoch: 398 [DONE]                                 \n",
      "[Training] Epoch: 398, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 398, LossG: 0.7452                                  \n",
      "[Training] Epoch: 399 [DONE]                                 \n",
      "[Training] Epoch: 399, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 399, LossG: 0.7451                                  \n",
      "[Training] Epoch: 400 [DONE]                                 \n",
      "[Training] Epoch: 400, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 400, LossG: 0.7451                                  \n",
      "[Training] Epoch: 401 [DONE]                                 \n",
      "[Training] Epoch: 401, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 401, LossG: 0.7451                                  \n",
      "[Training] Epoch: 402 [DONE]                                 \n",
      "[Training] Epoch: 402, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 402, LossG: 0.7451                                  \n",
      "[Training] Epoch: 403 [DONE]                                 \n",
      "[Training] Epoch: 403, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 403, LossG: 0.7452                                  \n",
      "[Training] Epoch: 404 [DONE]                                 \n",
      "[Training] Epoch: 404, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 404, LossG: 0.7451                                  \n",
      "[Training] Epoch: 405 [DONE]                                 \n",
      "[Training] Epoch: 405, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 405, LossG: 0.7452                                  \n",
      "[Training] Epoch: 406 [DONE]                                 \n",
      "[Training] Epoch: 406, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 406, LossG: 0.7451                                  \n",
      "[Training] Epoch: 407 [DONE]                                 \n",
      "[Training] Epoch: 407, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 407, LossG: 0.7451                                  \n",
      "[Training] Epoch: 408 [DONE]                                 \n",
      "[Training] Epoch: 408, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 408, LossG: 0.7451                                  \n",
      "[Training] Epoch: 409 [DONE]                                 \n",
      "[Training] Epoch: 409, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 409, LossG: 0.7451                                  \n",
      "[Training] Epoch: 410 [DONE]                                 \n",
      "[Training] Epoch: 410, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 410, LossG: 0.7452                                  \n",
      "[Training] Epoch: 411 [DONE]                                 \n",
      "[Training] Epoch: 411, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 411, LossG: 0.7452                                  \n",
      "[Training] Epoch: 412 [DONE]                                 \n",
      "[Training] Epoch: 412, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 412, LossG: 0.7451                                  \n",
      "[Training] Epoch: 413 [DONE]                                 \n",
      "[Training] Epoch: 413, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 413, LossG: 0.7452                                  \n",
      "[Training] Epoch: 414 [DONE]                                 \n",
      "[Training] Epoch: 414, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 414, LossG: 0.7452                                  \n",
      "[Training] Epoch: 415 [DONE]                                 \n",
      "[Training] Epoch: 415, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 415, LossG: 0.7452                                  \n",
      "[Training] Epoch: 416 [DONE]                                 \n",
      "[Training] Epoch: 416, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 416, LossG: 0.7451                                  \n",
      "[Training] Epoch: 417 [DONE]                                 \n",
      "[Training] Epoch: 417, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 417, LossG: 0.7451                                  \n",
      "[Training] Epoch: 418 [DONE]                                 \n",
      "[Training] Epoch: 418, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 418, LossG: 0.7452                                  \n",
      "[Training] Epoch: 419 [DONE]                                 \n",
      "[Training] Epoch: 419, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 419, LossG: 0.7451                                  \n",
      "[Training] Epoch: 420 [DONE]                                 \n",
      "[Training] Epoch: 420, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 420, LossG: 0.7452                                  \n",
      "[Training] Epoch: 421 [DONE]                                 \n",
      "[Training] Epoch: 421, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 421, LossG: 0.7451                                  \n",
      "[Training] Epoch: 422 [DONE]                                 \n",
      "[Training] Epoch: 422, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 422, LossG: 0.7452                                  \n",
      "[Training] Epoch: 423 [DONE]                                 \n",
      "[Training] Epoch: 423, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 423, LossG: 0.7451                                  \n",
      "[Training] Epoch: 424 [DONE]                                 \n",
      "[Training] Epoch: 424, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 424, LossG: 0.7451                                  \n",
      "[Training] Epoch: 425 [DONE]                                 \n",
      "[Training] Epoch: 425, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 425, LossG: 0.7451                                  \n",
      "[Training] Epoch: 426 [DONE]                                 \n",
      "[Training] Epoch: 426, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 426, LossG: 0.7451                                  \n",
      "[Training] Epoch: 427 [DONE]                                 \n",
      "[Training] Epoch: 427, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 427, LossG: 0.7452                                  \n",
      "[Training] Epoch: 428 [DONE]                                 \n",
      "[Training] Epoch: 428, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 428, LossG: 0.7451                                  \n",
      "[Training] Epoch: 429 [DONE]                                 \n",
      "[Training] Epoch: 429, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 429, LossG: 0.7452                                  \n",
      "[Training] Epoch: 430 [DONE]                                 \n",
      "[Training] Epoch: 430, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 430, LossG: 0.7452                                  \n",
      "[Training] Epoch: 431 [DONE]                                 \n",
      "[Training] Epoch: 431, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 431, LossG: 0.7452                                  \n",
      "[Training] Epoch: 432 [DONE]                                 \n",
      "[Training] Epoch: 432, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 432, LossG: 0.7451                                  \n",
      "[Training] Epoch: 433 [DONE]                                 \n",
      "[Training] Epoch: 433, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 433, LossG: 0.7451                                  \n",
      "[Training] Epoch: 434 [DONE]                                 \n",
      "[Training] Epoch: 434, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 434, LossG: 0.7451                                  \n",
      "[Training] Epoch: 435 [DONE]                                 \n",
      "[Training] Epoch: 435, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 435, LossG: 0.7451                                  \n",
      "[Training] Epoch: 436 [DONE]                                 \n",
      "[Training] Epoch: 436, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 436, LossG: 0.7452                                  \n",
      "[Training] Epoch: 437 [DONE]                                 \n",
      "[Training] Epoch: 437, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 437, LossG: 0.7452                                  \n",
      "[Training] Epoch: 438 [DONE]                                 \n",
      "[Training] Epoch: 438, LossG: 0.7452=================================================================] 100.0%\n",
      "[Validation] Epoch: 438, LossG: 0.7452                                  \n",
      "[Training] Epoch: 439 [DONE]                                 \n",
      "[Training] Epoch: 439, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 439, LossG: 0.7451                                  \n",
      "[Training] Epoch: 440 [DONE]                                 \n",
      "[Training] Epoch: 440, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 440, LossG: 0.7451                                  \n",
      "[Training] Epoch: 441 [DONE]                                 \n",
      "[Training] Epoch: 441, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 441, LossG: 0.7451                                  \n",
      "[Training] Epoch: 442 [DONE]                                 \n",
      "[Training] Epoch: 442, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 442, LossG: 0.7451                                  \n",
      "[Training] Epoch: 443 [DONE]                                 \n",
      "[Training] Epoch: 443, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 443, LossG: 0.7451                                  \n",
      "[Training] Epoch: 444 [DONE]                                 \n",
      "[Training] Epoch: 444, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 444, LossG: 0.7451                                  \n",
      "[Training] Epoch: 445 [DONE]                                 \n",
      "[Training] Epoch: 445, LossG: 0.7451=================================================================] 100.0%\n",
      "[Validation] Epoch: 445, LossG: 0.7451                                  \n"
     ]
    }
   ],
   "source": [
    "# Run a training loop\n",
    "for i in range(450, 445, -1):\n",
    "    print(\"Epoch: {}\".format(i))\n",
    "    runTraining(i, weights_path='./models/Test_Model/' + str(i) + '_Epoch', augm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model on an Image\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotOutput(model_path, image_path):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net_test = UNet(4)\n",
    "    net_test = net_test.to(device)\n",
    "    net_test.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "\n",
    "    # Preprocess the image\n",
    "    x = TF.to_tensor(image)\n",
    "    x = TF.normalize(x, [0.5], [0.5])\n",
    "    x = x.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move the tensor to the same device as the model\n",
    "    x = x.to(device)\n",
    "\n",
    "    output = net_test(x)\n",
    "\n",
    "    # The output is the predicted segmentation\n",
    "    predicted_segmentation = torch.argmax(output.squeeze(), dim=0)\n",
    "\n",
    "    # Convert the tensor to a numpy array\n",
    "    predicted_segmentation = predicted_segmentation.detach().cpu().numpy()\n",
    "\n",
    "    # Display the predicted segmentation\n",
    "    plt.imshow(predicted_segmentation, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the training and validation loss of given weights\n",
    "\n",
    "def getLoss(weights_path):\n",
    "    # Load the weights from the file\n",
    "    model = UNet(4)\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "    # Determine the device and move the model to the device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize the loss function\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize a variable to store the total loss\n",
    "    root_dir = './Data/'\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                        root_dir,\n",
    "                                                        transform=transform,\n",
    "                                                        mask_transform=mask_transform,\n",
    "                                                        augment=True,  # Set to True to enable data augmentation\n",
    "                                                        equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                                batch_size=16,\n",
    "                                worker_init_fn=np.random.seed(0),\n",
    "                                num_workers=0,\n",
    "                                shuffle=True)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,                 \n",
    "                            batch_size=16,       \n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "    lossEpoch_train = []\n",
    "    lossEpoch_val = []\n",
    "\n",
    "\n",
    "    for j, data in enumerate(train_loader_full):\n",
    "        ### Set to zero all the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = data            \n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = to_var(labels)\n",
    "        images = to_var(images)\n",
    "\n",
    "        ################### Train ###################\n",
    "        #-- The CNN makes its predictions (forward pass)\n",
    "        net_predictions = model(images)\n",
    "\n",
    "        #-- Compute the losses --#\n",
    "        # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "        segmentation_classes = getTargetSegmentation(labels)\n",
    "        \n",
    "        # COMPUTE THE LOSS\n",
    "        CE_loss_value = CE_loss(softMax(net_predictions), segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "        \n",
    "        lossTotal = CE_loss_value\n",
    "        lossEpoch_train.append(lossTotal.item())\n",
    "\n",
    "    lossEpoch_train = np.asarray(lossEpoch_train)\n",
    "    lossEpoch_train = lossEpoch_train.mean()\n",
    "\n",
    "\n",
    "    for j, data in enumerate(val_loader):\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = data            \n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = to_var(labels)\n",
    "        images = to_var(images)\n",
    "\n",
    "        ################### Validate ###################\n",
    "        #-- The CNN makes its predictions (forward pass)\n",
    "        net_predictions = model(images)\n",
    "\n",
    "        #-- Compute the losses --#\n",
    "        # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "        segmentation_classes = getTargetSegmentation(labels)\n",
    "        \n",
    "        # COMPUTE THE LOSS\n",
    "        CE_loss_value = CE_loss(softMax(net_predictions), segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "        \n",
    "        lossTotal = CE_loss_value\n",
    "        lossEpoch_val.append(lossTotal.item())\n",
    "\n",
    "    lossEpoch_val = np.asarray(lossEpoch_val)\n",
    "    lossEpoch_val = lossEpoch_val.mean()\n",
    "\n",
    "    print('Training loss:', lossEpoch_train)\n",
    "    print('Validation loss:', lossEpoch_val)\n",
    "    return lossEpoch_train, lossEpoch_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7624091322605426\n",
      "Validation loss: 0.7545190215110779\n",
      "Training loss: 0.7455840294177716\n",
      "Validation loss: 0.7507919788360595\n",
      "Training loss: 0.7453137361086332\n",
      "Validation loss: 0.7500378608703613\n",
      "Training loss: 0.7451509328988882\n",
      "Validation loss: 0.7498529434204102\n",
      "Training loss: 0.7449692029219407\n",
      "Validation loss: 0.7495559453964233\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training and validation loss for multiple models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models_paths = ['./models/' + 'Trained' + '/Adam_Labeled_1.3k_Epoch']\n",
    "# models_paths = ['./models/' + 'Trained\\Data_Augmented' + '/Adam_Labeled_' + str(i) + '5k_Epoch' for i in range(0, 8)]\n",
    "# models_paths = ['./models/' + 'Trained/2nd_model_simple_multi_unet_model' + '/' + str(i) + '_Epoch' for i in range(10,500,10)]\n",
    "models_paths = ['./models/' + 'Test_Model' + '/' + str(i) + '_Epoch' for i in range(450, 445, -1)]\n",
    "# List to store the losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Iterate over the list of paths\n",
    "for path in models_paths:\n",
    "    # Get the losses for the current path\n",
    "    train_loss, val_loss = getLoss(path)\n",
    "    \n",
    "    # Add the losses to the lists\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "# Plot the losses\n",
    "epochs = range(len(models_paths))\n",
    "# epochs = [(5 + 10*i)*1000 for i in range(len(train_losses))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_losses, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses\n",
    "epochs = range(len(models_paths))\n",
    "# epochs = [(5 + 10*i)*1000 for i in range(len(train_losses))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_losses, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 0.7585404652815598, 0.7545776724815368)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the index of minimum validation loss\n",
    "min_train_loss = min(train_losses)\n",
    "min_train_loss_index = train_losses.index(min_train_loss)\n",
    "min_train_loss_index, min_train_loss, val_losses[min_train_loss_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def plot_model_output(model_path, image_path):\n",
    "    # Ensure model is in eval mode\n",
    "    net_test = UNet(4)\n",
    "\n",
    "    # Determine the device and move the model to the device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net_test = net_test.to(device)\n",
    "    net_test.load_state_dict(torch.load(model_path))\n",
    "    net_test.eval()\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "\n",
    "    # Preprocess the image\n",
    "    x = TF.to_tensor(image)\n",
    "    x = TF.normalize(x, [0.5], [0.5])\n",
    "    x = x.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move the tensor to the same device as the model\n",
    "    x = x.to(device)\n",
    "\n",
    "    # Get the model output\n",
    "    with torch.no_grad():\n",
    "        output = net_test(x)\n",
    "\n",
    "    # The output is the predicted segmentation\n",
    "    predicted_segmentation = torch.argmax(output.squeeze(), dim=0)\n",
    "\n",
    "    # Convert the tensor to a numpy array\n",
    "    predicted_segmentation = predicted_segmentation.detach().cpu().numpy()\n",
    "\n",
    "    # Display the predicted segmentation\n",
    "    plt.imshow(predicted_segmentation, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "# plot_model_output(model_path, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARtklEQVR4nO3dfYxV9Z3H8fcHKIMPo8Dy0BFQ0LDNQmspHVkNxrjUrUj/QJu4oX+0JGvEP2xiE0yD7R+aJta6QdukKTZQacmmrUtSG8nKugjBaGhTReUZ0RFYnEKH4aEiFAeG+e4fc6AXfndm7szcc++d4fNKJvfc33n4fTmOnznPRxGBmVmhIdUuwMxqj4PBzBIOBjNLOBjMLOFgMLOEg8HMErkFg6S5kvZIapK0JK9+zKz8lMd1DJKGAu8D/wo0A28B34iIXWXvzMzKLq8thllAU0TsjYgzwAvA/Jz6MrMyG5bTcicAHxV8bwb+uauJJfnyS7P8HYmIsaVMmFcwqEjbRf/zS1oELMqpfzNL/V+pE+YVDM3ApILvE4GDhRNExHJgOXiLwazW5HWM4S1gqqQpkoYDC4A1OfVlZmWWyxZDRLRL+jbwv8BQYGVE7MyjLzMrv1xOV/a6CO9KmFXC2xHRWMqEvvLRzBIOBjNLOBjMLOFgMLOEg8HMEg4GM0s4GMws4WAws4SDwcwSDgYzSzgYzCzhYDCzhIPBzBIOBjNLOBjMLOFgMLOEg8HMEg4GM0s4GMws4WAws4SDwcwSDgYzSzgYzCzhYDCzhIPBzBIOBjNLOBjMLOFgMLOEg8HMEg4GM0s4GMws4WAws4SDwcwSDgYzSwzrz8yS9gOfAOeA9oholDQa+C9gMrAf+LeION6/Ms2sksqxxfAvETEjIhqz70uADRExFdiQfTezASSPXYn5wKpseBVwbw59mFmO+hsMAayT9LakRVnb+Ig4BJB9jis2o6RFkjZL2tzPGsyszPp1jAGYHREHJY0DXpX0XqkzRsRyYDmApOhnHWZWRv3aYoiIg9nnYeD3wCygRVIDQPZ5uL9Fmlll9TkYJF0lqf78MPBVYAewBliYTbYQeKm/RZpZZfVnV2I88HtJ55fzm4h4RdJbwGpJDwAHgPv7X6aZVZIiqr9772MMZhXxdsFlBd3ylY9mlnAwmFnCwWBmCQeDmSUcDGaWcDCYWcLBYGYJB4OZJRwMZpZwMJhZwsFgZgkHg5klHAxmlnAwmFnCwTAAzJgxg/r6er72ta9VuxS7TPT3mY9WAVu2bAHg+HG/nsMqww9qMbt8+EEtZtZ3DgYzSzgYzCzhYDCzhIPBzBIOBjNLOBjMLOFgMLOEg8HMEg4GM0s4GMws4WAws4SDwcwSDgYzSzgYzCzhYDCzRI/BIGmlpMOSdhS0jZb0qqQPss9RBeMek9QkaY+ku/Mq3MzyU8oWw6+AuZe0LQE2RMRUYEP2HUnTgAXA9GyeZZKGlq1aM6uIHoMhIl4Hjl3SPB9YlQ2vAu4taH8hItoiYh/QBMwqT6lmVil9PcYwPiIOAWSf47L2CcBHBdM1Z21mNoCU+ynRKtJW9EGvkhYBi8rcv5mVQV+3GFokNQBkn4ez9mZgUsF0E4GDxRYQEcsjorHUp9aaWeX0NRjWAAuz4YXASwXtCyTVSZoCTAXe7F+JZlZpPe5KSPotcCcwRlIz8DjwI2C1pAeAA8D9ABGxU9JqYBfQDjwcEedyqt3McuIXzphdPvzCGTPrOweDmSUcDGaWcDCYWcLBYGaJcl/5aIPAPffcw1e+8pUep2tqauLnP/95BSqySvPpSmP48OFcccUV/PSnPwVg2LBhDBvW89+Mjo4Ozpw5A8APf/hD9u3bR1tbW661Wr+UfLrSwXAZu+aaaxg5ciSLFy+moaGh38trb29nyZIlnD59mtbW1jJUaGXmYLDujRo1im9961vMnj277Mveu3cvy5Yt48CBA2VftvWLg8G6dvXVV/Pggw9y22235dbHnj172LVrF2vXruXjjz/OrR/rFQeDFffII48wcuRIpk+fXpH+du3axZNPPsnZs2cr0p91y8FgqcWLF3PLLbcwZEhlz1IfOHCARx99tKJ9WlEOBrvYgw8+yF133YVU7Fk6nerq6rjuuuuYOXNm0fE7duxg//79AETEhTMSpdi3bx+PP/44n376aa/qtrJyMNjfXXvttTz00EM0Nnb9OzF27FjuvPPOkpfZ1tbGpk2bADh58mRJpym3bt3KsmXLOH78eMn9WFn57kr7u9tuu63bUJg4cSJ33HFHr5ZZV1fHnDlzmDNnDjfffDNTpkzpcRfli1/8Yq/7sepwMAxyn/3sZ7n11lu7HD958mS+/OUv9+u4w+TJk2lsbGTGjBk9TtvY2MjEiRP73JdVhi+JHuRGjx7NtGnTio674YYbuPnmmxk+fHhZ+rrpppu45pprOHr0KNu3by86zec+9znGjBlDc3NzWfq0fDgYBrFrr72WxYsXFx03fvx4Zs6cWdKlz70xduxY2tvbkURXx6+GDvU7iGqddyUGsSFDhlBfX5+0S+KKK64oeyic19DQ0O11Et/97ncZO3ZsLn1beTgYLkNXXXUVt9xyS+59jBgxoug4Sd2eNrXqczAMYnPmzKla39dff723CgYwB8MgJYn7778/aR8yZAhf+MIXqlCRDSQOhsuQTxdaTxwMl5lKnRGIiC7PSgA8/fTTPjtRwxwMl5l58+ZVpJ/33nuv22sVrrzyyorUYX3jYDCzhIPhMvP+++9XuwQAXnnlFTo6OqpdhnXBwXCZ2bNnT7VLAODll1/u9hiEVZeDYZCKCH7wgx9UuwwboBwMg9jBgweT5yR0dHSwbt26XPuNCM6dO9fl+La2Nu9G1DgHwyD217/+laeeeippP3PmDCdPnsyt37/85S/s3r27y/HPPPMMR44cya1/6z8Hw2Xo9OnTbNmyJZdlt7e3+50Sg4CDYZBraWlh8+bNSfsnn3xCS0tL2fv79NNPa+YAp/Wdg2GQO3r0KCtXrmTr1q0XtZ88ebIqf9k3btzI3r17K96v9U6PwSBppaTDknYUtD0h6c+StmQ/8wrGPSapSdIeSXfnVbiV7siRI0X36Zuamjh06FDZ+uno6OC1117rcvzmzZtZtWoVJ06cKFuflo9Sthh+Bcwt0v7jiJiR/awFkDQNWABMz+ZZJskXxNeAFStWsHXr1ouuHTh79iybNm0q24HAl19+mdOnTxcd19HRwfHjx/nb3/5Wlr4sXz0GQ0S8DhwrcXnzgRcioi0i9gFNwKx+1Gdl0tHRwZNPPsm2bdsuao8INm7c2O/dio8//rjLU5QdHR288cYbrFixol99WOX05xjDtyVty3Y1RmVtE4CPCqZpztoSkhZJ2iwpPTJmuXnqqadYv34977777kXtb7zxRp8f0Nra2sqmTZu6fA3d+vXr+dnPftanZVt19DUYngNuAmYAh4BnsvZiz+sqet1rRCyPiMZSX4Bh5dHR0cHy5cv5xS9+cdHZinPnzrFr165eL6+1tZV33nmHU6dOFR3/4osv8stf/rLP9Vp19OlpoBFx4TyXpBXAf2dfm4FJBZNOBA72uTrLTWtrK88//zwjRozg85//PACnTp3itdde48Ybb+T666/vdv62tjb++Mc/cvr06S4vllq9ejVr1qzp9ipIq019CgZJDRFx/nD2fcD5MxZrgN9Ieha4DpgKvNnvKi0XR48eZenSpQwfPpyf/OQnXHnllbS2tnL8+HHq6uoYN27chYe2Fh60jAjWrVvX5Xso3333XZ577jlOnTrlt1wPUD2+u1LSb4E7gTFAC/B49n0GnbsJ+4GHzgeFpO8D/w60A9+JiP/psQi/u7LqRowYwbPPPktdXR319fUXAmHu3LmcOHGCP/zhDxdNX+z35tixY7S0tPDEE0/4zsna5JfaWt9MmzaNr3/960DnW6Pq6up6nKe5uZljx46xdOlSv826tjkYrP/uu+8+6uvrGTlyJLfffvuF9ohg7dq1F7YKNm3axIcfflitMq10DgYrn/r6embOnHnhe0Tw+uuvV7Ei6yMHg5klSg4G30RlZgkHg5klHAxmlnAwmFnCwWBmCQeDmSUcDGaWcDCYWcLBYGYJB4OZJRwMZpZwMJhZwsFgZgkHg5klHAxmlnAwmFnCwWBmCQeDmSUcDGaWcDCYWcLBYGYJB4OZJRwMZpZwMJhZwsFgZgkHg5klHAxmlnAwmFnCwWBmCQeDmSV6DAZJkyRtlLRb0k5Jj2TtoyW9KumD7HNUwTyPSWqStEfS3Xn+A8ys/ErZYmgHFkfEPwG3Ag9LmgYsATZExFRgQ/adbNwCYDowF1gmaWgexZtZPnoMhog4FBHvZMOfALuBCcB8YFU22Srg3mx4PvBCRLRFxD6gCZhV5rrNLEe9OsYgaTLwJeBPwPiIOASd4QGMyyabAHxUMFtz1mZmA8SwUieUdDXwO+A7EXFCUpeTFmmLIstbBCwqtX8zq5ySthgkfYbOUPh1RLyYNbdIasjGNwCHs/ZmYFLB7BOBg5cuMyKWR0RjRDT2tXgzy0cpZyUEPA/sjohnC0atARZmwwuBlwraF0iqkzQFmAq8Wb6SzSxvpexKzAa+CWyXtCVr+x7wI2C1pAeAA8D9ABGxU9JqYBedZzQejohz5S7czPKjiGT3v/JFSNUvwmzwe7vUXXdf+WhmCQeDmSUcDGaWcDCYWcLBYGYJB4OZJRwMZpZwMJhZwsFgZgkHg5klHAxmlnAwmFnCwWBmCQeDmSUcDGaWcDCYWcLBYGYJB4OZJRwMZpZwMJhZwsFgZgkHg5klHAxmlnAwmFnCwWBmCQeDmSUcDGaWcDCYWcLBYGYJB4OZJRwMZpZwMJhZwsFgZgkHg5klegwGSZMkbZS0W9JOSY9k7U9I+rOkLdnPvIJ5HpPUJGmPpLvz/AeYWfkNK2GadmBxRLwjqR54W9Kr2bgfR8TSwoklTQMWANOB64D1kv4xIs6Vs3Azy0+PWwwRcSgi3smGPwF2AxO6mWU+8EJEtEXEPqAJmFWOYs2sMnp1jEHSZOBLwJ+ypm9L2iZppaRRWdsE4KOC2ZopEiSSFknaLGlz78s2szyVHAySrgZ+B3wnIk4AzwE3ATOAQ8Az5yctMnskDRHLI6IxIhp7W7SZ5aukYJD0GTpD4dcR8SJARLRExLmI6ABW8PfdhWZgUsHsE4GD5SvZzPJWylkJAc8DuyPi2YL2hoLJ7gN2ZMNrgAWS6iRNAaYCb5avZDPLWylnJWYD3wS2S9qStX0P+IakGXTuJuwHHgKIiJ2SVgO76Dyj8bDPSJgNLIpIdv8rX4TUCpwCjlS7lhKMYWDUCQOn1oFSJwycWovVeUNEjC1l5poIBgBJmwfCgciBUicMnFoHSp0wcGrtb52+JNrMEg4GM0vUUjAsr3YBJRoodcLAqXWg1AkDp9Z+1VkzxxjMrHbU0haDmdWIqgeDpLnZ7dlNkpZUu55LSdovaXt2a/nmrG20pFclfZB9juppOTnUtVLSYUk7Ctq6rKuat8J3UWvN3bbfzSMGamq9VuRRCBFRtR9gKPAhcCMwHNgKTKtmTUVq3A+MuaTtP4Al2fAS4Okq1HUHMBPY0VNdwLRs3dYBU7J1PrTKtT4BPFpk2qrVCjQAM7PheuD9rJ6aWq/d1Fm2dVrtLYZZQFNE7I2IM8ALdN62XevmA6uy4VXAvZUuICJeB45d0txVXVW9Fb6LWrtStVqj60cM1NR67abOrvS6zmoHQ0m3aFdZAOskvS1pUdY2PiIOQed/JGBc1aq7WFd11ep67vNt+3m75BEDNbtey/kohELVDoaSbtGustkRMRO4B3hY0h3VLqgPanE99+u2/TwVecRAl5MWaatYreV+FEKhagdDzd+iHREHs8/DwO/p3ARrOX93afZ5uHoVXqSrumpuPUeN3rZf7BED1OB6zftRCNUOhreAqZKmSBpO57Mi11S5pgskXZU95xJJVwFfpfP28jXAwmyyhcBL1akw0VVdNXcrfC3ett/VIwaosfVakUchVOJobw9HWOfReVT1Q+D71a7nktpupPNo7lZg5/n6gH8ANgAfZJ+jq1Dbb+ncXDxL51+EB7qrC/h+to73APfUQK3/CWwHtmW/uA3VrhW4nc5N7G3AluxnXq2t127qLNs69ZWPZpao9q6EmdUgB4OZJRwMZpZwMJhZwsFgZgkHg5klHAxmlnAwmFni/wEt/L+5JYPHzAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the outputs for different models\n",
    "\n",
    "# models_paths = ['./models/' + 'Trained/2nd_model_simple_multi_unet_model' + '/' + str(i) + '_Epoch' for i in range(50,500,50)]\n",
    "# models_paths = ['./models/' + 'Trained/Data_Augmented_15K_EpochPlus' + '/Adam_Labeled_' + str(i) + '5k_Epoch' for i in range(0, 8)]\n",
    "models_paths = ['./models/' + 'Trained/2nd_model_simple_multi_unet_model/Data_Augmented/Augmented_' + str(i) + 'x' for i in range(6)]\n",
    "image_path = \"./Data/val/Img/patient001_12_2.png\"\n",
    "\n",
    "for model_path in models_paths:\n",
    "    plotOutput(model_path, image_path)\n",
    "    # plot_model_output(model_path, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
